Last login: Tue Jan 17 20:26:26 on ttys001
(base) ankitaroychoudhury@Ankitas-MacBook-Pro ~ % cd Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury 
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % git status
On branch main
Your branch is up to date with 'origin/main'.

nothing to commit, working tree clean
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % pytest -m
ERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]
pytest: error: argument -m: expected one argument

(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % pytest
============================= test session starts ==============================
platform darwin -- Python 3.9.13, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury
plugins: anyio-3.5.0
collected 20 items                                                             

tests/test_a_environment.py .                                            [  5%]
tests/test_a_setup.py ...                                                [ 20%]
tests/test_data.py .FF                                                   [ 35%]
tests/test_decision_tree.py FFFF                                         [ 55%]
tests/test_experiment.py FF                                              [ 65%]
tests/test_metrics.py F                                                  [ 70%]
tests/test_numpy.py ..FFFF                                               [100%]

=================================== FAILURES ===================================
____________________________ test_train_test_split _____________________________

    def test_train_test_split():
        from src import load_data
        from src import train_test_split
    
        n_features = np.random.randint(5, 20)
        n_samples = np.random.randint(50, 150)
        features, targets, attribute_names = write_random_csv_file(n_features, n_samples)
        fraction = np.random.rand()
    
>       output = train_test_split(features, targets, fraction)

tests/test_data.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[-0.94419946,  0.09254154, -1.46925943, ...,  0.3644835 ,
        -0.77533515,  0.14395248],
       [-1.3607441...113, -0.33294272],
       [-1.49393237, -0.53822425, -0.77794142, ..., -0.23658294,
         0.40176608,  0.27907642]])
labels = array([0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,
       0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,...    1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0])
fraction = 0.2798708631823529

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
____________________________ test_cross_validation _____________________________

    def test_cross_validation():
        from src import load_data
        from src import cross_validation
    
        # Remember, your train_test_split should be deterministic
        # You shouldn't be randomly shuffling the data!
        n = 10
        features = np.arange(n).reshape(-1, 1)
        targets = np.arange(n).reshape(-1, 1)
        for folds in [2, 5, 10]:
>           cv = cross_validation(features, targets, folds)

tests/test_data.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
labels = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
n_folds = 2

    def cross_validation(features, labels, n_folds):
        """
        Split the data in `n_folds` different groups for cross-validation.
            Split the features and labels into a `n_folds` number of groups that
            divide the data as evenly as possible. Then for each group,
            return a tuple that treats that group as the test set and all
            other groups combine to make the training set.
    
            Note that this should be *deterministic*; don't shuffle the data.
            If there are 100 examples and you have 5 folds, each group
            should contain 20 examples and the first group should contain
            the first 20 examples.
    
            See test_cross_validation for expected behavior.
    
        Args:
            features: an NxK matrix of N examples, each with K features
            labels: an Nx1 array of N labels
            n_folds: the number of cross-validation groups
    
        Output:
            A list of tuples, where each tuple contains:
              (train_features, train_labels, test_features, test_labels)
        """
    
        assert features.shape[0] == labels.shape[0]
    
        if n_folds == 1:
            return [(features, labels, features, labels)]
>       raise NotImplementedError
E       NotImplementedError

src/data.py:92: NotImplementedError
______________________ test_decision_tree_binary_predict _______________________

    def test_decision_tree_binary_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Outlook', 'Temp', 'Wind']
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Outlook", attribute_index=0,
            split_value=0.5, branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=0.5, branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
        examples = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [0, 1, 1]])
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fdf42585c40>
features = array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 1, 1],
       [0, 1, 1]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
____________________ test_decision_tree_continuous_predict _____________________

    def test_decision_tree_continuous_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Wind', 'Temp', 'Outlook']
        examples = np.array([[1, 79.21, 1], [2, 90.56, 0], [7, 88.36, 1], [5, 84.02, 0], [1, 43.77, 0]])
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Wind", attribute_index=0,
            split_value=np.median(examples[:, 0]), branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=np.median(examples[:, 1]), branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
    
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fdf425b1ca0>
features = array([[ 1.  , 79.21,  1.  ],
       [ 2.  , 90.56,  0.  ],
       [ 7.  , 88.36,  1.  ],
       [ 5.  , 84.02,  0.  ],
       [ 1.  , 43.77,  0.  ]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
____________________________ test_information_gain _____________________________

    def test_information_gain():
        from src import load_data
        from src import information_gain
    
        _features, _targets, _attribute_names = load_data('data/play-tennis.csv')
>       iGHumidity = information_gain(_features, 2, _targets)

tests/test_decision_tree.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0, 0, 1, 0],
       [0, 0, 1, 1],
       [1, 0, 1, 0],
       [1, 1, 1, 0],
       [1, 1, 0, 0],
       [1, 1,...[0, 1, 0, 0],
       [1, 1, 0, 0],
       [0, 1, 0, 1],
       [1, 1, 1, 1],
       [1, 0, 0, 0],
       [1, 1, 1, 1]])
attribute_index = 2
labels = array([[0],
       [0],
       [1],
       [1],
       [1],
       [0],
       [1],
       [0],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0]])

    def information_gain(features, attribute_index, labels):
        """
        Information gain is how a decision tree makes decisions on how to create
        split points in the tree. Information gain is measured in terms of entropy.
        The goal of a decision tree is to decrease entropy at each split point as
        much as possible. This function should work perfectly or your decision tree
        will not work properly.
    
        Information gain is a central concept in many machine learning algorithms.
        In decision trees, it captures how effective splitting the tree on a
        specific attribute will be for the goal of classifying the training data
        correctly.  Consider data points S and an attribute A; we'll split S into
        two data points.
    
        For binary A: S(A == 0) and S(A == 1)
        For continuous A: S(A < m) and S(A >= m), where m is the median of A in S.
    
        Together, the two subsets make up S. If the attribute A were perfectly correlated with
        the class of each data point in S, then all points in a given subset will have the
        same class. Clearly, in this case, we want something that captures that A is a good
        attribute to use in the decision tree. This something is information gain. Formally:
    
            IG(S,A) = H(S) - H(S|A)
    
        where H is information entropy. Recall that entropy captures how orderly or chaotic
        a system is. A system that is very chaotic will evenly distribute probabilities to
        all outcomes (e.g. 50% chance of class 0, 50% chance of class 1). Machine learning
        algorithms work to decrease entropy, so as to make predictions that are
        accurate on testing data. Formally, H is defined as:
    
            H(S) = sum_{c in (groups in S)} -p(c) * log_2 p(c)
    
        To elaborate: for each group c in S, you compute the probability (or weight) of c:
    
            p(c) = (# of elements of group c in S) / (total # of elements in S)
    
        Then you compute the term for this group:
    
            -p(c) * log_2 p(c)
    
        Note: if p(c) is 0, we define `-p(c) * log_2 p(c)` as 0. You can see how
            we handle this in the provided `entropy()` function, to avoid how numpy
            defines `0 * log(0) = 0 * -inf = nan`.
    
        Then compute the sum across all groups: either classes 0 and 1 for binary data, or
        for the above-median and below-median classes for continuous data. The final number
        is the entropy. To gain more intution about entropy, consider the following - what
        does H(S) = 0 tell you about S?
    
        Information gain is an extension of entropy. The equation for information gain
        involves comparing the entropy of the set and the entropy of the set when conditioned
        on selecting for a single attribute (e.g. S(A == 0)).
    
        For more details: https://en.wikipedia.org/wiki/ID3_algorithm#The_ID3_metrics
    
        Args:
            features (np.array): numpy array containing features for each example.
            attribute_index (int): which column of features to take when computing the
                information gain
            labels (np.array): numpy array containing labels corresponding to each example.
    
        Returns:
            information_gain (float): information gain if the features were split on the
                attribute_index.
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:262: NotImplementedError
____________________________ test_decision_tree_run ____________________________

    def test_decision_tree_run():
        goals = {
            'xor-easy.csv': {1.0: 1.0},
            'xor-hard.csv': {1.0: 0.8, 0.8: 1.0},
            'ivy-league.csv': {1.0: .9, 0.8: 0.6,},
            'majority-rule.csv': {1.0: 1.0, 0.8: 0.8,},
            'circles-hard.csv': {1.0: 0.7},
            'circles-easy.csv': {1.0: 0.8},
            'blobs.csv': {1.0: 0.8, 0.8: 0.9,},
        }
    
        order = [
            'xor-easy.csv',
            'ivy-league.csv',
            'majority-rule.csv',
            'xor-hard.csv',
            'blobs.csv',
            'circles-easy.csv',
            'circles-hard.csv',
        ]
    
        learner_type = 'decision_tree'
        for key in order:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_decision_tree.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
src/decision_tree.py:125: in fit
    self.tree = self._create_tree(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fdf425858b0>
features = array([[1, 1],
       [0, 0],
       [1, 0],
       [0, 1]])
labels = array([[0],
       [0],
       [1],
       [1]]), used_attributes = []
default = 0

    def _create_tree(self, features, labels, used_attributes, default):
        '''
        Create a decision tree recursively.
        1. If no data remains, return a leaf node with return_value `default`
            (e.g., if features and labels are both empty)
    
        2. If all labels are the same, return a leaf node with
            that label as the return_value
    
        3. For each attribute, compute the information gain from splitting on it
    
        3.1. If that is in `used_attributes`, instead set information gain to -1
            to prevent us from reusing it
        3.2. If all attributes are used, return a leaf node with the mode class
    
        3.3.1 If at least one attribute, has a non-negative information gain,
            select `best_attribute` with the largest information gain;
        3.3.2 Split data (feature & label) according to attribute values,
            where: `attribute_values = features[:, best_attribute]`;
        3.3.3 If that attribute's values are binary, split on 0.5;
            Otherwise, split on the median of the attribute values;
    
        3.4 Create a non-leaf node with the specified attribute_name,
              attribute_index, and split_value, and then RECURSIVELY
              set build its branches using self._create_tree.
              After recursing, return the node.
        '''
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:160: NotImplementedError
______________________________ test_predict_mode _______________________________

    def test_predict_mode():
        goals = {
          'ivy-league.csv': {1.0: 0.5},
          'majority-rule.csv': {1.0: 0.6},
          'circles-easy.csv': {1.0: 0.6},
          'blobs.csv': {1.0: 0.55},
        }
    
        learner_type = 'predict_mode'
        for key in goals:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_experiment.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.predict_mode.PredictMode object at 0x7fdf4256c5b0>
features = array([[1, 1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 1, 0, 0]...      [0, 1, 1, 0, 1, 0, 1],
       [0, 1, 1, 0, 0, 1, 1],
       [0, 1, 1, 0, 0, 0, 1],
       [0, 1, 1, 0, 0, 1, 1]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0]...      [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0],
       [0]])

    def fit(self, features, labels):
        """
        Looking at the provided labels, record the mode (most common) label.
    
        You may call your `find_mode` function from `src.numpy_practice`
    
        Args:
            features (np.array): numpy array of shape (n, d)
                 where n is number of examples and d is number of features.
            labels (np.array): numpy array containing true labels for each of the N
                examples.
        Output:
            None: Simply update self.most_common_class with the most common label
        """
>       raise NotImplementedError
E       NotImplementedError

src/predict_mode.py:35: NotImplementedError
_______________________________ test_comparisons _______________________________

    def test_comparisons():
        comparisons = [
            # predict_mode beats decision tree on majority rule w/ 0.7 frac
            ('majority-rule.csv', 0.7, 'predict_mode', 'decision_tree',
             {}, {}),
    
            # decision tree beats predict mode on majority rule w/ 1.0 frac
            ('majority-rule.csv', 1.0, 'decision_tree', 'predict_mode',
             {}, {}),
        ]
    
        for i, comparison in enumerate(comparisons):
            (key, fraction, method_a, method_b,
             kwargs_a, kwargs_b) = comparison
    
            data_path = datasets.get(key)
>           acc_a = run(data_path, method_a, fraction, **kwargs_a)

tests/test_experiment.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:55: in run
    X_train, Y_train, X_test, Y_test = train_test_split(X, Y, fraction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 0, 0],
       [1,... 1, 0, 0],
       [0, 0, 0, 0, 1, 1],
       [0, 0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0, 1],
       [0, 0, 0, 0, 0, 0]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [1],
       [1]...      [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0]])
fraction = 0.7

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
_________________________________ test_metrics _________________________________

    def test_metrics():
        from sklearn.metrics import accuracy_score
        from src import compute_accuracy
    
        y_true, y_pred = make_fake_data()
        _actual = accuracy_score(y_true, y_pred)
>       _est = compute_accuracy(y_true, y_pred)

tests/test_metrics.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = array([False, False, False, False, False,  True,  True, False,  True,
       False,  True, False,  True,  True, False,... True,  True,  True,  True, False,
        True,  True, False, False, False,  True, False,  True,  True,
       False])
predictions = array([ True, False,  True, False,  True, False,  True,  True,  True,
        True,  True, False,  True,  True,  True,... True,  True, False, False,  True,
        True, False,  True,  True,  True,  True,  True,  True,  True,
        True])

    def compute_accuracy(actual, predictions):
        """
        Given predictions (an N-length numpy vector) and actual labels (an N-length
        numpy vector), compute the accuracy:
    
        Hint: implement and use the compute_confusion_matrix function!
    
        Args:
            actual (np.array): predicted labels of length N
            predictions (np.array): predicted labels of length N
    
        Output:
            accuracy (float): accuracy
        """
        if predictions.shape[0] != actual.shape[0]:
            raise ValueError("predictions and actual must be the same length!")
    
>       raise NotImplementedError
E       NotImplementedError

src/metrics.py:53: NotImplementedError
_____________________ test_numpy_replace_nans_out_of_place _____________________

    @pytest.mark.filterwarnings("ignore:divide by zero:RuntimeWarning")
    @pytest.mark.filterwarnings("ignore:invalid value encountered in divide:RuntimeWarning")
    def test_numpy_replace_nans_out_of_place():
    
        pairs = [
            (np.array([1, 2, 3, np.inf, 4, 5, np.nan, np.true_divide(-1, 0), 6]),
             np.array([1, 2, 3, np.inf, 4, 5, 0, -np.inf, 6])),
    
            (np.array([-1, 1, 0, -1, 1, 0]) / np.array([1, 0, 1, 0, 1, 0]),
             np.array([-1, np.inf, 0, -np.inf, 1, 0])),
        ]
    
        for before, after in pairs:
            before_copy = before.copy()
            retval = src.numpy_practice.replace_nans_out_of_place(before)
>           assert np.array_equal(retval, after), "replace_nans_out_of_place should return answer"
E           AssertionError: replace_nans_out_of_place should return answer
E           assert False
E            +  where False = <function array_equal at 0x7fdf40c59d30>(None, array([  1.,   2.,   3.,  inf,   4.,   5.,   0., -inf,   6.]))
E            +    where <function array_equal at 0x7fdf40c59d30> = np.array_equal

tests/test_numpy.py:126: AssertionError
_____________________________ test_numpy_find_mode _____________________________

    def test_numpy_find_mode():
        pairs = [
            (np.array([1, 2, 2, 3, 3, 3]),
             3),
            (np.concatenate([np.arange(3, 7), np.arange(6, 0, -1), np.arange(1, 7, 3)]),
             4),
            (np.concatenate([np.zeros(10), np.ones(11)]),
             1)
        ]
        for arr, target in pairs:
>           assert src.numpy_practice.find_mode(arr) == target, f"Mode is {target}"

tests/test_numpy.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([1, 2, 2, 3, 3, 3])

    def find_mode(x):
        """
        In the given array, find the mode of the vector.
        The mode is the value that appears the most times (don't worry about ties).
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([1, 2, 2, 3, 3, 3])
            >>> find_mode(x)
            3
    
        You should use:
            - np.argmax: https://numpy.org/doc/stable/reference/generated/numpy.argmax.html
    
        You should use one of:
            - np.unique: https://numpy.org/doc/stable/reference/generated/numpy.unique.html
            - np.bincount: https://numpy.org/doc/stable/reference/generated/numpy.bincount.html
    
        Args:
            x: a numpy array of integers
        Returns:
            the mode of x
        """
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:106: NotImplementedError
_______________________ test_numpy_flip_and_slice_matrix _______________________

    def test_numpy_flip_and_slice_matrix():
    
        pairs = [
            (np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]]),
             np.array([[2, 1, 0], [11, 10, 9]])),
            (np.array([[ 2,  6, 16, 18, 13, 13, 17]]).T,
             np.array([[2, 18, 17]]).T),
            (np.array([[ 0, 17, 14,  4]]),
             np.array([[ 4, 14, 17,  0]]))
        ]
        for before, after in pairs:
            msg = f"flip_and_slice_matrix({before}) should return {after}"
            before = before.astype(int)
>           assert np.array_equal(src.numpy_practice.flip_and_slice_matrix(before), after), msg

tests/test_numpy.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11],
       [12, 13, 14]])

    def flip_and_slice_matrix(x):
        """
        Take the matrix x and flip it horizontally, then take the every third row.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2],
            ...               [ 3,  4,  5],
            ...               [ 6,  7,  8],
            ...               [ 9, 10, 11],
            ...               [12, 13, 14]])
            >>> flip_and_slice_matrix(x)
            array([[2, 1, 0],
                   [11, 10, 9]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.indexing.html#basics-indexing
    
        Args:
          x: a matrix
        Returns:
          a numpy matrix
        """
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:134: NotImplementedError
_____________________ test_numpy_divide_matrix_along_rows ______________________

    def test_numpy_divide_matrix_along_rows():
    
        trios = [
            (np.array([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]),
             np.array([1, 2, 4]),
             np.array([[0, 1, 2, 3], [2, 2.5, 3, 3.5], [2, 2.25, 2.5, 2.75]])),
            (np.array([[2, 14], [2, 17], [8, 8], [12, 9], [9, 6], [10, 4]]),
             np.array([1, 1, 2, 3, 3, 2]),
             np.array([[2, 14], [2, 17], [4, 4], [4, 3], [3, 2], [5, 2]]))
        ]
        for (x, y, target) in trios:
            msg = f"divide_matrix_along_rows({x}, {y}) should return {target}"
>           assert np.array_equal(src.numpy_practice.divide_matrix_along_rows(x, y), target), msg

tests/test_numpy.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])
y = array([1, 2, 4])

    def divide_matrix_along_rows(x, y):
        """
        Take the matrix x and divide it by the vector y, such that
            the ith row of x is divided by the ith value of y.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2,  3],
            ...               [ 4,  5,  6,  7],
            ...               [ 8,  9, 10, 11]])
            >>> y = np.array([1, 2, 4])
            >>> divide_rows(x, y)
            array([[0.  , 1.  , 2.  , 3.  ],
                   [2.  , 2.5 , 3.  , 3.5 ],
                   [2.  , 2.25, 2.5 , 2.75]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.broadcasting.html
        You should use one of:
            - np.reshape: https://numpy.org/doc/stable/reference/generated/numpy.reshape.html
            - np.newaxis: https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis
    
        Args:
          x: a matrix
          y: a vector with as many entries as x has rows
        Returns:
          a numpy matrix
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:168: NotImplementedError
--------------------------- Captured stdout teardown ---------------------------

======================
Output of autograder
======================
# of tests:	6/19 tests passed
Overall score:	4/100
======================
FAIL: test_train_test_split
FAIL: test_cross_validation
FAIL: test_decision_tree_binary_predict
FAIL: test_decision_tree_continuous_predict
FAIL: test_information_gain
FAIL: test_decision_tree_run
FAIL: test_predict_mode
FAIL: test_comparisons
FAIL: test_metrics
PASS: test_hello_world
PASS: test_numpy_replace_nonfinite_in_place
FAIL: test_numpy_replace_nans_out_of_place
FAIL: test_numpy_find_mode
FAIL: test_numpy_flip_and_slice_matrix
FAIL: test_numpy_divide_matrix_along_rows
======================
=============================== warnings summary ===============================
tests/test_data.py::test_load_data
  /Users/ankitaroychoudhury/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2
    warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/test_data.py::test_train_test_split - NotImplementedError
FAILED tests/test_data.py::test_cross_validation - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_binary_predict - NotIm...
FAILED tests/test_decision_tree.py::test_decision_tree_continuous_predict - N...
FAILED tests/test_decision_tree.py::test_information_gain - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_run - NotImplementedError
FAILED tests/test_experiment.py::test_predict_mode - NotImplementedError
FAILED tests/test_experiment.py::test_comparisons - NotImplementedError
FAILED tests/test_metrics.py::test_metrics - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_replace_nans_out_of_place - AssertionE...
FAILED tests/test_numpy.py::test_numpy_find_mode - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_flip_and_slice_matrix - NotImplemented...
FAILED tests/test_numpy.py::test_numpy_divide_matrix_along_rows - NotImplemen...
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % pytest
========================================== test session starts ==========================================
platform darwin -- Python 3.9.13, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury
plugins: anyio-3.5.0
collected 8 items / 3 errors                                                                            

================================================ ERRORS =================================================
_____________________________ ERROR collecting tests/test_decision_tree.py ______________________________
../../../../opt/anaconda3/lib/python3.9/site-packages/_pytest/python.py:608: in _importtestmodule
    mod = import_path(self.path, mode=importmode, root=self.config.rootpath)
../../../../opt/anaconda3/lib/python3.9/site-packages/_pytest/pathlib.py:533: in import_path
    importlib.import_module(module_name)
../../../../opt/anaconda3/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
../../../../opt/anaconda3/lib/python3.9/site-packages/_pytest/assertion/rewrite.py:168: in exec_module
    exec(co, module.__dict__)
tests/test_decision_tree.py:2: in <module>
    from src import run
src/__init__.py:2: in <module>
    from src.decision_tree import DecisionTree, information_gain
src/decision_tree.py:2: in <module>
    from src.numpy_practice import find_mode
E     File "/Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury/src/numpy_practice.py", line 78
E       return x[np.where(np.isnan(x))] = 0
E                                       ^
E   SyntaxError: invalid syntax
_______________________________ ERROR collecting tests/test_experiment.py _______________________________
../../../../opt/anaconda3/lib/python3.9/site-packages/_pytest/python.py:608: in _importtestmodule
    mod = import_path(self.path, mode=importmode, root=self.config.rootpath)
../../../../opt/anaconda3/lib/python3.9/site-packages/_pytest/pathlib.py:533: in import_path
    importlib.import_module(module_name)
../../../../opt/anaconda3/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
../../../../opt/anaconda3/lib/python3.9/site-packages/_pytest/assertion/rewrite.py:168: in exec_module
    exec(co, module.__dict__)
tests/test_experiment.py:2: in <module>
    from src import run
src/__init__.py:2: in <module>
    from src.decision_tree import DecisionTree, information_gain
src/decision_tree.py:2: in <module>
    from src.numpy_practice import find_mode
E     File "/Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury/src/numpy_practice.py", line 78
E       return x[np.where(np.isnan(x))] = 0
E                                       ^
E   SyntaxError: invalid syntax
_________________________________ ERROR collecting tests/test_numpy.py __________________________________
../../../../opt/anaconda3/lib/python3.9/site-packages/_pytest/python.py:608: in _importtestmodule
    mod = import_path(self.path, mode=importmode, root=self.config.rootpath)
../../../../opt/anaconda3/lib/python3.9/site-packages/_pytest/pathlib.py:533: in import_path
    importlib.import_module(module_name)
../../../../opt/anaconda3/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
../../../../opt/anaconda3/lib/python3.9/site-packages/_pytest/assertion/rewrite.py:168: in exec_module
    exec(co, module.__dict__)
tests/test_numpy.py:7: in <module>
    import src.numpy_practice
src/__init__.py:2: in <module>
    from src.decision_tree import DecisionTree, information_gain
src/decision_tree.py:2: in <module>
    from src.numpy_practice import find_mode
E     File "/Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury/src/numpy_practice.py", line 78
E       return x[np.where(np.isnan(x))] = 0
E                                       ^
E   SyntaxError: invalid syntax
======================================== short test summary info ========================================
ERROR tests/test_decision_tree.py
ERROR tests/test_experiment.py
ERROR tests/test_numpy.py
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 3 errors during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
=========================================== 3 errors in 0.47s ===========================================
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % pytest
========================================== test session starts ==========================================
platform darwin -- Python 3.9.13, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury
plugins: anyio-3.5.0
collected 20 items                                                                                      

tests/test_a_environment.py .                                                                     [  5%]
tests/test_a_setup.py ...                                                                         [ 20%]
tests/test_data.py .FF                                                                            [ 35%]
tests/test_decision_tree.py FFFF                                                                  [ 55%]
tests/test_experiment.py FF                                                                       [ 65%]
tests/test_metrics.py F                                                                           [ 70%]
tests/test_numpy.py ..FFFF                                                                        [100%]

=============================================== FAILURES ================================================
_________________________________________ test_train_test_split _________________________________________

    def test_train_test_split():
        from src import load_data
        from src import train_test_split
    
        n_features = np.random.randint(5, 20)
        n_samples = np.random.randint(50, 150)
        features, targets, attribute_names = write_random_csv_file(n_features, n_samples)
        fraction = np.random.rand()
    
>       output = train_test_split(features, targets, fraction)

tests/test_data.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

features = array([[-1.38006747e+00,  7.79601402e-01, -7.90518279e-01,
        -1.51066077e+00,  3.62546441e-02,  8.35277727e-01,
...-1.21771199e-01,
         4.68616472e-01, -8.94701790e-01,  8.94409646e-01,
        -2.25464357e-01, -9.88667134e-02]])
labels = array([0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,
       0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,
       1, 0, 0])
fraction = 0.3162473901831261

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
_________________________________________ test_cross_validation _________________________________________

    def test_cross_validation():
        from src import load_data
        from src import cross_validation
    
        # Remember, your train_test_split should be deterministic
        # You shouldn't be randomly shuffling the data!
        n = 10
        features = np.arange(n).reshape(-1, 1)
        targets = np.arange(n).reshape(-1, 1)
        for folds in [2, 5, 10]:
>           cv = cross_validation(features, targets, folds)

tests/test_data.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

features = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
labels = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
n_folds = 2

    def cross_validation(features, labels, n_folds):
        """
        Split the data in `n_folds` different groups for cross-validation.
            Split the features and labels into a `n_folds` number of groups that
            divide the data as evenly as possible. Then for each group,
            return a tuple that treats that group as the test set and all
            other groups combine to make the training set.
    
            Note that this should be *deterministic*; don't shuffle the data.
            If there are 100 examples and you have 5 folds, each group
            should contain 20 examples and the first group should contain
            the first 20 examples.
    
            See test_cross_validation for expected behavior.
    
        Args:
            features: an NxK matrix of N examples, each with K features
            labels: an Nx1 array of N labels
            n_folds: the number of cross-validation groups
    
        Output:
            A list of tuples, where each tuple contains:
              (train_features, train_labels, test_features, test_labels)
        """
    
        assert features.shape[0] == labels.shape[0]
    
        if n_folds == 1:
            return [(features, labels, features, labels)]
>       raise NotImplementedError
E       NotImplementedError

src/data.py:92: NotImplementedError
___________________________________ test_decision_tree_binary_predict ___________________________________

    def test_decision_tree_binary_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Outlook', 'Temp', 'Wind']
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Outlook", attribute_index=0,
            split_value=0.5, branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=0.5, branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
        examples = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [0, 1, 1]])
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <src.decision_tree.DecisionTree object at 0x7fd8120d58b0>
features = array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 1, 1],
       [0, 1, 1]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
_________________________________ test_decision_tree_continuous_predict _________________________________

    def test_decision_tree_continuous_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Wind', 'Temp', 'Outlook']
        examples = np.array([[1, 79.21, 1], [2, 90.56, 0], [7, 88.36, 1], [5, 84.02, 0], [1, 43.77, 0]])
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Wind", attribute_index=0,
            split_value=np.median(examples[:, 0]), branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=np.median(examples[:, 1]), branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
    
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <src.decision_tree.DecisionTree object at 0x7fd802257a90>
features = array([[ 1.  , 79.21,  1.  ],
       [ 2.  , 90.56,  0.  ],
       [ 7.  , 88.36,  1.  ],
       [ 5.  , 84.02,  0.  ],
       [ 1.  , 43.77,  0.  ]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
_________________________________________ test_information_gain _________________________________________

    def test_information_gain():
        from src import load_data
        from src import information_gain
    
        _features, _targets, _attribute_names = load_data('data/play-tennis.csv')
>       iGHumidity = information_gain(_features, 2, _targets)

tests/test_decision_tree.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

features = array([[0, 0, 1, 0],
       [0, 0, 1, 1],
       [1, 0, 1, 0],
       [1, 1, 1, 0],
       [1, 1, 0, 0],
       [1, 1,...[0, 1, 0, 0],
       [1, 1, 0, 0],
       [0, 1, 0, 1],
       [1, 1, 1, 1],
       [1, 0, 0, 0],
       [1, 1, 1, 1]])
attribute_index = 2
labels = array([[0],
       [0],
       [1],
       [1],
       [1],
       [0],
       [1],
       [0],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0]])

    def information_gain(features, attribute_index, labels):
        """
        Information gain is how a decision tree makes decisions on how to create
        split points in the tree. Information gain is measured in terms of entropy.
        The goal of a decision tree is to decrease entropy at each split point as
        much as possible. This function should work perfectly or your decision tree
        will not work properly.
    
        Information gain is a central concept in many machine learning algorithms.
        In decision trees, it captures how effective splitting the tree on a
        specific attribute will be for the goal of classifying the training data
        correctly.  Consider data points S and an attribute A; we'll split S into
        two data points.
    
        For binary A: S(A == 0) and S(A == 1)
        For continuous A: S(A < m) and S(A >= m), where m is the median of A in S.
    
        Together, the two subsets make up S. If the attribute A were perfectly correlated with
        the class of each data point in S, then all points in a given subset will have the
        same class. Clearly, in this case, we want something that captures that A is a good
        attribute to use in the decision tree. This something is information gain. Formally:
    
            IG(S,A) = H(S) - H(S|A)
    
        where H is information entropy. Recall that entropy captures how orderly or chaotic
        a system is. A system that is very chaotic will evenly distribute probabilities to
        all outcomes (e.g. 50% chance of class 0, 50% chance of class 1). Machine learning
        algorithms work to decrease entropy, so as to make predictions that are
        accurate on testing data. Formally, H is defined as:
    
            H(S) = sum_{c in (groups in S)} -p(c) * log_2 p(c)
    
        To elaborate: for each group c in S, you compute the probability (or weight) of c:
    
            p(c) = (# of elements of group c in S) / (total # of elements in S)
    
        Then you compute the term for this group:
    
            -p(c) * log_2 p(c)
    
        Note: if p(c) is 0, we define `-p(c) * log_2 p(c)` as 0. You can see how
            we handle this in the provided `entropy()` function, to avoid how numpy
            defines `0 * log(0) = 0 * -inf = nan`.
    
        Then compute the sum across all groups: either classes 0 and 1 for binary data, or
        for the above-median and below-median classes for continuous data. The final number
        is the entropy. To gain more intution about entropy, consider the following - what
        does H(S) = 0 tell you about S?
    
        Information gain is an extension of entropy. The equation for information gain
        involves comparing the entropy of the set and the entropy of the set when conditioned
        on selecting for a single attribute (e.g. S(A == 0)).
    
        For more details: https://en.wikipedia.org/wiki/ID3_algorithm#The_ID3_metrics
    
        Args:
            features (np.array): numpy array containing features for each example.
            attribute_index (int): which column of features to take when computing the
                information gain
            labels (np.array): numpy array containing labels corresponding to each example.
    
        Returns:
            information_gain (float): information gain if the features were split on the
                attribute_index.
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:262: NotImplementedError
________________________________________ test_decision_tree_run _________________________________________

    def test_decision_tree_run():
        goals = {
            'xor-easy.csv': {1.0: 1.0},
            'xor-hard.csv': {1.0: 0.8, 0.8: 1.0},
            'ivy-league.csv': {1.0: .9, 0.8: 0.6,},
            'majority-rule.csv': {1.0: 1.0, 0.8: 0.8,},
            'circles-hard.csv': {1.0: 0.7},
            'circles-easy.csv': {1.0: 0.8},
            'blobs.csv': {1.0: 0.8, 0.8: 0.9,},
        }
    
        order = [
            'xor-easy.csv',
            'ivy-league.csv',
            'majority-rule.csv',
            'xor-hard.csv',
            'blobs.csv',
            'circles-easy.csv',
            'circles-hard.csv',
        ]
    
        learner_type = 'decision_tree'
        for key in order:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_decision_tree.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
src/decision_tree.py:125: in fit
    self.tree = self._create_tree(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <src.decision_tree.DecisionTree object at 0x7fd810c15b50>
features = array([[1, 1],
       [0, 0],
       [1, 0],
       [0, 1]])
labels = array([[0],
       [0],
       [1],
       [1]]), used_attributes = [], default = 0

    def _create_tree(self, features, labels, used_attributes, default):
        '''
        Create a decision tree recursively.
        1. If no data remains, return a leaf node with return_value `default`
            (e.g., if features and labels are both empty)
    
        2. If all labels are the same, return a leaf node with
            that label as the return_value
    
        3. For each attribute, compute the information gain from splitting on it
    
        3.1. If that is in `used_attributes`, instead set information gain to -1
            to prevent us from reusing it
        3.2. If all attributes are used, return a leaf node with the mode class
    
        3.3.1 If at least one attribute, has a non-negative information gain,
            select `best_attribute` with the largest information gain;
        3.3.2 Split data (feature & label) according to attribute values,
            where: `attribute_values = features[:, best_attribute]`;
        3.3.3 If that attribute's values are binary, split on 0.5;
            Otherwise, split on the median of the attribute values;
    
        3.4 Create a non-leaf node with the specified attribute_name,
              attribute_index, and split_value, and then RECURSIVELY
              set build its branches using self._create_tree.
              After recursing, return the node.
        '''
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:160: NotImplementedError
___________________________________________ test_predict_mode ___________________________________________

    def test_predict_mode():
        goals = {
          'ivy-league.csv': {1.0: 0.5},
          'majority-rule.csv': {1.0: 0.6},
          'circles-easy.csv': {1.0: 0.6},
          'blobs.csv': {1.0: 0.55},
        }
    
        learner_type = 'predict_mode'
        for key in goals:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_experiment.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <src.predict_mode.PredictMode object at 0x7fd802261430>
features = array([[1, 1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 1, 0, 0]...      [0, 1, 1, 0, 1, 0, 1],
       [0, 1, 1, 0, 0, 1, 1],
       [0, 1, 1, 0, 0, 0, 1],
       [0, 1, 1, 0, 0, 1, 1]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0]...      [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0],
       [0]])

    def fit(self, features, labels):
        """
        Looking at the provided labels, record the mode (most common) label.
    
        You may call your `find_mode` function from `src.numpy_practice`
    
        Args:
            features (np.array): numpy array of shape (n, d)
                 where n is number of examples and d is number of features.
            labels (np.array): numpy array containing true labels for each of the N
                examples.
        Output:
            None: Simply update self.most_common_class with the most common label
        """
>       raise NotImplementedError
E       NotImplementedError

src/predict_mode.py:35: NotImplementedError
___________________________________________ test_comparisons ____________________________________________

    def test_comparisons():
        comparisons = [
            # predict_mode beats decision tree on majority rule w/ 0.7 frac
            ('majority-rule.csv', 0.7, 'predict_mode', 'decision_tree',
             {}, {}),
    
            # decision tree beats predict mode on majority rule w/ 1.0 frac
            ('majority-rule.csv', 1.0, 'decision_tree', 'predict_mode',
             {}, {}),
        ]
    
        for i, comparison in enumerate(comparisons):
            (key, fraction, method_a, method_b,
             kwargs_a, kwargs_b) = comparison
    
            data_path = datasets.get(key)
>           acc_a = run(data_path, method_a, fraction, **kwargs_a)

tests/test_experiment.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/experiment.py:55: in run
    X_train, Y_train, X_test, Y_test = train_test_split(X, Y, fraction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

features = array([[1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 0, 0],
       [1,... 1, 0, 0],
       [0, 0, 0, 0, 1, 1],
       [0, 0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0, 1],
       [0, 0, 0, 0, 0, 0]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [1],
       [1]...      [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0]])
fraction = 0.7

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
_____________________________________________ test_metrics ______________________________________________

    def test_metrics():
        from sklearn.metrics import accuracy_score
        from src import compute_accuracy
    
        y_true, y_pred = make_fake_data()
        _actual = accuracy_score(y_true, y_pred)
>       _est = compute_accuracy(y_true, y_pred)

tests/test_metrics.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

actual = array([ True,  True,  True,  True, False, False, False, False,  True,
        True, False, False,  True,  True, False,... True, False,  True, False,  True,
       False, False, False, False, False,  True,  True,  True,  True,
        True])
predictions = array([ True,  True,  True, False, False,  True, False,  True,  True,
       False,  True, False,  True, False, False,... True,  True, False, False,  True,
       False,  True,  True,  True,  True, False,  True, False, False,
        True])

    def compute_accuracy(actual, predictions):
        """
        Given predictions (an N-length numpy vector) and actual labels (an N-length
        numpy vector), compute the accuracy:
    
        Hint: implement and use the compute_confusion_matrix function!
    
        Args:
            actual (np.array): predicted labels of length N
            predictions (np.array): predicted labels of length N
    
        Output:
            accuracy (float): accuracy
        """
        if predictions.shape[0] != actual.shape[0]:
            raise ValueError("predictions and actual must be the same length!")
    
>       raise NotImplementedError
E       NotImplementedError

src/metrics.py:53: NotImplementedError
_________________________________ test_numpy_replace_nans_out_of_place __________________________________

    @pytest.mark.filterwarnings("ignore:divide by zero:RuntimeWarning")
    @pytest.mark.filterwarnings("ignore:invalid value encountered in divide:RuntimeWarning")
    def test_numpy_replace_nans_out_of_place():
    
        pairs = [
            (np.array([1, 2, 3, np.inf, 4, 5, np.nan, np.true_divide(-1, 0), 6]),
             np.array([1, 2, 3, np.inf, 4, 5, 0, -np.inf, 6])),
    
            (np.array([-1, 1, 0, -1, 1, 0]) / np.array([1, 0, 1, 0, 1, 0]),
             np.array([-1, np.inf, 0, -np.inf, 1, 0])),
        ]
    
        for before, after in pairs:
            before_copy = before.copy()
            retval = src.numpy_practice.replace_nans_out_of_place(before)
            assert np.array_equal(retval, after), "replace_nans_out_of_place should return answer"
>           assert np.array_equal(before, before_copy, equal_nan=True), f"{before} shouldn't be modified"
E           AssertionError: [  1.   2.   3.  inf   4.   5.   0. -inf   6.] shouldn't be modified
E           assert False
E            +  where False = <function array_equal at 0x7fd800b01d30>(array([  1.,   2.,   3.,  inf,   4.,   5.,   0., -inf,   6.]), array([  1.,   2.,   3.,  inf,   4.,   5.,  nan, -inf,   6.]), equal_nan=True)
E            +    where <function array_equal at 0x7fd800b01d30> = np.array_equal

tests/test_numpy.py:127: AssertionError
_________________________________________ test_numpy_find_mode __________________________________________

    def test_numpy_find_mode():
        pairs = [
            (np.array([1, 2, 2, 3, 3, 3]),
             3),
            (np.concatenate([np.arange(3, 7), np.arange(6, 0, -1), np.arange(1, 7, 3)]),
             4),
            (np.concatenate([np.zeros(10), np.ones(11)]),
             1)
        ]
        for arr, target in pairs:
>           assert src.numpy_practice.find_mode(arr) == target, f"Mode is {target}"

tests/test_numpy.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

x = array([1, 2, 2, 3, 3, 3])

    def find_mode(x):
        """
        In the given array, find the mode of the vector.
        The mode is the value that appears the most times (don't worry about ties).
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([1, 2, 2, 3, 3, 3])
            >>> find_mode(x)
            3
    
        You should use:
            - np.argmax: https://numpy.org/doc/stable/reference/generated/numpy.argmax.html
    
        You should use one of:
            - np.unique: https://numpy.org/doc/stable/reference/generated/numpy.unique.html
            - np.bincount: https://numpy.org/doc/stable/reference/generated/numpy.bincount.html
    
        Args:
            x: a numpy array of integers
        Returns:
            the mode of x
        """
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:108: NotImplementedError
___________________________________ test_numpy_flip_and_slice_matrix ____________________________________

    def test_numpy_flip_and_slice_matrix():
    
        pairs = [
            (np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]]),
             np.array([[2, 1, 0], [11, 10, 9]])),
            (np.array([[ 2,  6, 16, 18, 13, 13, 17]]).T,
             np.array([[2, 18, 17]]).T),
            (np.array([[ 0, 17, 14,  4]]),
             np.array([[ 4, 14, 17,  0]]))
        ]
        for before, after in pairs:
            msg = f"flip_and_slice_matrix({before}) should return {after}"
            before = before.astype(int)
>           assert np.array_equal(src.numpy_practice.flip_and_slice_matrix(before), after), msg

tests/test_numpy.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

x = array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11],
       [12, 13, 14]])

    def flip_and_slice_matrix(x):
        """
        Take the matrix x and flip it horizontally, then take the every third row.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2],
            ...               [ 3,  4,  5],
            ...               [ 6,  7,  8],
            ...               [ 9, 10, 11],
            ...               [12, 13, 14]])
            >>> flip_and_slice_matrix(x)
            array([[2, 1, 0],
                   [11, 10, 9]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.indexing.html#basics-indexing
    
        Args:
          x: a matrix
        Returns:
          a numpy matrix
        """
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:136: NotImplementedError
__________________________________ test_numpy_divide_matrix_along_rows __________________________________

    def test_numpy_divide_matrix_along_rows():
    
        trios = [
            (np.array([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]),
             np.array([1, 2, 4]),
             np.array([[0, 1, 2, 3], [2, 2.5, 3, 3.5], [2, 2.25, 2.5, 2.75]])),
            (np.array([[2, 14], [2, 17], [8, 8], [12, 9], [9, 6], [10, 4]]),
             np.array([1, 1, 2, 3, 3, 2]),
             np.array([[2, 14], [2, 17], [4, 4], [4, 3], [3, 2], [5, 2]]))
        ]
        for (x, y, target) in trios:
            msg = f"divide_matrix_along_rows({x}, {y}) should return {target}"
>           assert np.array_equal(src.numpy_practice.divide_matrix_along_rows(x, y), target), msg

tests/test_numpy.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

x = array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]]), y = array([1, 2, 4])

    def divide_matrix_along_rows(x, y):
        """
        Take the matrix x and divide it by the vector y, such that
            the ith row of x is divided by the ith value of y.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2,  3],
            ...               [ 4,  5,  6,  7],
            ...               [ 8,  9, 10, 11]])
            >>> y = np.array([1, 2, 4])
            >>> divide_rows(x, y)
            array([[0.  , 1.  , 2.  , 3.  ],
                   [2.  , 2.5 , 3.  , 3.5 ],
                   [2.  , 2.25, 2.5 , 2.75]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.broadcasting.html
        You should use one of:
            - np.reshape: https://numpy.org/doc/stable/reference/generated/numpy.reshape.html
            - np.newaxis: https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis
    
        Args:
          x: a matrix
          y: a vector with as many entries as x has rows
        Returns:
          a numpy matrix
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:170: NotImplementedError
--------------------------------------- Captured stdout teardown ----------------------------------------

======================
Output of autograder
======================
# of tests:	6/19 tests passed
Overall score:	4/100
======================
FAIL: test_train_test_split
FAIL: test_cross_validation
FAIL: test_decision_tree_binary_predict
FAIL: test_decision_tree_continuous_predict
FAIL: test_information_gain
FAIL: test_decision_tree_run
FAIL: test_predict_mode
FAIL: test_comparisons
FAIL: test_metrics
PASS: test_hello_world
PASS: test_numpy_replace_nonfinite_in_place
FAIL: test_numpy_replace_nans_out_of_place
FAIL: test_numpy_find_mode
FAIL: test_numpy_flip_and_slice_matrix
FAIL: test_numpy_divide_matrix_along_rows
======================
=========================================== warnings summary ============================================
tests/test_data.py::test_load_data
  /Users/ankitaroychoudhury/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2
    warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================================== short test summary info ========================================
FAILED tests/test_data.py::test_train_test_split - NotImplementedError
FAILED tests/test_data.py::test_cross_validation - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_binary_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_continuous_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_information_gain - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_run - NotImplementedError
FAILED tests/test_experiment.py::test_predict_mode - NotImplementedError
FAILED tests/test_experiment.py::test_comparisons - NotImplementedError
FAILED tests/test_metrics.py::test_metrics - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_replace_nans_out_of_place - AssertionError: [  1.   2.   3.  in...
FAILED tests/test_numpy.py::test_numpy_find_mode - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_flip_and_slice_matrix - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_divide_matrix_along_rows - NotImplementedError
================================ 13 failed, 7 passed, 1 warning in 1.59s ================================
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % pytest
============================================ test session starts =============================================
platform darwin -- Python 3.9.13, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury
plugins: anyio-3.5.0
collected 20 items                                                                                           

tests/test_a_environment.py .                                                                          [  5%]
tests/test_a_setup.py ...                                                                              [ 20%]
tests/test_data.py .FF                                                                                 [ 35%]
tests/test_decision_tree.py FFFF                                                                       [ 55%]
tests/test_experiment.py FF                                                                            [ 65%]
tests/test_metrics.py F                                                                                [ 70%]
tests/test_numpy.py ..FFFF                                                                             [100%]

================================================== FAILURES ==================================================
___________________________________________ test_train_test_split ____________________________________________

    def test_train_test_split():
        from src import load_data
        from src import train_test_split
    
        n_features = np.random.randint(5, 20)
        n_samples = np.random.randint(50, 150)
        features, targets, attribute_names = write_random_csv_file(n_features, n_samples)
        fraction = np.random.rand()
    
>       output = train_test_split(features, targets, fraction)

tests/test_data.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[ 0.7947512 , -1.91801147, -0.40565652, ..., -1.6236317 ,
        -2.18029883, -0.49707764],
       [ 1.9933657...587, -0.83653745],
       [ 0.13794725, -0.78629334, -0.44441852, ...,  0.88269116,
         1.70078618, -0.52866436]])
labels = array([0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,...    0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,
       1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1])
fraction = 0.4253110757565195

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
___________________________________________ test_cross_validation ____________________________________________

    def test_cross_validation():
        from src import load_data
        from src import cross_validation
    
        # Remember, your train_test_split should be deterministic
        # You shouldn't be randomly shuffling the data!
        n = 10
        features = np.arange(n).reshape(-1, 1)
        targets = np.arange(n).reshape(-1, 1)
        for folds in [2, 5, 10]:
>           cv = cross_validation(features, targets, folds)

tests/test_data.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
labels = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
n_folds = 2

    def cross_validation(features, labels, n_folds):
        """
        Split the data in `n_folds` different groups for cross-validation.
            Split the features and labels into a `n_folds` number of groups that
            divide the data as evenly as possible. Then for each group,
            return a tuple that treats that group as the test set and all
            other groups combine to make the training set.
    
            Note that this should be *deterministic*; don't shuffle the data.
            If there are 100 examples and you have 5 folds, each group
            should contain 20 examples and the first group should contain
            the first 20 examples.
    
            See test_cross_validation for expected behavior.
    
        Args:
            features: an NxK matrix of N examples, each with K features
            labels: an Nx1 array of N labels
            n_folds: the number of cross-validation groups
    
        Output:
            A list of tuples, where each tuple contains:
              (train_features, train_labels, test_features, test_labels)
        """
    
        assert features.shape[0] == labels.shape[0]
    
        if n_folds == 1:
            return [(features, labels, features, labels)]
>       raise NotImplementedError
E       NotImplementedError

src/data.py:92: NotImplementedError
_____________________________________ test_decision_tree_binary_predict ______________________________________

    def test_decision_tree_binary_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Outlook', 'Temp', 'Wind']
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Outlook", attribute_index=0,
            split_value=0.5, branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=0.5, branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
        examples = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [0, 1, 1]])
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fdba984a040>
features = array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 1, 1],
       [0, 1, 1]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________ test_decision_tree_continuous_predict ____________________________________

    def test_decision_tree_continuous_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Wind', 'Temp', 'Outlook']
        examples = np.array([[1, 79.21, 1], [2, 90.56, 0], [7, 88.36, 1], [5, 84.02, 0], [1, 43.77, 0]])
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Wind", attribute_index=0,
            split_value=np.median(examples[:, 0]), branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=np.median(examples[:, 1]), branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
    
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fdba9848d60>
features = array([[ 1.  , 79.21,  1.  ],
       [ 2.  , 90.56,  0.  ],
       [ 7.  , 88.36,  1.  ],
       [ 5.  , 84.02,  0.  ],
       [ 1.  , 43.77,  0.  ]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________________ test_information_gain ____________________________________________

    def test_information_gain():
        from src import load_data
        from src import information_gain
    
        _features, _targets, _attribute_names = load_data('data/play-tennis.csv')
>       iGHumidity = information_gain(_features, 2, _targets)

tests/test_decision_tree.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0, 0, 1, 0],
       [0, 0, 1, 1],
       [1, 0, 1, 0],
       [1, 1, 1, 0],
       [1, 1, 0, 0],
       [1, 1,...[0, 1, 0, 0],
       [1, 1, 0, 0],
       [0, 1, 0, 1],
       [1, 1, 1, 1],
       [1, 0, 0, 0],
       [1, 1, 1, 1]])
attribute_index = 2
labels = array([[0],
       [0],
       [1],
       [1],
       [1],
       [0],
       [1],
       [0],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0]])

    def information_gain(features, attribute_index, labels):
        """
        Information gain is how a decision tree makes decisions on how to create
        split points in the tree. Information gain is measured in terms of entropy.
        The goal of a decision tree is to decrease entropy at each split point as
        much as possible. This function should work perfectly or your decision tree
        will not work properly.
    
        Information gain is a central concept in many machine learning algorithms.
        In decision trees, it captures how effective splitting the tree on a
        specific attribute will be for the goal of classifying the training data
        correctly.  Consider data points S and an attribute A; we'll split S into
        two data points.
    
        For binary A: S(A == 0) and S(A == 1)
        For continuous A: S(A < m) and S(A >= m), where m is the median of A in S.
    
        Together, the two subsets make up S. If the attribute A were perfectly correlated with
        the class of each data point in S, then all points in a given subset will have the
        same class. Clearly, in this case, we want something that captures that A is a good
        attribute to use in the decision tree. This something is information gain. Formally:
    
            IG(S,A) = H(S) - H(S|A)
    
        where H is information entropy. Recall that entropy captures how orderly or chaotic
        a system is. A system that is very chaotic will evenly distribute probabilities to
        all outcomes (e.g. 50% chance of class 0, 50% chance of class 1). Machine learning
        algorithms work to decrease entropy, so as to make predictions that are
        accurate on testing data. Formally, H is defined as:
    
            H(S) = sum_{c in (groups in S)} -p(c) * log_2 p(c)
    
        To elaborate: for each group c in S, you compute the probability (or weight) of c:
    
            p(c) = (# of elements of group c in S) / (total # of elements in S)
    
        Then you compute the term for this group:
    
            -p(c) * log_2 p(c)
    
        Note: if p(c) is 0, we define `-p(c) * log_2 p(c)` as 0. You can see how
            we handle this in the provided `entropy()` function, to avoid how numpy
            defines `0 * log(0) = 0 * -inf = nan`.
    
        Then compute the sum across all groups: either classes 0 and 1 for binary data, or
        for the above-median and below-median classes for continuous data. The final number
        is the entropy. To gain more intution about entropy, consider the following - what
        does H(S) = 0 tell you about S?
    
        Information gain is an extension of entropy. The equation for information gain
        involves comparing the entropy of the set and the entropy of the set when conditioned
        on selecting for a single attribute (e.g. S(A == 0)).
    
        For more details: https://en.wikipedia.org/wiki/ID3_algorithm#The_ID3_metrics
    
        Args:
            features (np.array): numpy array containing features for each example.
            attribute_index (int): which column of features to take when computing the
                information gain
            labels (np.array): numpy array containing labels corresponding to each example.
    
        Returns:
            information_gain (float): information gain if the features were split on the
                attribute_index.
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:262: NotImplementedError
___________________________________________ test_decision_tree_run ___________________________________________

    def test_decision_tree_run():
        goals = {
            'xor-easy.csv': {1.0: 1.0},
            'xor-hard.csv': {1.0: 0.8, 0.8: 1.0},
            'ivy-league.csv': {1.0: .9, 0.8: 0.6,},
            'majority-rule.csv': {1.0: 1.0, 0.8: 0.8,},
            'circles-hard.csv': {1.0: 0.7},
            'circles-easy.csv': {1.0: 0.8},
            'blobs.csv': {1.0: 0.8, 0.8: 0.9,},
        }
    
        order = [
            'xor-easy.csv',
            'ivy-league.csv',
            'majority-rule.csv',
            'xor-hard.csv',
            'blobs.csv',
            'circles-easy.csv',
            'circles-hard.csv',
        ]
    
        learner_type = 'decision_tree'
        for key in order:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_decision_tree.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
src/decision_tree.py:125: in fit
    self.tree = self._create_tree(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fdba987ec70>
features = array([[1, 1],
       [0, 0],
       [1, 0],
       [0, 1]])
labels = array([[0],
       [0],
       [1],
       [1]]), used_attributes = [], default = 0

    def _create_tree(self, features, labels, used_attributes, default):
        '''
        Create a decision tree recursively.
        1. If no data remains, return a leaf node with return_value `default`
            (e.g., if features and labels are both empty)
    
        2. If all labels are the same, return a leaf node with
            that label as the return_value
    
        3. For each attribute, compute the information gain from splitting on it
    
        3.1. If that is in `used_attributes`, instead set information gain to -1
            to prevent us from reusing it
        3.2. If all attributes are used, return a leaf node with the mode class
    
        3.3.1 If at least one attribute, has a non-negative information gain,
            select `best_attribute` with the largest information gain;
        3.3.2 Split data (feature & label) according to attribute values,
            where: `attribute_values = features[:, best_attribute]`;
        3.3.3 If that attribute's values are binary, split on 0.5;
            Otherwise, split on the median of the attribute values;
    
        3.4 Create a non-leaf node with the specified attribute_name,
              attribute_index, and split_value, and then RECURSIVELY
              set build its branches using self._create_tree.
              After recursing, return the node.
        '''
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:160: NotImplementedError
_____________________________________________ test_predict_mode ______________________________________________

    def test_predict_mode():
        goals = {
          'ivy-league.csv': {1.0: 0.5},
          'majority-rule.csv': {1.0: 0.6},
          'circles-easy.csv': {1.0: 0.6},
          'blobs.csv': {1.0: 0.55},
        }
    
        learner_type = 'predict_mode'
        for key in goals:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_experiment.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.predict_mode.PredictMode object at 0x7fdba941ac70>
features = array([[1, 1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 1, 0, 0]...      [0, 1, 1, 0, 1, 0, 1],
       [0, 1, 1, 0, 0, 1, 1],
       [0, 1, 1, 0, 0, 0, 1],
       [0, 1, 1, 0, 0, 1, 1]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0]...      [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0],
       [0]])

    def fit(self, features, labels):
        """
        Looking at the provided labels, record the mode (most common) label.
    
        You may call your `find_mode` function from `src.numpy_practice`
    
        Args:
            features (np.array): numpy array of shape (n, d)
                 where n is number of examples and d is number of features.
            labels (np.array): numpy array containing true labels for each of the N
                examples.
        Output:
            None: Simply update self.most_common_class with the most common label
        """
>       raise NotImplementedError
E       NotImplementedError

src/predict_mode.py:35: NotImplementedError
______________________________________________ test_comparisons ______________________________________________

    def test_comparisons():
        comparisons = [
            # predict_mode beats decision tree on majority rule w/ 0.7 frac
            ('majority-rule.csv', 0.7, 'predict_mode', 'decision_tree',
             {}, {}),
    
            # decision tree beats predict mode on majority rule w/ 1.0 frac
            ('majority-rule.csv', 1.0, 'decision_tree', 'predict_mode',
             {}, {}),
        ]
    
        for i, comparison in enumerate(comparisons):
            (key, fraction, method_a, method_b,
             kwargs_a, kwargs_b) = comparison
    
            data_path = datasets.get(key)
>           acc_a = run(data_path, method_a, fraction, **kwargs_a)

tests/test_experiment.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:55: in run
    X_train, Y_train, X_test, Y_test = train_test_split(X, Y, fraction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 0, 0],
       [1,... 1, 0, 0],
       [0, 0, 0, 0, 1, 1],
       [0, 0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0, 1],
       [0, 0, 0, 0, 0, 0]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [1],
       [1]...      [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0]])
fraction = 0.7

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
________________________________________________ test_metrics ________________________________________________

    def test_metrics():
        from sklearn.metrics import accuracy_score
        from src import compute_accuracy
    
        y_true, y_pred = make_fake_data()
        _actual = accuracy_score(y_true, y_pred)
>       _est = compute_accuracy(y_true, y_pred)

tests/test_metrics.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = array([ True, False,  True, False, False, False, False, False,  True,
        True, False, False,  True, False,  True,...False, False, False,  True,  True,
       False,  True, False,  True, False,  True,  True,  True,  True,
       False])
predictions = array([ True,  True,  True,  True, False, False, False, False,  True,
       False, False,  True, False, False, False,... True,  True, False,  True,  True,
        True,  True, False,  True, False,  True,  True,  True, False,
       False])

    def compute_accuracy(actual, predictions):
        """
        Given predictions (an N-length numpy vector) and actual labels (an N-length
        numpy vector), compute the accuracy:
    
        Hint: implement and use the compute_confusion_matrix function!
    
        Args:
            actual (np.array): predicted labels of length N
            predictions (np.array): predicted labels of length N
    
        Output:
            accuracy (float): accuracy
        """
        if predictions.shape[0] != actual.shape[0]:
            raise ValueError("predictions and actual must be the same length!")
    
>       raise NotImplementedError
E       NotImplementedError

src/metrics.py:53: NotImplementedError
____________________________________ test_numpy_replace_nans_out_of_place ____________________________________

    @pytest.mark.filterwarnings("ignore:divide by zero:RuntimeWarning")
    @pytest.mark.filterwarnings("ignore:invalid value encountered in divide:RuntimeWarning")
    def test_numpy_replace_nans_out_of_place():
    
        pairs = [
            (np.array([1, 2, 3, np.inf, 4, 5, np.nan, np.true_divide(-1, 0), 6]),
             np.array([1, 2, 3, np.inf, 4, 5, 0, -np.inf, 6])),
    
            (np.array([-1, 1, 0, -1, 1, 0]) / np.array([1, 0, 1, 0, 1, 0]),
             np.array([-1, np.inf, 0, -np.inf, 1, 0])),
        ]
    
        for before, after in pairs:
            before_copy = before.copy()
            retval = src.numpy_practice.replace_nans_out_of_place(before)
>           assert np.array_equal(retval, after), "replace_nans_out_of_place should return answer"
E           AssertionError: replace_nans_out_of_place should return answer
E           assert False
E            +  where False = <function array_equal at 0x7fdbb8c49d30>(array([  1.,   2.,   3.,  inf,   4.,   5.,  nan, -inf,   6.]), array([  1.,   2.,   3.,  inf,   4.,   5.,   0., -inf,   6.]))
E            +    where <function array_equal at 0x7fdbb8c49d30> = np.array_equal

tests/test_numpy.py:126: AssertionError
____________________________________________ test_numpy_find_mode ____________________________________________

    def test_numpy_find_mode():
        pairs = [
            (np.array([1, 2, 2, 3, 3, 3]),
             3),
            (np.concatenate([np.arange(3, 7), np.arange(6, 0, -1), np.arange(1, 7, 3)]),
             4),
            (np.concatenate([np.zeros(10), np.ones(11)]),
             1)
        ]
        for arr, target in pairs:
>           assert src.numpy_practice.find_mode(arr) == target, f"Mode is {target}"

tests/test_numpy.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([1, 2, 2, 3, 3, 3])

    def find_mode(x):
        """
        In the given array, find the mode of the vector.
        The mode is the value that appears the most times (don't worry about ties).
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([1, 2, 2, 3, 3, 3])
            >>> find_mode(x)
            3
    
        You should use:
            - np.argmax: https://numpy.org/doc/stable/reference/generated/numpy.argmax.html
    
        You should use one of:
            - np.unique: https://numpy.org/doc/stable/reference/generated/numpy.unique.html
            - np.bincount: https://numpy.org/doc/stable/reference/generated/numpy.bincount.html
    
        Args:
            x: a numpy array of integers
        Returns:
            the mode of x
        """
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:108: NotImplementedError
______________________________________ test_numpy_flip_and_slice_matrix ______________________________________

    def test_numpy_flip_and_slice_matrix():
    
        pairs = [
            (np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]]),
             np.array([[2, 1, 0], [11, 10, 9]])),
            (np.array([[ 2,  6, 16, 18, 13, 13, 17]]).T,
             np.array([[2, 18, 17]]).T),
            (np.array([[ 0, 17, 14,  4]]),
             np.array([[ 4, 14, 17,  0]]))
        ]
        for before, after in pairs:
            msg = f"flip_and_slice_matrix({before}) should return {after}"
            before = before.astype(int)
>           assert np.array_equal(src.numpy_practice.flip_and_slice_matrix(before), after), msg

tests/test_numpy.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11],
       [12, 13, 14]])

    def flip_and_slice_matrix(x):
        """
        Take the matrix x and flip it horizontally, then take the every third row.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2],
            ...               [ 3,  4,  5],
            ...               [ 6,  7,  8],
            ...               [ 9, 10, 11],
            ...               [12, 13, 14]])
            >>> flip_and_slice_matrix(x)
            array([[2, 1, 0],
                   [11, 10, 9]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.indexing.html#basics-indexing
    
        Args:
          x: a matrix
        Returns:
          a numpy matrix
        """
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:136: NotImplementedError
____________________________________ test_numpy_divide_matrix_along_rows _____________________________________

    def test_numpy_divide_matrix_along_rows():
    
        trios = [
            (np.array([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]),
             np.array([1, 2, 4]),
             np.array([[0, 1, 2, 3], [2, 2.5, 3, 3.5], [2, 2.25, 2.5, 2.75]])),
            (np.array([[2, 14], [2, 17], [8, 8], [12, 9], [9, 6], [10, 4]]),
             np.array([1, 1, 2, 3, 3, 2]),
             np.array([[2, 14], [2, 17], [4, 4], [4, 3], [3, 2], [5, 2]]))
        ]
        for (x, y, target) in trios:
            msg = f"divide_matrix_along_rows({x}, {y}) should return {target}"
>           assert np.array_equal(src.numpy_practice.divide_matrix_along_rows(x, y), target), msg

tests/test_numpy.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]]), y = array([1, 2, 4])

    def divide_matrix_along_rows(x, y):
        """
        Take the matrix x and divide it by the vector y, such that
            the ith row of x is divided by the ith value of y.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2,  3],
            ...               [ 4,  5,  6,  7],
            ...               [ 8,  9, 10, 11]])
            >>> y = np.array([1, 2, 4])
            >>> divide_rows(x, y)
            array([[0.  , 1.  , 2.  , 3.  ],
                   [2.  , 2.5 , 3.  , 3.5 ],
                   [2.  , 2.25, 2.5 , 2.75]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.broadcasting.html
        You should use one of:
            - np.reshape: https://numpy.org/doc/stable/reference/generated/numpy.reshape.html
            - np.newaxis: https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis
    
        Args:
          x: a matrix
          y: a vector with as many entries as x has rows
        Returns:
          a numpy matrix
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:170: NotImplementedError
------------------------------------------ Captured stdout teardown ------------------------------------------

======================
Output of autograder
======================
# of tests:	6/19 tests passed
Overall score:	4/100
======================
FAIL: test_train_test_split
FAIL: test_cross_validation
FAIL: test_decision_tree_binary_predict
FAIL: test_decision_tree_continuous_predict
FAIL: test_information_gain
FAIL: test_decision_tree_run
FAIL: test_predict_mode
FAIL: test_comparisons
FAIL: test_metrics
PASS: test_hello_world
PASS: test_numpy_replace_nonfinite_in_place
FAIL: test_numpy_replace_nans_out_of_place
FAIL: test_numpy_find_mode
FAIL: test_numpy_flip_and_slice_matrix
FAIL: test_numpy_divide_matrix_along_rows
======================
============================================== warnings summary ==============================================
tests/test_data.py::test_load_data
  /Users/ankitaroychoudhury/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2
    warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================================== short test summary info ===========================================
FAILED tests/test_data.py::test_train_test_split - NotImplementedError
FAILED tests/test_data.py::test_cross_validation - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_binary_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_continuous_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_information_gain - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_run - NotImplementedError
FAILED tests/test_experiment.py::test_predict_mode - NotImplementedError
FAILED tests/test_experiment.py::test_comparisons - NotImplementedError
FAILED tests/test_metrics.py::test_metrics - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_replace_nans_out_of_place - AssertionError: replace_nans_out_of_plac...
FAILED tests/test_numpy.py::test_numpy_find_mode - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_flip_and_slice_matrix - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_divide_matrix_along_rows - NotImplementedError
================================== 13 failed, 7 passed, 1 warning in 1.61s ===================================
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % pytest
============================================ test session starts =============================================
platform darwin -- Python 3.9.13, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury
plugins: anyio-3.5.0
collected 20 items                                                                                           

tests/test_a_environment.py .                                                                          [  5%]
tests/test_a_setup.py ...                                                                              [ 20%]
tests/test_data.py .FF                                                                                 [ 35%]
tests/test_decision_tree.py FFFF                                                                       [ 55%]
tests/test_experiment.py FF                                                                            [ 65%]
tests/test_metrics.py F                                                                                [ 70%]
tests/test_numpy.py ..FFFF                                                                             [100%]

================================================== FAILURES ==================================================
___________________________________________ test_train_test_split ____________________________________________

    def test_train_test_split():
        from src import load_data
        from src import train_test_split
    
        n_features = np.random.randint(5, 20)
        n_samples = np.random.randint(50, 150)
        features, targets, attribute_names = write_random_csv_file(n_features, n_samples)
        fraction = np.random.rand()
    
>       output = train_test_split(features, targets, fraction)

tests/test_data.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[ 0.23642867, -1.16233274, -1.00205262, ...,  0.20708846,
         1.93466744,  0.69638286],
       [ 0.2452649...731, -0.47259985],
       [ 0.03613034,  0.87047808, -1.70738497, ..., -0.39917817,
         0.43006446, -0.42368779]])
labels = array([0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,
       1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,...1, 0,
       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,
       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0])
fraction = 0.1714208977062316

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
___________________________________________ test_cross_validation ____________________________________________

    def test_cross_validation():
        from src import load_data
        from src import cross_validation
    
        # Remember, your train_test_split should be deterministic
        # You shouldn't be randomly shuffling the data!
        n = 10
        features = np.arange(n).reshape(-1, 1)
        targets = np.arange(n).reshape(-1, 1)
        for folds in [2, 5, 10]:
>           cv = cross_validation(features, targets, folds)

tests/test_data.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
labels = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
n_folds = 2

    def cross_validation(features, labels, n_folds):
        """
        Split the data in `n_folds` different groups for cross-validation.
            Split the features and labels into a `n_folds` number of groups that
            divide the data as evenly as possible. Then for each group,
            return a tuple that treats that group as the test set and all
            other groups combine to make the training set.
    
            Note that this should be *deterministic*; don't shuffle the data.
            If there are 100 examples and you have 5 folds, each group
            should contain 20 examples and the first group should contain
            the first 20 examples.
    
            See test_cross_validation for expected behavior.
    
        Args:
            features: an NxK matrix of N examples, each with K features
            labels: an Nx1 array of N labels
            n_folds: the number of cross-validation groups
    
        Output:
            A list of tuples, where each tuple contains:
              (train_features, train_labels, test_features, test_labels)
        """
    
        assert features.shape[0] == labels.shape[0]
    
        if n_folds == 1:
            return [(features, labels, features, labels)]
>       raise NotImplementedError
E       NotImplementedError

src/data.py:92: NotImplementedError
_____________________________________ test_decision_tree_binary_predict ______________________________________

    def test_decision_tree_binary_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Outlook', 'Temp', 'Wind']
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Outlook", attribute_index=0,
            split_value=0.5, branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=0.5, branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
        examples = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [0, 1, 1]])
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7f950a6c9400>
features = array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 1, 1],
       [0, 1, 1]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________ test_decision_tree_continuous_predict ____________________________________

    def test_decision_tree_continuous_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Wind', 'Temp', 'Outlook']
        examples = np.array([[1, 79.21, 1], [2, 90.56, 0], [7, 88.36, 1], [5, 84.02, 0], [1, 43.77, 0]])
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Wind", attribute_index=0,
            split_value=np.median(examples[:, 0]), branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=np.median(examples[:, 1]), branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
    
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7f950a6b4c70>
features = array([[ 1.  , 79.21,  1.  ],
       [ 2.  , 90.56,  0.  ],
       [ 7.  , 88.36,  1.  ],
       [ 5.  , 84.02,  0.  ],
       [ 1.  , 43.77,  0.  ]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________________ test_information_gain ____________________________________________

    def test_information_gain():
        from src import load_data
        from src import information_gain
    
        _features, _targets, _attribute_names = load_data('data/play-tennis.csv')
>       iGHumidity = information_gain(_features, 2, _targets)

tests/test_decision_tree.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0, 0, 1, 0],
       [0, 0, 1, 1],
       [1, 0, 1, 0],
       [1, 1, 1, 0],
       [1, 1, 0, 0],
       [1, 1,...[0, 1, 0, 0],
       [1, 1, 0, 0],
       [0, 1, 0, 1],
       [1, 1, 1, 1],
       [1, 0, 0, 0],
       [1, 1, 1, 1]])
attribute_index = 2
labels = array([[0],
       [0],
       [1],
       [1],
       [1],
       [0],
       [1],
       [0],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0]])

    def information_gain(features, attribute_index, labels):
        """
        Information gain is how a decision tree makes decisions on how to create
        split points in the tree. Information gain is measured in terms of entropy.
        The goal of a decision tree is to decrease entropy at each split point as
        much as possible. This function should work perfectly or your decision tree
        will not work properly.
    
        Information gain is a central concept in many machine learning algorithms.
        In decision trees, it captures how effective splitting the tree on a
        specific attribute will be for the goal of classifying the training data
        correctly.  Consider data points S and an attribute A; we'll split S into
        two data points.
    
        For binary A: S(A == 0) and S(A == 1)
        For continuous A: S(A < m) and S(A >= m), where m is the median of A in S.
    
        Together, the two subsets make up S. If the attribute A were perfectly correlated with
        the class of each data point in S, then all points in a given subset will have the
        same class. Clearly, in this case, we want something that captures that A is a good
        attribute to use in the decision tree. This something is information gain. Formally:
    
            IG(S,A) = H(S) - H(S|A)
    
        where H is information entropy. Recall that entropy captures how orderly or chaotic
        a system is. A system that is very chaotic will evenly distribute probabilities to
        all outcomes (e.g. 50% chance of class 0, 50% chance of class 1). Machine learning
        algorithms work to decrease entropy, so as to make predictions that are
        accurate on testing data. Formally, H is defined as:
    
            H(S) = sum_{c in (groups in S)} -p(c) * log_2 p(c)
    
        To elaborate: for each group c in S, you compute the probability (or weight) of c:
    
            p(c) = (# of elements of group c in S) / (total # of elements in S)
    
        Then you compute the term for this group:
    
            -p(c) * log_2 p(c)
    
        Note: if p(c) is 0, we define `-p(c) * log_2 p(c)` as 0. You can see how
            we handle this in the provided `entropy()` function, to avoid how numpy
            defines `0 * log(0) = 0 * -inf = nan`.
    
        Then compute the sum across all groups: either classes 0 and 1 for binary data, or
        for the above-median and below-median classes for continuous data. The final number
        is the entropy. To gain more intution about entropy, consider the following - what
        does H(S) = 0 tell you about S?
    
        Information gain is an extension of entropy. The equation for information gain
        involves comparing the entropy of the set and the entropy of the set when conditioned
        on selecting for a single attribute (e.g. S(A == 0)).
    
        For more details: https://en.wikipedia.org/wiki/ID3_algorithm#The_ID3_metrics
    
        Args:
            features (np.array): numpy array containing features for each example.
            attribute_index (int): which column of features to take when computing the
                information gain
            labels (np.array): numpy array containing labels corresponding to each example.
    
        Returns:
            information_gain (float): information gain if the features were split on the
                attribute_index.
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:262: NotImplementedError
___________________________________________ test_decision_tree_run ___________________________________________

    def test_decision_tree_run():
        goals = {
            'xor-easy.csv': {1.0: 1.0},
            'xor-hard.csv': {1.0: 0.8, 0.8: 1.0},
            'ivy-league.csv': {1.0: .9, 0.8: 0.6,},
            'majority-rule.csv': {1.0: 1.0, 0.8: 0.8,},
            'circles-hard.csv': {1.0: 0.7},
            'circles-easy.csv': {1.0: 0.8},
            'blobs.csv': {1.0: 0.8, 0.8: 0.9,},
        }
    
        order = [
            'xor-easy.csv',
            'ivy-league.csv',
            'majority-rule.csv',
            'xor-hard.csv',
            'blobs.csv',
            'circles-easy.csv',
            'circles-hard.csv',
        ]
    
        learner_type = 'decision_tree'
        for key in order:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_decision_tree.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
src/decision_tree.py:125: in fit
    self.tree = self._create_tree(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7f9519bc27c0>
features = array([[1, 1],
       [0, 0],
       [1, 0],
       [0, 1]])
labels = array([[0],
       [0],
       [1],
       [1]]), used_attributes = [], default = 0

    def _create_tree(self, features, labels, used_attributes, default):
        '''
        Create a decision tree recursively.
        1. If no data remains, return a leaf node with return_value `default`
            (e.g., if features and labels are both empty)
    
        2. If all labels are the same, return a leaf node with
            that label as the return_value
    
        3. For each attribute, compute the information gain from splitting on it
    
        3.1. If that is in `used_attributes`, instead set information gain to -1
            to prevent us from reusing it
        3.2. If all attributes are used, return a leaf node with the mode class
    
        3.3.1 If at least one attribute, has a non-negative information gain,
            select `best_attribute` with the largest information gain;
        3.3.2 Split data (feature & label) according to attribute values,
            where: `attribute_values = features[:, best_attribute]`;
        3.3.3 If that attribute's values are binary, split on 0.5;
            Otherwise, split on the median of the attribute values;
    
        3.4 Create a non-leaf node with the specified attribute_name,
              attribute_index, and split_value, and then RECURSIVELY
              set build its branches using self._create_tree.
              After recursing, return the node.
        '''
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:160: NotImplementedError
_____________________________________________ test_predict_mode ______________________________________________

    def test_predict_mode():
        goals = {
          'ivy-league.csv': {1.0: 0.5},
          'majority-rule.csv': {1.0: 0.6},
          'circles-easy.csv': {1.0: 0.6},
          'blobs.csv': {1.0: 0.55},
        }
    
        learner_type = 'predict_mode'
        for key in goals:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_experiment.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.predict_mode.PredictMode object at 0x7f950a6b4130>
features = array([[1, 1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 1, 0, 0]...      [0, 1, 1, 0, 1, 0, 1],
       [0, 1, 1, 0, 0, 1, 1],
       [0, 1, 1, 0, 0, 0, 1],
       [0, 1, 1, 0, 0, 1, 1]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0]...      [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0],
       [0]])

    def fit(self, features, labels):
        """
        Looking at the provided labels, record the mode (most common) label.
    
        You may call your `find_mode` function from `src.numpy_practice`
    
        Args:
            features (np.array): numpy array of shape (n, d)
                 where n is number of examples and d is number of features.
            labels (np.array): numpy array containing true labels for each of the N
                examples.
        Output:
            None: Simply update self.most_common_class with the most common label
        """
>       raise NotImplementedError
E       NotImplementedError

src/predict_mode.py:35: NotImplementedError
______________________________________________ test_comparisons ______________________________________________

    def test_comparisons():
        comparisons = [
            # predict_mode beats decision tree on majority rule w/ 0.7 frac
            ('majority-rule.csv', 0.7, 'predict_mode', 'decision_tree',
             {}, {}),
    
            # decision tree beats predict mode on majority rule w/ 1.0 frac
            ('majority-rule.csv', 1.0, 'decision_tree', 'predict_mode',
             {}, {}),
        ]
    
        for i, comparison in enumerate(comparisons):
            (key, fraction, method_a, method_b,
             kwargs_a, kwargs_b) = comparison
    
            data_path = datasets.get(key)
>           acc_a = run(data_path, method_a, fraction, **kwargs_a)

tests/test_experiment.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:55: in run
    X_train, Y_train, X_test, Y_test = train_test_split(X, Y, fraction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 0, 0],
       [1,... 1, 0, 0],
       [0, 0, 0, 0, 1, 1],
       [0, 0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0, 1],
       [0, 0, 0, 0, 0, 0]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [1],
       [1]...      [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0]])
fraction = 0.7

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
________________________________________________ test_metrics ________________________________________________

    def test_metrics():
        from sklearn.metrics import accuracy_score
        from src import compute_accuracy
    
        y_true, y_pred = make_fake_data()
        _actual = accuracy_score(y_true, y_pred)
>       _est = compute_accuracy(y_true, y_pred)

tests/test_metrics.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = array([False,  True,  True,  True,  True, False,  True,  True, False,
       False, False, False,  True, False, False,...False, False, False, False, False,
       False,  True,  True, False, False, False, False, False, False,
       False])
predictions = array([False,  True,  True,  True,  True,  True,  True,  True,  True,
        True, False, False, False,  True, False,... True, False, False,  True, False,
       False, False,  True,  True,  True,  True,  True, False,  True,
        True])

    def compute_accuracy(actual, predictions):
        """
        Given predictions (an N-length numpy vector) and actual labels (an N-length
        numpy vector), compute the accuracy:
    
        Hint: implement and use the compute_confusion_matrix function!
    
        Args:
            actual (np.array): predicted labels of length N
            predictions (np.array): predicted labels of length N
    
        Output:
            accuracy (float): accuracy
        """
        if predictions.shape[0] != actual.shape[0]:
            raise ValueError("predictions and actual must be the same length!")
    
>       raise NotImplementedError
E       NotImplementedError

src/metrics.py:53: NotImplementedError
____________________________________ test_numpy_replace_nans_out_of_place ____________________________________

    @pytest.mark.filterwarnings("ignore:divide by zero:RuntimeWarning")
    @pytest.mark.filterwarnings("ignore:invalid value encountered in divide:RuntimeWarning")
    def test_numpy_replace_nans_out_of_place():
    
        pairs = [
            (np.array([1, 2, 3, np.inf, 4, 5, np.nan, np.true_divide(-1, 0), 6]),
             np.array([1, 2, 3, np.inf, 4, 5, 0, -np.inf, 6])),
    
            (np.array([-1, 1, 0, -1, 1, 0]) / np.array([1, 0, 1, 0, 1, 0]),
             np.array([-1, np.inf, 0, -np.inf, 1, 0])),
        ]
    
        for before, after in pairs:
            before_copy = before.copy()
            retval = src.numpy_practice.replace_nans_out_of_place(before)
>           assert np.array_equal(retval, after), "replace_nans_out_of_place should return answer"
E           AssertionError: replace_nans_out_of_place should return answer
E           assert False
E            +  where False = <function array_equal at 0x7f9518491d30>(0, array([  1.,   2.,   3.,  inf,   4.,   5.,   0., -inf,   6.]))
E            +    where <function array_equal at 0x7f9518491d30> = np.array_equal

tests/test_numpy.py:126: AssertionError
____________________________________________ test_numpy_find_mode ____________________________________________

    def test_numpy_find_mode():
        pairs = [
            (np.array([1, 2, 2, 3, 3, 3]),
             3),
            (np.concatenate([np.arange(3, 7), np.arange(6, 0, -1), np.arange(1, 7, 3)]),
             4),
            (np.concatenate([np.zeros(10), np.ones(11)]),
             1)
        ]
        for arr, target in pairs:
>           assert src.numpy_practice.find_mode(arr) == target, f"Mode is {target}"

tests/test_numpy.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([1, 2, 2, 3, 3, 3])

    def find_mode(x):
        """
        In the given array, find the mode of the vector.
        The mode is the value that appears the most times (don't worry about ties).
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([1, 2, 2, 3, 3, 3])
            >>> find_mode(x)
            3
    
        You should use:
            - np.argmax: https://numpy.org/doc/stable/reference/generated/numpy.argmax.html
    
        You should use one of:
            - np.unique: https://numpy.org/doc/stable/reference/generated/numpy.unique.html
            - np.bincount: https://numpy.org/doc/stable/reference/generated/numpy.bincount.html
    
        Args:
            x: a numpy array of integers
        Returns:
            the mode of x
        """
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:108: NotImplementedError
______________________________________ test_numpy_flip_and_slice_matrix ______________________________________

    def test_numpy_flip_and_slice_matrix():
    
        pairs = [
            (np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]]),
             np.array([[2, 1, 0], [11, 10, 9]])),
            (np.array([[ 2,  6, 16, 18, 13, 13, 17]]).T,
             np.array([[2, 18, 17]]).T),
            (np.array([[ 0, 17, 14,  4]]),
             np.array([[ 4, 14, 17,  0]]))
        ]
        for before, after in pairs:
            msg = f"flip_and_slice_matrix({before}) should return {after}"
            before = before.astype(int)
>           assert np.array_equal(src.numpy_practice.flip_and_slice_matrix(before), after), msg

tests/test_numpy.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11],
       [12, 13, 14]])

    def flip_and_slice_matrix(x):
        """
        Take the matrix x and flip it horizontally, then take the every third row.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2],
            ...               [ 3,  4,  5],
            ...               [ 6,  7,  8],
            ...               [ 9, 10, 11],
            ...               [12, 13, 14]])
            >>> flip_and_slice_matrix(x)
            array([[2, 1, 0],
                   [11, 10, 9]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.indexing.html#basics-indexing
    
        Args:
          x: a matrix
        Returns:
          a numpy matrix
        """
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:136: NotImplementedError
____________________________________ test_numpy_divide_matrix_along_rows _____________________________________

    def test_numpy_divide_matrix_along_rows():
    
        trios = [
            (np.array([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]),
             np.array([1, 2, 4]),
             np.array([[0, 1, 2, 3], [2, 2.5, 3, 3.5], [2, 2.25, 2.5, 2.75]])),
            (np.array([[2, 14], [2, 17], [8, 8], [12, 9], [9, 6], [10, 4]]),
             np.array([1, 1, 2, 3, 3, 2]),
             np.array([[2, 14], [2, 17], [4, 4], [4, 3], [3, 2], [5, 2]]))
        ]
        for (x, y, target) in trios:
            msg = f"divide_matrix_along_rows({x}, {y}) should return {target}"
>           assert np.array_equal(src.numpy_practice.divide_matrix_along_rows(x, y), target), msg

tests/test_numpy.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]]), y = array([1, 2, 4])

    def divide_matrix_along_rows(x, y):
        """
        Take the matrix x and divide it by the vector y, such that
            the ith row of x is divided by the ith value of y.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2,  3],
            ...               [ 4,  5,  6,  7],
            ...               [ 8,  9, 10, 11]])
            >>> y = np.array([1, 2, 4])
            >>> divide_rows(x, y)
            array([[0.  , 1.  , 2.  , 3.  ],
                   [2.  , 2.5 , 3.  , 3.5 ],
                   [2.  , 2.25, 2.5 , 2.75]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.broadcasting.html
        You should use one of:
            - np.reshape: https://numpy.org/doc/stable/reference/generated/numpy.reshape.html
            - np.newaxis: https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis
    
        Args:
          x: a matrix
          y: a vector with as many entries as x has rows
        Returns:
          a numpy matrix
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:170: NotImplementedError
------------------------------------------ Captured stdout teardown ------------------------------------------

======================
Output of autograder
======================
# of tests:	6/19 tests passed
Overall score:	4/100
======================
FAIL: test_train_test_split
FAIL: test_cross_validation
FAIL: test_decision_tree_binary_predict
FAIL: test_decision_tree_continuous_predict
FAIL: test_information_gain
FAIL: test_decision_tree_run
FAIL: test_predict_mode
FAIL: test_comparisons
FAIL: test_metrics
PASS: test_hello_world
PASS: test_numpy_replace_nonfinite_in_place
FAIL: test_numpy_replace_nans_out_of_place
FAIL: test_numpy_find_mode
FAIL: test_numpy_flip_and_slice_matrix
FAIL: test_numpy_divide_matrix_along_rows
======================
============================================== warnings summary ==============================================
tests/test_data.py::test_load_data
  /Users/ankitaroychoudhury/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2
    warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================================== short test summary info ===========================================
FAILED tests/test_data.py::test_train_test_split - NotImplementedError
FAILED tests/test_data.py::test_cross_validation - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_binary_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_continuous_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_information_gain - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_run - NotImplementedError
FAILED tests/test_experiment.py::test_predict_mode - NotImplementedError
FAILED tests/test_experiment.py::test_comparisons - NotImplementedError
FAILED tests/test_metrics.py::test_metrics - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_replace_nans_out_of_place - AssertionError: replace_nans_out_of_plac...
FAILED tests/test_numpy.py::test_numpy_find_mode - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_flip_and_slice_matrix - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_divide_matrix_along_rows - NotImplementedError
================================== 13 failed, 7 passed, 1 warning in 1.46s ===================================
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % pytest
============================================ test session starts =============================================
platform darwin -- Python 3.9.13, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury
plugins: anyio-3.5.0
collected 20 items                                                                                           

tests/test_a_environment.py .                                                                          [  5%]
tests/test_a_setup.py ...                                                                              [ 20%]
tests/test_data.py .FF                                                                                 [ 35%]
tests/test_decision_tree.py FFFF                                                                       [ 55%]
tests/test_experiment.py FF                                                                            [ 65%]
tests/test_metrics.py F                                                                                [ 70%]
tests/test_numpy.py ..FFFF                                                                             [100%]

================================================== FAILURES ==================================================
___________________________________________ test_train_test_split ____________________________________________

    def test_train_test_split():
        from src import load_data
        from src import train_test_split
    
        n_features = np.random.randint(5, 20)
        n_samples = np.random.randint(50, 150)
        features, targets, attribute_names = write_random_csv_file(n_features, n_samples)
        fraction = np.random.rand()
    
>       output = train_test_split(features, targets, fraction)

tests/test_data.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[ 8.19358712e-01, -8.27485174e-01,  1.29699799e+00,
        -2.53699719e+00, -1.62725643e+00],
       [-1.29997...8.02760202e-01],
       [-1.94647721e+00,  1.49342692e+00, -3.01002717e+00,
        -8.41104260e-01, -3.10311831e+00]])
labels = array([0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,...    1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0])
fraction = 0.8556542776679821

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
___________________________________________ test_cross_validation ____________________________________________

    def test_cross_validation():
        from src import load_data
        from src import cross_validation
    
        # Remember, your train_test_split should be deterministic
        # You shouldn't be randomly shuffling the data!
        n = 10
        features = np.arange(n).reshape(-1, 1)
        targets = np.arange(n).reshape(-1, 1)
        for folds in [2, 5, 10]:
>           cv = cross_validation(features, targets, folds)

tests/test_data.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
labels = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
n_folds = 2

    def cross_validation(features, labels, n_folds):
        """
        Split the data in `n_folds` different groups for cross-validation.
            Split the features and labels into a `n_folds` number of groups that
            divide the data as evenly as possible. Then for each group,
            return a tuple that treats that group as the test set and all
            other groups combine to make the training set.
    
            Note that this should be *deterministic*; don't shuffle the data.
            If there are 100 examples and you have 5 folds, each group
            should contain 20 examples and the first group should contain
            the first 20 examples.
    
            See test_cross_validation for expected behavior.
    
        Args:
            features: an NxK matrix of N examples, each with K features
            labels: an Nx1 array of N labels
            n_folds: the number of cross-validation groups
    
        Output:
            A list of tuples, where each tuple contains:
              (train_features, train_labels, test_features, test_labels)
        """
    
        assert features.shape[0] == labels.shape[0]
    
        if n_folds == 1:
            return [(features, labels, features, labels)]
>       raise NotImplementedError
E       NotImplementedError

src/data.py:92: NotImplementedError
_____________________________________ test_decision_tree_binary_predict ______________________________________

    def test_decision_tree_binary_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Outlook', 'Temp', 'Wind']
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Outlook", attribute_index=0,
            split_value=0.5, branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=0.5, branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
        examples = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [0, 1, 1]])
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7f8b09975a90>
features = array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 1, 1],
       [0, 1, 1]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________ test_decision_tree_continuous_predict ____________________________________

    def test_decision_tree_continuous_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Wind', 'Temp', 'Outlook']
        examples = np.array([[1, 79.21, 1], [2, 90.56, 0], [7, 88.36, 1], [5, 84.02, 0], [1, 43.77, 0]])
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Wind", attribute_index=0,
            split_value=np.median(examples[:, 0]), branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=np.median(examples[:, 1]), branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
    
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7f8b1aa00e50>
features = array([[ 1.  , 79.21,  1.  ],
       [ 2.  , 90.56,  0.  ],
       [ 7.  , 88.36,  1.  ],
       [ 5.  , 84.02,  0.  ],
       [ 1.  , 43.77,  0.  ]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________________ test_information_gain ____________________________________________

    def test_information_gain():
        from src import load_data
        from src import information_gain
    
        _features, _targets, _attribute_names = load_data('data/play-tennis.csv')
>       iGHumidity = information_gain(_features, 2, _targets)

tests/test_decision_tree.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0, 0, 1, 0],
       [0, 0, 1, 1],
       [1, 0, 1, 0],
       [1, 1, 1, 0],
       [1, 1, 0, 0],
       [1, 1,...[0, 1, 0, 0],
       [1, 1, 0, 0],
       [0, 1, 0, 1],
       [1, 1, 1, 1],
       [1, 0, 0, 0],
       [1, 1, 1, 1]])
attribute_index = 2
labels = array([[0],
       [0],
       [1],
       [1],
       [1],
       [0],
       [1],
       [0],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0]])

    def information_gain(features, attribute_index, labels):
        """
        Information gain is how a decision tree makes decisions on how to create
        split points in the tree. Information gain is measured in terms of entropy.
        The goal of a decision tree is to decrease entropy at each split point as
        much as possible. This function should work perfectly or your decision tree
        will not work properly.
    
        Information gain is a central concept in many machine learning algorithms.
        In decision trees, it captures how effective splitting the tree on a
        specific attribute will be for the goal of classifying the training data
        correctly.  Consider data points S and an attribute A; we'll split S into
        two data points.
    
        For binary A: S(A == 0) and S(A == 1)
        For continuous A: S(A < m) and S(A >= m), where m is the median of A in S.
    
        Together, the two subsets make up S. If the attribute A were perfectly correlated with
        the class of each data point in S, then all points in a given subset will have the
        same class. Clearly, in this case, we want something that captures that A is a good
        attribute to use in the decision tree. This something is information gain. Formally:
    
            IG(S,A) = H(S) - H(S|A)
    
        where H is information entropy. Recall that entropy captures how orderly or chaotic
        a system is. A system that is very chaotic will evenly distribute probabilities to
        all outcomes (e.g. 50% chance of class 0, 50% chance of class 1). Machine learning
        algorithms work to decrease entropy, so as to make predictions that are
        accurate on testing data. Formally, H is defined as:
    
            H(S) = sum_{c in (groups in S)} -p(c) * log_2 p(c)
    
        To elaborate: for each group c in S, you compute the probability (or weight) of c:
    
            p(c) = (# of elements of group c in S) / (total # of elements in S)
    
        Then you compute the term for this group:
    
            -p(c) * log_2 p(c)
    
        Note: if p(c) is 0, we define `-p(c) * log_2 p(c)` as 0. You can see how
            we handle this in the provided `entropy()` function, to avoid how numpy
            defines `0 * log(0) = 0 * -inf = nan`.
    
        Then compute the sum across all groups: either classes 0 and 1 for binary data, or
        for the above-median and below-median classes for continuous data. The final number
        is the entropy. To gain more intution about entropy, consider the following - what
        does H(S) = 0 tell you about S?
    
        Information gain is an extension of entropy. The equation for information gain
        involves comparing the entropy of the set and the entropy of the set when conditioned
        on selecting for a single attribute (e.g. S(A == 0)).
    
        For more details: https://en.wikipedia.org/wiki/ID3_algorithm#The_ID3_metrics
    
        Args:
            features (np.array): numpy array containing features for each example.
            attribute_index (int): which column of features to take when computing the
                information gain
            labels (np.array): numpy array containing labels corresponding to each example.
    
        Returns:
            information_gain (float): information gain if the features were split on the
                attribute_index.
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:262: NotImplementedError
___________________________________________ test_decision_tree_run ___________________________________________

    def test_decision_tree_run():
        goals = {
            'xor-easy.csv': {1.0: 1.0},
            'xor-hard.csv': {1.0: 0.8, 0.8: 1.0},
            'ivy-league.csv': {1.0: .9, 0.8: 0.6,},
            'majority-rule.csv': {1.0: 1.0, 0.8: 0.8,},
            'circles-hard.csv': {1.0: 0.7},
            'circles-easy.csv': {1.0: 0.8},
            'blobs.csv': {1.0: 0.8, 0.8: 0.9,},
        }
    
        order = [
            'xor-easy.csv',
            'ivy-league.csv',
            'majority-rule.csv',
            'xor-hard.csv',
            'blobs.csv',
            'circles-easy.csv',
            'circles-hard.csv',
        ]
    
        learner_type = 'decision_tree'
        for key in order:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_decision_tree.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
src/decision_tree.py:125: in fit
    self.tree = self._create_tree(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7f8b08834dc0>
features = array([[1, 1],
       [0, 0],
       [1, 0],
       [0, 1]])
labels = array([[0],
       [0],
       [1],
       [1]]), used_attributes = [], default = 0

    def _create_tree(self, features, labels, used_attributes, default):
        '''
        Create a decision tree recursively.
        1. If no data remains, return a leaf node with return_value `default`
            (e.g., if features and labels are both empty)
    
        2. If all labels are the same, return a leaf node with
            that label as the return_value
    
        3. For each attribute, compute the information gain from splitting on it
    
        3.1. If that is in `used_attributes`, instead set information gain to -1
            to prevent us from reusing it
        3.2. If all attributes are used, return a leaf node with the mode class
    
        3.3.1 If at least one attribute, has a non-negative information gain,
            select `best_attribute` with the largest information gain;
        3.3.2 Split data (feature & label) according to attribute values,
            where: `attribute_values = features[:, best_attribute]`;
        3.3.3 If that attribute's values are binary, split on 0.5;
            Otherwise, split on the median of the attribute values;
    
        3.4 Create a non-leaf node with the specified attribute_name,
              attribute_index, and split_value, and then RECURSIVELY
              set build its branches using self._create_tree.
              After recursing, return the node.
        '''
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:160: NotImplementedError
_____________________________________________ test_predict_mode ______________________________________________

    def test_predict_mode():
        goals = {
          'ivy-league.csv': {1.0: 0.5},
          'majority-rule.csv': {1.0: 0.6},
          'circles-easy.csv': {1.0: 0.6},
          'blobs.csv': {1.0: 0.55},
        }
    
        learner_type = 'predict_mode'
        for key in goals:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_experiment.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.predict_mode.PredictMode object at 0x7f8b1a9ff940>
features = array([[1, 1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 1, 0, 0]...      [0, 1, 1, 0, 1, 0, 1],
       [0, 1, 1, 0, 0, 1, 1],
       [0, 1, 1, 0, 0, 0, 1],
       [0, 1, 1, 0, 0, 1, 1]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0]...      [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0],
       [0]])

    def fit(self, features, labels):
        """
        Looking at the provided labels, record the mode (most common) label.
    
        You may call your `find_mode` function from `src.numpy_practice`
    
        Args:
            features (np.array): numpy array of shape (n, d)
                 where n is number of examples and d is number of features.
            labels (np.array): numpy array containing true labels for each of the N
                examples.
        Output:
            None: Simply update self.most_common_class with the most common label
        """
>       raise NotImplementedError
E       NotImplementedError

src/predict_mode.py:35: NotImplementedError
______________________________________________ test_comparisons ______________________________________________

    def test_comparisons():
        comparisons = [
            # predict_mode beats decision tree on majority rule w/ 0.7 frac
            ('majority-rule.csv', 0.7, 'predict_mode', 'decision_tree',
             {}, {}),
    
            # decision tree beats predict mode on majority rule w/ 1.0 frac
            ('majority-rule.csv', 1.0, 'decision_tree', 'predict_mode',
             {}, {}),
        ]
    
        for i, comparison in enumerate(comparisons):
            (key, fraction, method_a, method_b,
             kwargs_a, kwargs_b) = comparison
    
            data_path = datasets.get(key)
>           acc_a = run(data_path, method_a, fraction, **kwargs_a)

tests/test_experiment.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:55: in run
    X_train, Y_train, X_test, Y_test = train_test_split(X, Y, fraction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 0, 0],
       [1,... 1, 0, 0],
       [0, 0, 0, 0, 1, 1],
       [0, 0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0, 1],
       [0, 0, 0, 0, 0, 0]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [1],
       [1]...      [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0]])
fraction = 0.7

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
________________________________________________ test_metrics ________________________________________________

    def test_metrics():
        from sklearn.metrics import accuracy_score
        from src import compute_accuracy
    
        y_true, y_pred = make_fake_data()
        _actual = accuracy_score(y_true, y_pred)
>       _est = compute_accuracy(y_true, y_pred)

tests/test_metrics.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = array([ True, False, False, False, False, False,  True, False,  True,
       False,  True, False, False, False, False,... True,  True, False,  True,  True,
       False, False,  True,  True,  True, False, False, False,  True,
        True])
predictions = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True, False, False, False,  True,  True,... True, False, False,  True, False,
       False,  True, False,  True,  True, False, False, False,  True,
        True])

    def compute_accuracy(actual, predictions):
        """
        Given predictions (an N-length numpy vector) and actual labels (an N-length
        numpy vector), compute the accuracy:
    
        Hint: implement and use the compute_confusion_matrix function!
    
        Args:
            actual (np.array): predicted labels of length N
            predictions (np.array): predicted labels of length N
    
        Output:
            accuracy (float): accuracy
        """
        if predictions.shape[0] != actual.shape[0]:
            raise ValueError("predictions and actual must be the same length!")
    
>       raise NotImplementedError
E       NotImplementedError

src/metrics.py:53: NotImplementedError
____________________________________ test_numpy_replace_nans_out_of_place ____________________________________

    @pytest.mark.filterwarnings("ignore:divide by zero:RuntimeWarning")
    @pytest.mark.filterwarnings("ignore:invalid value encountered in divide:RuntimeWarning")
    def test_numpy_replace_nans_out_of_place():
    
        pairs = [
            (np.array([1, 2, 3, np.inf, 4, 5, np.nan, np.true_divide(-1, 0), 6]),
             np.array([1, 2, 3, np.inf, 4, 5, 0, -np.inf, 6])),
    
            (np.array([-1, 1, 0, -1, 1, 0]) / np.array([1, 0, 1, 0, 1, 0]),
             np.array([-1, np.inf, 0, -np.inf, 1, 0])),
        ]
    
        for before, after in pairs:
            before_copy = before.copy()
            retval = src.numpy_practice.replace_nans_out_of_place(before)
            assert np.array_equal(retval, after), "replace_nans_out_of_place should return answer"
            assert np.array_equal(before, before_copy, equal_nan=True), f"{before} shouldn't be modified"
    
>       check_function(
            "replace_nans_out_of_place",
            1,
            required=[("np.isnan", ), ("np.where")],
            prohibited=["for ", "if ", ";", "eval"]
        )

tests/test_numpy.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

function = 'replace_nans_out_of_place', max_length = 1, required = [('np.isnan',), 'np.where']
prohibited = ['for ', 'if ', ';', 'eval']

    def check_function(function, max_length, required=[], prohibited=[]):
        """
        This function is designed to force you to get to know numpy,
            by preventing you from passing the test by writing for loops or if statements,
            and by restricting you to only `max_length` number of lines.
        """
        docstring = docstrings[function].split("\n")
    
        with open(src.numpy_practice.__file__) as infile:
            for line in infile:
                if "import" in line:
                    assert line.strip() == "import numpy as np", "Don't import anything, sorry"
    
        with open(src.numpy_practice.__file__) as infile:
            for line in infile:
                if line.strip().startswith("def "):
                    func = line.strip().split("def ")[1].split("(")[0]
                    assert func in docstrings.keys(), f"You can solve these without writing {func}()"
    
        with open(src.numpy_practice.__file__) as infile:
            # Seek to the beginning of the function we're checking
            for line in infile:
                if line.strip().startswith(f"def {function}"):
                    break
    
            # Make sure the docstring is unchanged
            for i, doc_line in enumerate(docstring):
                line = infile.readline()
>               assert line.strip() == doc_line.strip(), f"Don't change the {i}th line of the docstring in function {function}()"
E               AssertionError: Don't change the 6th line of the docstring in function replace_nans_out_of_place()
E               assert '>>> x = np.a..., -1 / 0, 6])' == '>>> x = np.a..., -1 / 0, 6])'
E                 - >>> x = np.array([1, 2, 3, np.inf, 4, 5, np.nan, -1 / 0, 6])
E                 + >>> x = np.array([1, n2, 3, np.inf, 4, 5, np.nan, -1 / 0, 6])
E                 ?                      +

tests/test_numpy.py:39: AssertionError
____________________________________________ test_numpy_find_mode ____________________________________________

    def test_numpy_find_mode():
        pairs = [
            (np.array([1, 2, 2, 3, 3, 3]),
             3),
            (np.concatenate([np.arange(3, 7), np.arange(6, 0, -1), np.arange(1, 7, 3)]),
             4),
            (np.concatenate([np.zeros(10), np.ones(11)]),
             1)
        ]
        for arr, target in pairs:
>           assert src.numpy_practice.find_mode(arr) == target, f"Mode is {target}"

tests/test_numpy.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([1, 2, 2, 3, 3, 3])

    def find_mode(x):
        """
        In the given array, find the mode of the vector.
        The mode is the value that appears the most times (don't worry about ties).
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([1, 2, 2, 3, 3, 3])
            >>> find_mode(x)
            3
    
        You should use:
            - np.argmax: https://numpy.org/doc/stable/reference/generated/numpy.argmax.html
    
        You should use one of:
            - np.unique: https://numpy.org/doc/stable/reference/generated/numpy.unique.html
            - np.bincount: https://numpy.org/doc/stable/reference/generated/numpy.bincount.html
    
        Args:
            x: a numpy array of integers
        Returns:
            the mode of x
        """
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:107: NotImplementedError
______________________________________ test_numpy_flip_and_slice_matrix ______________________________________

    def test_numpy_flip_and_slice_matrix():
    
        pairs = [
            (np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]]),
             np.array([[2, 1, 0], [11, 10, 9]])),
            (np.array([[ 2,  6, 16, 18, 13, 13, 17]]).T,
             np.array([[2, 18, 17]]).T),
            (np.array([[ 0, 17, 14,  4]]),
             np.array([[ 4, 14, 17,  0]]))
        ]
        for before, after in pairs:
            msg = f"flip_and_slice_matrix({before}) should return {after}"
            before = before.astype(int)
>           assert np.array_equal(src.numpy_practice.flip_and_slice_matrix(before), after), msg

tests/test_numpy.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11],
       [12, 13, 14]])

    def flip_and_slice_matrix(x):
        """
        Take the matrix x and flip it horizontally, then take the every third row.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2],
            ...               [ 3,  4,  5],
            ...               [ 6,  7,  8],
            ...               [ 9, 10, 11],
            ...               [12, 13, 14]])
            >>> flip_and_slice_matrix(x)
            array([[2, 1, 0],
                   [11, 10, 9]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.indexing.html#basics-indexing
    
        Args:
          x: a matrix
        Returns:
          a numpy matrix
        """
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:135: NotImplementedError
____________________________________ test_numpy_divide_matrix_along_rows _____________________________________

    def test_numpy_divide_matrix_along_rows():
    
        trios = [
            (np.array([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]),
             np.array([1, 2, 4]),
             np.array([[0, 1, 2, 3], [2, 2.5, 3, 3.5], [2, 2.25, 2.5, 2.75]])),
            (np.array([[2, 14], [2, 17], [8, 8], [12, 9], [9, 6], [10, 4]]),
             np.array([1, 1, 2, 3, 3, 2]),
             np.array([[2, 14], [2, 17], [4, 4], [4, 3], [3, 2], [5, 2]]))
        ]
        for (x, y, target) in trios:
            msg = f"divide_matrix_along_rows({x}, {y}) should return {target}"
>           assert np.array_equal(src.numpy_practice.divide_matrix_along_rows(x, y), target), msg

tests/test_numpy.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]]), y = array([1, 2, 4])

    def divide_matrix_along_rows(x, y):
        """
        Take the matrix x and divide it by the vector y, such that
            the ith row of x is divided by the ith value of y.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2,  3],
            ...               [ 4,  5,  6,  7],
            ...               [ 8,  9, 10, 11]])
            >>> y = np.array([1, 2, 4])
            >>> divide_rows(x, y)
            array([[0.  , 1.  , 2.  , 3.  ],
                   [2.  , 2.5 , 3.  , 3.5 ],
                   [2.  , 2.25, 2.5 , 2.75]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.broadcasting.html
        You should use one of:
            - np.reshape: https://numpy.org/doc/stable/reference/generated/numpy.reshape.html
            - np.newaxis: https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis
    
        Args:
          x: a matrix
          y: a vector with as many entries as x has rows
        Returns:
          a numpy matrix
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:169: NotImplementedError
------------------------------------------ Captured stdout teardown ------------------------------------------

======================
Output of autograder
======================
# of tests:	6/19 tests passed
Overall score:	4/100
======================
FAIL: test_train_test_split
FAIL: test_cross_validation
FAIL: test_decision_tree_binary_predict
FAIL: test_decision_tree_continuous_predict
FAIL: test_information_gain
FAIL: test_decision_tree_run
FAIL: test_predict_mode
FAIL: test_comparisons
FAIL: test_metrics
PASS: test_hello_world
PASS: test_numpy_replace_nonfinite_in_place
FAIL: test_numpy_replace_nans_out_of_place
FAIL: test_numpy_find_mode
FAIL: test_numpy_flip_and_slice_matrix
FAIL: test_numpy_divide_matrix_along_rows
======================
============================================== warnings summary ==============================================
tests/test_data.py::test_load_data
  /Users/ankitaroychoudhury/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2
    warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================================== short test summary info ===========================================
FAILED tests/test_data.py::test_train_test_split - NotImplementedError
FAILED tests/test_data.py::test_cross_validation - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_binary_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_continuous_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_information_gain - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_run - NotImplementedError
FAILED tests/test_experiment.py::test_predict_mode - NotImplementedError
FAILED tests/test_experiment.py::test_comparisons - NotImplementedError
FAILED tests/test_metrics.py::test_metrics - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_replace_nans_out_of_place - AssertionError: Don't change the 6th lin...
FAILED tests/test_numpy.py::test_numpy_find_mode - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_flip_and_slice_matrix - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_divide_matrix_along_rows - NotImplementedError
================================== 13 failed, 7 passed, 1 warning in 1.57s ===================================
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % pytest
============================================ test session starts =============================================
platform darwin -- Python 3.9.13, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury
plugins: anyio-3.5.0
collected 20 items                                                                                           

tests/test_a_environment.py .                                                                          [  5%]
tests/test_a_setup.py ...                                                                              [ 20%]
tests/test_data.py .FF                                                                                 [ 35%]
tests/test_decision_tree.py FFFF                                                                       [ 55%]
tests/test_experiment.py FF                                                                            [ 65%]
tests/test_metrics.py F                                                                                [ 70%]
tests/test_numpy.py ...FFF                                                                             [100%]

================================================== FAILURES ==================================================
___________________________________________ test_train_test_split ____________________________________________

    def test_train_test_split():
        from src import load_data
        from src import train_test_split
    
        n_features = np.random.randint(5, 20)
        n_samples = np.random.randint(50, 150)
        features, targets, attribute_names = write_random_csv_file(n_features, n_samples)
        fraction = np.random.rand()
    
>       output = train_test_split(features, targets, fraction)

tests/test_data.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[ 1.32877322,  1.12688381,  1.40577699, ...,  0.84200405,
        -0.4700087 , -0.32996406],
       [-0.4260790...632, -2.62766131],
       [-1.63370394, -2.27467327,  2.4248381 , ..., -1.21875605,
         0.43515593, -0.73012031]])
labels = array([1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,
       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,... 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,
       1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1])
fraction = 0.10675984814138417

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
___________________________________________ test_cross_validation ____________________________________________

    def test_cross_validation():
        from src import load_data
        from src import cross_validation
    
        # Remember, your train_test_split should be deterministic
        # You shouldn't be randomly shuffling the data!
        n = 10
        features = np.arange(n).reshape(-1, 1)
        targets = np.arange(n).reshape(-1, 1)
        for folds in [2, 5, 10]:
>           cv = cross_validation(features, targets, folds)

tests/test_data.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
labels = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
n_folds = 2

    def cross_validation(features, labels, n_folds):
        """
        Split the data in `n_folds` different groups for cross-validation.
            Split the features and labels into a `n_folds` number of groups that
            divide the data as evenly as possible. Then for each group,
            return a tuple that treats that group as the test set and all
            other groups combine to make the training set.
    
            Note that this should be *deterministic*; don't shuffle the data.
            If there are 100 examples and you have 5 folds, each group
            should contain 20 examples and the first group should contain
            the first 20 examples.
    
            See test_cross_validation for expected behavior.
    
        Args:
            features: an NxK matrix of N examples, each with K features
            labels: an Nx1 array of N labels
            n_folds: the number of cross-validation groups
    
        Output:
            A list of tuples, where each tuple contains:
              (train_features, train_labels, test_features, test_labels)
        """
    
        assert features.shape[0] == labels.shape[0]
    
        if n_folds == 1:
            return [(features, labels, features, labels)]
>       raise NotImplementedError
E       NotImplementedError

src/data.py:92: NotImplementedError
_____________________________________ test_decision_tree_binary_predict ______________________________________

    def test_decision_tree_binary_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Outlook', 'Temp', 'Wind']
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Outlook", attribute_index=0,
            split_value=0.5, branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=0.5, branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
        examples = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [0, 1, 1]])
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fc3628b36d0>
features = array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 1, 1],
       [0, 1, 1]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________ test_decision_tree_continuous_predict ____________________________________

    def test_decision_tree_continuous_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Wind', 'Temp', 'Outlook']
        examples = np.array([[1, 79.21, 1], [2, 90.56, 0], [7, 88.36, 1], [5, 84.02, 0], [1, 43.77, 0]])
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Wind", attribute_index=0,
            split_value=np.median(examples[:, 0]), branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=np.median(examples[:, 1]), branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
    
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fc3628b8f10>
features = array([[ 1.  , 79.21,  1.  ],
       [ 2.  , 90.56,  0.  ],
       [ 7.  , 88.36,  1.  ],
       [ 5.  , 84.02,  0.  ],
       [ 1.  , 43.77,  0.  ]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________________ test_information_gain ____________________________________________

    def test_information_gain():
        from src import load_data
        from src import information_gain
    
        _features, _targets, _attribute_names = load_data('data/play-tennis.csv')
>       iGHumidity = information_gain(_features, 2, _targets)

tests/test_decision_tree.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0, 0, 1, 0],
       [0, 0, 1, 1],
       [1, 0, 1, 0],
       [1, 1, 1, 0],
       [1, 1, 0, 0],
       [1, 1,...[0, 1, 0, 0],
       [1, 1, 0, 0],
       [0, 1, 0, 1],
       [1, 1, 1, 1],
       [1, 0, 0, 0],
       [1, 1, 1, 1]])
attribute_index = 2
labels = array([[0],
       [0],
       [1],
       [1],
       [1],
       [0],
       [1],
       [0],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0]])

    def information_gain(features, attribute_index, labels):
        """
        Information gain is how a decision tree makes decisions on how to create
        split points in the tree. Information gain is measured in terms of entropy.
        The goal of a decision tree is to decrease entropy at each split point as
        much as possible. This function should work perfectly or your decision tree
        will not work properly.
    
        Information gain is a central concept in many machine learning algorithms.
        In decision trees, it captures how effective splitting the tree on a
        specific attribute will be for the goal of classifying the training data
        correctly.  Consider data points S and an attribute A; we'll split S into
        two data points.
    
        For binary A: S(A == 0) and S(A == 1)
        For continuous A: S(A < m) and S(A >= m), where m is the median of A in S.
    
        Together, the two subsets make up S. If the attribute A were perfectly correlated with
        the class of each data point in S, then all points in a given subset will have the
        same class. Clearly, in this case, we want something that captures that A is a good
        attribute to use in the decision tree. This something is information gain. Formally:
    
            IG(S,A) = H(S) - H(S|A)
    
        where H is information entropy. Recall that entropy captures how orderly or chaotic
        a system is. A system that is very chaotic will evenly distribute probabilities to
        all outcomes (e.g. 50% chance of class 0, 50% chance of class 1). Machine learning
        algorithms work to decrease entropy, so as to make predictions that are
        accurate on testing data. Formally, H is defined as:
    
            H(S) = sum_{c in (groups in S)} -p(c) * log_2 p(c)
    
        To elaborate: for each group c in S, you compute the probability (or weight) of c:
    
            p(c) = (# of elements of group c in S) / (total # of elements in S)
    
        Then you compute the term for this group:
    
            -p(c) * log_2 p(c)
    
        Note: if p(c) is 0, we define `-p(c) * log_2 p(c)` as 0. You can see how
            we handle this in the provided `entropy()` function, to avoid how numpy
            defines `0 * log(0) = 0 * -inf = nan`.
    
        Then compute the sum across all groups: either classes 0 and 1 for binary data, or
        for the above-median and below-median classes for continuous data. The final number
        is the entropy. To gain more intution about entropy, consider the following - what
        does H(S) = 0 tell you about S?
    
        Information gain is an extension of entropy. The equation for information gain
        involves comparing the entropy of the set and the entropy of the set when conditioned
        on selecting for a single attribute (e.g. S(A == 0)).
    
        For more details: https://en.wikipedia.org/wiki/ID3_algorithm#The_ID3_metrics
    
        Args:
            features (np.array): numpy array containing features for each example.
            attribute_index (int): which column of features to take when computing the
                information gain
            labels (np.array): numpy array containing labels corresponding to each example.
    
        Returns:
            information_gain (float): information gain if the features were split on the
                attribute_index.
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:262: NotImplementedError
___________________________________________ test_decision_tree_run ___________________________________________

    def test_decision_tree_run():
        goals = {
            'xor-easy.csv': {1.0: 1.0},
            'xor-hard.csv': {1.0: 0.8, 0.8: 1.0},
            'ivy-league.csv': {1.0: .9, 0.8: 0.6,},
            'majority-rule.csv': {1.0: 1.0, 0.8: 0.8,},
            'circles-hard.csv': {1.0: 0.7},
            'circles-easy.csv': {1.0: 0.8},
            'blobs.csv': {1.0: 0.8, 0.8: 0.9,},
        }
    
        order = [
            'xor-easy.csv',
            'ivy-league.csv',
            'majority-rule.csv',
            'xor-hard.csv',
            'blobs.csv',
            'circles-easy.csv',
            'circles-hard.csv',
        ]
    
        learner_type = 'decision_tree'
        for key in order:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_decision_tree.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
src/decision_tree.py:125: in fit
    self.tree = self._create_tree(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fc3628aeb80>
features = array([[1, 1],
       [0, 0],
       [1, 0],
       [0, 1]])
labels = array([[0],
       [0],
       [1],
       [1]]), used_attributes = [], default = 0

    def _create_tree(self, features, labels, used_attributes, default):
        '''
        Create a decision tree recursively.
        1. If no data remains, return a leaf node with return_value `default`
            (e.g., if features and labels are both empty)
    
        2. If all labels are the same, return a leaf node with
            that label as the return_value
    
        3. For each attribute, compute the information gain from splitting on it
    
        3.1. If that is in `used_attributes`, instead set information gain to -1
            to prevent us from reusing it
        3.2. If all attributes are used, return a leaf node with the mode class
    
        3.3.1 If at least one attribute, has a non-negative information gain,
            select `best_attribute` with the largest information gain;
        3.3.2 Split data (feature & label) according to attribute values,
            where: `attribute_values = features[:, best_attribute]`;
        3.3.3 If that attribute's values are binary, split on 0.5;
            Otherwise, split on the median of the attribute values;
    
        3.4 Create a non-leaf node with the specified attribute_name,
              attribute_index, and split_value, and then RECURSIVELY
              set build its branches using self._create_tree.
              After recursing, return the node.
        '''
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:160: NotImplementedError
_____________________________________________ test_predict_mode ______________________________________________

    def test_predict_mode():
        goals = {
          'ivy-league.csv': {1.0: 0.5},
          'majority-rule.csv': {1.0: 0.6},
          'circles-easy.csv': {1.0: 0.6},
          'blobs.csv': {1.0: 0.55},
        }
    
        learner_type = 'predict_mode'
        for key in goals:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_experiment.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.predict_mode.PredictMode object at 0x7fc3628b2370>
features = array([[1, 1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 1, 0, 0]...      [0, 1, 1, 0, 1, 0, 1],
       [0, 1, 1, 0, 0, 1, 1],
       [0, 1, 1, 0, 0, 0, 1],
       [0, 1, 1, 0, 0, 1, 1]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0]...      [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0],
       [0]])

    def fit(self, features, labels):
        """
        Looking at the provided labels, record the mode (most common) label.
    
        You may call your `find_mode` function from `src.numpy_practice`
    
        Args:
            features (np.array): numpy array of shape (n, d)
                 where n is number of examples and d is number of features.
            labels (np.array): numpy array containing true labels for each of the N
                examples.
        Output:
            None: Simply update self.most_common_class with the most common label
        """
>       raise NotImplementedError
E       NotImplementedError

src/predict_mode.py:35: NotImplementedError
______________________________________________ test_comparisons ______________________________________________

    def test_comparisons():
        comparisons = [
            # predict_mode beats decision tree on majority rule w/ 0.7 frac
            ('majority-rule.csv', 0.7, 'predict_mode', 'decision_tree',
             {}, {}),
    
            # decision tree beats predict mode on majority rule w/ 1.0 frac
            ('majority-rule.csv', 1.0, 'decision_tree', 'predict_mode',
             {}, {}),
        ]
    
        for i, comparison in enumerate(comparisons):
            (key, fraction, method_a, method_b,
             kwargs_a, kwargs_b) = comparison
    
            data_path = datasets.get(key)
>           acc_a = run(data_path, method_a, fraction, **kwargs_a)

tests/test_experiment.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:55: in run
    X_train, Y_train, X_test, Y_test = train_test_split(X, Y, fraction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 0, 0],
       [1,... 1, 0, 0],
       [0, 0, 0, 0, 1, 1],
       [0, 0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0, 1],
       [0, 0, 0, 0, 0, 0]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [1],
       [1]...      [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0]])
fraction = 0.7

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
________________________________________________ test_metrics ________________________________________________

    def test_metrics():
        from sklearn.metrics import accuracy_score
        from src import compute_accuracy
    
        y_true, y_pred = make_fake_data()
        _actual = accuracy_score(y_true, y_pred)
>       _est = compute_accuracy(y_true, y_pred)

tests/test_metrics.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = array([ True, False,  True, False, False, False,  True,  True, False,
       False, False,  True, False,  True, False,...False,  True, False, False, False,
       False, False, False,  True, False,  True,  True, False, False,
       False])
predictions = array([ True, False,  True,  True, False, False,  True, False,  True,
        True, False,  True,  True,  True, False,...False,  True,  True, False,  True,
        True,  True, False, False, False, False, False,  True,  True,
       False])

    def compute_accuracy(actual, predictions):
        """
        Given predictions (an N-length numpy vector) and actual labels (an N-length
        numpy vector), compute the accuracy:
    
        Hint: implement and use the compute_confusion_matrix function!
    
        Args:
            actual (np.array): predicted labels of length N
            predictions (np.array): predicted labels of length N
    
        Output:
            accuracy (float): accuracy
        """
        if predictions.shape[0] != actual.shape[0]:
            raise ValueError("predictions and actual must be the same length!")
    
>       raise NotImplementedError
E       NotImplementedError

src/metrics.py:53: NotImplementedError
____________________________________________ test_numpy_find_mode ____________________________________________

    def test_numpy_find_mode():
        pairs = [
            (np.array([1, 2, 2, 3, 3, 3]),
             3),
            (np.concatenate([np.arange(3, 7), np.arange(6, 0, -1), np.arange(1, 7, 3)]),
             4),
            (np.concatenate([np.zeros(10), np.ones(11)]),
             1)
        ]
        for arr, target in pairs:
>           assert src.numpy_practice.find_mode(arr) == target, f"Mode is {target}"

tests/test_numpy.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([1, 2, 2, 3, 3, 3])

    def find_mode(x):
        """
        In the given array, find the mode of the vector.
        The mode is the value that appears the most times (don't worry about ties).
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([1, 2, 2, 3, 3, 3])
            >>> find_mode(x)
            3
    
        You should use:
            - np.argmax: https://numpy.org/doc/stable/reference/generated/numpy.argmax.html
    
        You should use one of:
            - np.unique: https://numpy.org/doc/stable/reference/generated/numpy.unique.html
            - np.bincount: https://numpy.org/doc/stable/reference/generated/numpy.bincount.html
    
        Args:
            x: a numpy array of integers
        Returns:
            the mode of x
        """
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:107: NotImplementedError
______________________________________ test_numpy_flip_and_slice_matrix ______________________________________

    def test_numpy_flip_and_slice_matrix():
    
        pairs = [
            (np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]]),
             np.array([[2, 1, 0], [11, 10, 9]])),
            (np.array([[ 2,  6, 16, 18, 13, 13, 17]]).T,
             np.array([[2, 18, 17]]).T),
            (np.array([[ 0, 17, 14,  4]]),
             np.array([[ 4, 14, 17,  0]]))
        ]
        for before, after in pairs:
            msg = f"flip_and_slice_matrix({before}) should return {after}"
            before = before.astype(int)
>           assert np.array_equal(src.numpy_practice.flip_and_slice_matrix(before), after), msg

tests/test_numpy.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11],
       [12, 13, 14]])

    def flip_and_slice_matrix(x):
        """
        Take the matrix x and flip it horizontally, then take the every third row.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2],
            ...               [ 3,  4,  5],
            ...               [ 6,  7,  8],
            ...               [ 9, 10, 11],
            ...               [12, 13, 14]])
            >>> flip_and_slice_matrix(x)
            array([[2, 1, 0],
                   [11, 10, 9]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.indexing.html#basics-indexing
    
        Args:
          x: a matrix
        Returns:
          a numpy matrix
        """
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:135: NotImplementedError
____________________________________ test_numpy_divide_matrix_along_rows _____________________________________

    def test_numpy_divide_matrix_along_rows():
    
        trios = [
            (np.array([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]),
             np.array([1, 2, 4]),
             np.array([[0, 1, 2, 3], [2, 2.5, 3, 3.5], [2, 2.25, 2.5, 2.75]])),
            (np.array([[2, 14], [2, 17], [8, 8], [12, 9], [9, 6], [10, 4]]),
             np.array([1, 1, 2, 3, 3, 2]),
             np.array([[2, 14], [2, 17], [4, 4], [4, 3], [3, 2], [5, 2]]))
        ]
        for (x, y, target) in trios:
            msg = f"divide_matrix_along_rows({x}, {y}) should return {target}"
>           assert np.array_equal(src.numpy_practice.divide_matrix_along_rows(x, y), target), msg

tests/test_numpy.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]]), y = array([1, 2, 4])

    def divide_matrix_along_rows(x, y):
        """
        Take the matrix x and divide it by the vector y, such that
            the ith row of x is divided by the ith value of y.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2,  3],
            ...               [ 4,  5,  6,  7],
            ...               [ 8,  9, 10, 11]])
            >>> y = np.array([1, 2, 4])
            >>> divide_rows(x, y)
            array([[0.  , 1.  , 2.  , 3.  ],
                   [2.  , 2.5 , 3.  , 3.5 ],
                   [2.  , 2.25, 2.5 , 2.75]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.broadcasting.html
        You should use one of:
            - np.reshape: https://numpy.org/doc/stable/reference/generated/numpy.reshape.html
            - np.newaxis: https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis
    
        Args:
          x: a matrix
          y: a vector with as many entries as x has rows
        Returns:
          a numpy matrix
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:169: NotImplementedError
------------------------------------------ Captured stdout teardown ------------------------------------------

======================
Output of autograder
======================
# of tests:	7/19 tests passed
Overall score:	6/100
======================
FAIL: test_train_test_split
FAIL: test_cross_validation
FAIL: test_decision_tree_binary_predict
FAIL: test_decision_tree_continuous_predict
FAIL: test_information_gain
FAIL: test_decision_tree_run
FAIL: test_predict_mode
FAIL: test_comparisons
FAIL: test_metrics
PASS: test_hello_world
PASS: test_numpy_replace_nonfinite_in_place
PASS: test_numpy_replace_nans_out_of_place
FAIL: test_numpy_find_mode
FAIL: test_numpy_flip_and_slice_matrix
FAIL: test_numpy_divide_matrix_along_rows
======================
============================================== warnings summary ==============================================
tests/test_data.py::test_load_data
  /Users/ankitaroychoudhury/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2
    warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================================== short test summary info ===========================================
FAILED tests/test_data.py::test_train_test_split - NotImplementedError
FAILED tests/test_data.py::test_cross_validation - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_binary_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_continuous_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_information_gain - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_run - NotImplementedError
FAILED tests/test_experiment.py::test_predict_mode - NotImplementedError
FAILED tests/test_experiment.py::test_comparisons - NotImplementedError
FAILED tests/test_metrics.py::test_metrics - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_find_mode - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_flip_and_slice_matrix - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_divide_matrix_along_rows - NotImplementedError
================================== 12 failed, 8 passed, 1 warning in 1.33s ===================================
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % pytest
============================================ test session starts =============================================
platform darwin -- Python 3.9.13, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury
plugins: anyio-3.5.0
collected 20 items                                                                                           

tests/test_a_environment.py .                                                                          [  5%]
tests/test_a_setup.py ...                                                                              [ 20%]
tests/test_data.py .FF                                                                                 [ 35%]
tests/test_decision_tree.py FFFF                                                                       [ 55%]
tests/test_experiment.py FF                                                                            [ 65%]
tests/test_metrics.py F                                                                                [ 70%]
tests/test_numpy.py ....FF                                                                             [100%]

================================================== FAILURES ==================================================
___________________________________________ test_train_test_split ____________________________________________

    def test_train_test_split():
        from src import load_data
        from src import train_test_split
    
        n_features = np.random.randint(5, 20)
        n_samples = np.random.randint(50, 150)
        features, targets, attribute_names = write_random_csv_file(n_features, n_samples)
        fraction = np.random.rand()
    
>       output = train_test_split(features, targets, fraction)

tests/test_data.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[-1.56782851, -1.36287222, -2.08810926, ...,  1.77449442,
        -0.22683864,  1.31554142],
       [-0.5173841...503, -0.16206523],
       [-0.08369353, -0.16398367, -0.13976365, ..., -0.57891677,
        -0.4172126 ,  0.01636572]])
labels = array([0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,
       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1,...0, 0,
       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,
       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0])
fraction = 0.47911826399201773

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
___________________________________________ test_cross_validation ____________________________________________

    def test_cross_validation():
        from src import load_data
        from src import cross_validation
    
        # Remember, your train_test_split should be deterministic
        # You shouldn't be randomly shuffling the data!
        n = 10
        features = np.arange(n).reshape(-1, 1)
        targets = np.arange(n).reshape(-1, 1)
        for folds in [2, 5, 10]:
>           cv = cross_validation(features, targets, folds)

tests/test_data.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
labels = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
n_folds = 2

    def cross_validation(features, labels, n_folds):
        """
        Split the data in `n_folds` different groups for cross-validation.
            Split the features and labels into a `n_folds` number of groups that
            divide the data as evenly as possible. Then for each group,
            return a tuple that treats that group as the test set and all
            other groups combine to make the training set.
    
            Note that this should be *deterministic*; don't shuffle the data.
            If there are 100 examples and you have 5 folds, each group
            should contain 20 examples and the first group should contain
            the first 20 examples.
    
            See test_cross_validation for expected behavior.
    
        Args:
            features: an NxK matrix of N examples, each with K features
            labels: an Nx1 array of N labels
            n_folds: the number of cross-validation groups
    
        Output:
            A list of tuples, where each tuple contains:
              (train_features, train_labels, test_features, test_labels)
        """
    
        assert features.shape[0] == labels.shape[0]
    
        if n_folds == 1:
            return [(features, labels, features, labels)]
>       raise NotImplementedError
E       NotImplementedError

src/data.py:92: NotImplementedError
_____________________________________ test_decision_tree_binary_predict ______________________________________

    def test_decision_tree_binary_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Outlook', 'Temp', 'Wind']
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Outlook", attribute_index=0,
            split_value=0.5, branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=0.5, branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
        examples = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [0, 1, 1]])
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fac8a7191f0>
features = array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 1, 1],
       [0, 1, 1]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________ test_decision_tree_continuous_predict ____________________________________

    def test_decision_tree_continuous_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Wind', 'Temp', 'Outlook']
        examples = np.array([[1, 79.21, 1], [2, 90.56, 0], [7, 88.36, 1], [5, 84.02, 0], [1, 43.77, 0]])
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Wind", attribute_index=0,
            split_value=np.median(examples[:, 0]), branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=np.median(examples[:, 1]), branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
    
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fac8a717f10>
features = array([[ 1.  , 79.21,  1.  ],
       [ 2.  , 90.56,  0.  ],
       [ 7.  , 88.36,  1.  ],
       [ 5.  , 84.02,  0.  ],
       [ 1.  , 43.77,  0.  ]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________________ test_information_gain ____________________________________________

    def test_information_gain():
        from src import load_data
        from src import information_gain
    
        _features, _targets, _attribute_names = load_data('data/play-tennis.csv')
>       iGHumidity = information_gain(_features, 2, _targets)

tests/test_decision_tree.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0, 0, 1, 0],
       [0, 0, 1, 1],
       [1, 0, 1, 0],
       [1, 1, 1, 0],
       [1, 1, 0, 0],
       [1, 1,...[0, 1, 0, 0],
       [1, 1, 0, 0],
       [0, 1, 0, 1],
       [1, 1, 1, 1],
       [1, 0, 0, 0],
       [1, 1, 1, 1]])
attribute_index = 2
labels = array([[0],
       [0],
       [1],
       [1],
       [1],
       [0],
       [1],
       [0],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0]])

    def information_gain(features, attribute_index, labels):
        """
        Information gain is how a decision tree makes decisions on how to create
        split points in the tree. Information gain is measured in terms of entropy.
        The goal of a decision tree is to decrease entropy at each split point as
        much as possible. This function should work perfectly or your decision tree
        will not work properly.
    
        Information gain is a central concept in many machine learning algorithms.
        In decision trees, it captures how effective splitting the tree on a
        specific attribute will be for the goal of classifying the training data
        correctly.  Consider data points S and an attribute A; we'll split S into
        two data points.
    
        For binary A: S(A == 0) and S(A == 1)
        For continuous A: S(A < m) and S(A >= m), where m is the median of A in S.
    
        Together, the two subsets make up S. If the attribute A were perfectly correlated with
        the class of each data point in S, then all points in a given subset will have the
        same class. Clearly, in this case, we want something that captures that A is a good
        attribute to use in the decision tree. This something is information gain. Formally:
    
            IG(S,A) = H(S) - H(S|A)
    
        where H is information entropy. Recall that entropy captures how orderly or chaotic
        a system is. A system that is very chaotic will evenly distribute probabilities to
        all outcomes (e.g. 50% chance of class 0, 50% chance of class 1). Machine learning
        algorithms work to decrease entropy, so as to make predictions that are
        accurate on testing data. Formally, H is defined as:
    
            H(S) = sum_{c in (groups in S)} -p(c) * log_2 p(c)
    
        To elaborate: for each group c in S, you compute the probability (or weight) of c:
    
            p(c) = (# of elements of group c in S) / (total # of elements in S)
    
        Then you compute the term for this group:
    
            -p(c) * log_2 p(c)
    
        Note: if p(c) is 0, we define `-p(c) * log_2 p(c)` as 0. You can see how
            we handle this in the provided `entropy()` function, to avoid how numpy
            defines `0 * log(0) = 0 * -inf = nan`.
    
        Then compute the sum across all groups: either classes 0 and 1 for binary data, or
        for the above-median and below-median classes for continuous data. The final number
        is the entropy. To gain more intution about entropy, consider the following - what
        does H(S) = 0 tell you about S?
    
        Information gain is an extension of entropy. The equation for information gain
        involves comparing the entropy of the set and the entropy of the set when conditioned
        on selecting for a single attribute (e.g. S(A == 0)).
    
        For more details: https://en.wikipedia.org/wiki/ID3_algorithm#The_ID3_metrics
    
        Args:
            features (np.array): numpy array containing features for each example.
            attribute_index (int): which column of features to take when computing the
                information gain
            labels (np.array): numpy array containing labels corresponding to each example.
    
        Returns:
            information_gain (float): information gain if the features were split on the
                attribute_index.
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:262: NotImplementedError
___________________________________________ test_decision_tree_run ___________________________________________

    def test_decision_tree_run():
        goals = {
            'xor-easy.csv': {1.0: 1.0},
            'xor-hard.csv': {1.0: 0.8, 0.8: 1.0},
            'ivy-league.csv': {1.0: .9, 0.8: 0.6,},
            'majority-rule.csv': {1.0: 1.0, 0.8: 0.8,},
            'circles-hard.csv': {1.0: 0.7},
            'circles-easy.csv': {1.0: 0.8},
            'blobs.csv': {1.0: 0.8, 0.8: 0.9,},
        }
    
        order = [
            'xor-easy.csv',
            'ivy-league.csv',
            'majority-rule.csv',
            'xor-hard.csv',
            'blobs.csv',
            'circles-easy.csv',
            'circles-hard.csv',
        ]
    
        learner_type = 'decision_tree'
        for key in order:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_decision_tree.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
src/decision_tree.py:125: in fit
    self.tree = self._create_tree(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fac8a715070>
features = array([[1, 1],
       [0, 0],
       [1, 0],
       [0, 1]])
labels = array([[0],
       [0],
       [1],
       [1]]), used_attributes = [], default = 0

    def _create_tree(self, features, labels, used_attributes, default):
        '''
        Create a decision tree recursively.
        1. If no data remains, return a leaf node with return_value `default`
            (e.g., if features and labels are both empty)
    
        2. If all labels are the same, return a leaf node with
            that label as the return_value
    
        3. For each attribute, compute the information gain from splitting on it
    
        3.1. If that is in `used_attributes`, instead set information gain to -1
            to prevent us from reusing it
        3.2. If all attributes are used, return a leaf node with the mode class
    
        3.3.1 If at least one attribute, has a non-negative information gain,
            select `best_attribute` with the largest information gain;
        3.3.2 Split data (feature & label) according to attribute values,
            where: `attribute_values = features[:, best_attribute]`;
        3.3.3 If that attribute's values are binary, split on 0.5;
            Otherwise, split on the median of the attribute values;
    
        3.4 Create a non-leaf node with the specified attribute_name,
              attribute_index, and split_value, and then RECURSIVELY
              set build its branches using self._create_tree.
              After recursing, return the node.
        '''
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:160: NotImplementedError
_____________________________________________ test_predict_mode ______________________________________________

    def test_predict_mode():
        goals = {
          'ivy-league.csv': {1.0: 0.5},
          'majority-rule.csv': {1.0: 0.6},
          'circles-easy.csv': {1.0: 0.6},
          'blobs.csv': {1.0: 0.55},
        }
    
        learner_type = 'predict_mode'
        for key in goals:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_experiment.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.predict_mode.PredictMode object at 0x7fac8a72c280>
features = array([[1, 1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 1, 0, 0]...      [0, 1, 1, 0, 1, 0, 1],
       [0, 1, 1, 0, 0, 1, 1],
       [0, 1, 1, 0, 0, 0, 1],
       [0, 1, 1, 0, 0, 1, 1]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0]...      [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0],
       [0]])

    def fit(self, features, labels):
        """
        Looking at the provided labels, record the mode (most common) label.
    
        You may call your `find_mode` function from `src.numpy_practice`
    
        Args:
            features (np.array): numpy array of shape (n, d)
                 where n is number of examples and d is number of features.
            labels (np.array): numpy array containing true labels for each of the N
                examples.
        Output:
            None: Simply update self.most_common_class with the most common label
        """
>       raise NotImplementedError
E       NotImplementedError

src/predict_mode.py:35: NotImplementedError
______________________________________________ test_comparisons ______________________________________________

    def test_comparisons():
        comparisons = [
            # predict_mode beats decision tree on majority rule w/ 0.7 frac
            ('majority-rule.csv', 0.7, 'predict_mode', 'decision_tree',
             {}, {}),
    
            # decision tree beats predict mode on majority rule w/ 1.0 frac
            ('majority-rule.csv', 1.0, 'decision_tree', 'predict_mode',
             {}, {}),
        ]
    
        for i, comparison in enumerate(comparisons):
            (key, fraction, method_a, method_b,
             kwargs_a, kwargs_b) = comparison
    
            data_path = datasets.get(key)
>           acc_a = run(data_path, method_a, fraction, **kwargs_a)

tests/test_experiment.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:55: in run
    X_train, Y_train, X_test, Y_test = train_test_split(X, Y, fraction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 0, 0],
       [1,... 1, 0, 0],
       [0, 0, 0, 0, 1, 1],
       [0, 0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0, 1],
       [0, 0, 0, 0, 0, 0]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [1],
       [1]...      [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0]])
fraction = 0.7

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
________________________________________________ test_metrics ________________________________________________

    def test_metrics():
        from sklearn.metrics import accuracy_score
        from src import compute_accuracy
    
        y_true, y_pred = make_fake_data()
        _actual = accuracy_score(y_true, y_pred)
>       _est = compute_accuracy(y_true, y_pred)

tests/test_metrics.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = array([False, False, False,  True,  True,  True, False,  True,  True,
       False,  True, False, False,  True,  True,...False,  True,  True,  True,  True,
       False,  True, False, False, False, False, False,  True, False,
        True])
predictions = array([ True, False,  True,  True, False,  True, False,  True, False,
       False, False,  True, False, False, False,... True,  True, False, False,  True,
       False,  True,  True,  True,  True,  True,  True, False,  True,
        True])

    def compute_accuracy(actual, predictions):
        """
        Given predictions (an N-length numpy vector) and actual labels (an N-length
        numpy vector), compute the accuracy:
    
        Hint: implement and use the compute_confusion_matrix function!
    
        Args:
            actual (np.array): predicted labels of length N
            predictions (np.array): predicted labels of length N
    
        Output:
            accuracy (float): accuracy
        """
        if predictions.shape[0] != actual.shape[0]:
            raise ValueError("predictions and actual must be the same length!")
    
>       raise NotImplementedError
E       NotImplementedError

src/metrics.py:53: NotImplementedError
______________________________________ test_numpy_flip_and_slice_matrix ______________________________________

    def test_numpy_flip_and_slice_matrix():
    
        pairs = [
            (np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]]),
             np.array([[2, 1, 0], [11, 10, 9]])),
            (np.array([[ 2,  6, 16, 18, 13, 13, 17]]).T,
             np.array([[2, 18, 17]]).T),
            (np.array([[ 0, 17, 14,  4]]),
             np.array([[ 4, 14, 17,  0]]))
        ]
        for before, after in pairs:
            msg = f"flip_and_slice_matrix({before}) should return {after}"
            before = before.astype(int)
>           assert np.array_equal(src.numpy_practice.flip_and_slice_matrix(before), after), msg

tests/test_numpy.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11],
       [12, 13, 14]])

    def flip_and_slice_matrix(x):
        """
        Take the matrix x and flip it horizontally, then take the every third row.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2],
            ...               [ 3,  4,  5],
            ...               [ 6,  7,  8],
            ...               [ 9, 10, 11],
            ...               [12, 13, 14]])
            >>> flip_and_slice_matrix(x)
            array([[2, 1, 0],
                   [11, 10, 9]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.indexing.html#basics-indexing
    
        Args:
          x: a matrix
        Returns:
          a numpy matrix
        """
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:137: NotImplementedError
____________________________________ test_numpy_divide_matrix_along_rows _____________________________________

    def test_numpy_divide_matrix_along_rows():
    
        trios = [
            (np.array([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]),
             np.array([1, 2, 4]),
             np.array([[0, 1, 2, 3], [2, 2.5, 3, 3.5], [2, 2.25, 2.5, 2.75]])),
            (np.array([[2, 14], [2, 17], [8, 8], [12, 9], [9, 6], [10, 4]]),
             np.array([1, 1, 2, 3, 3, 2]),
             np.array([[2, 14], [2, 17], [4, 4], [4, 3], [3, 2], [5, 2]]))
        ]
        for (x, y, target) in trios:
            msg = f"divide_matrix_along_rows({x}, {y}) should return {target}"
>           assert np.array_equal(src.numpy_practice.divide_matrix_along_rows(x, y), target), msg

tests/test_numpy.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]]), y = array([1, 2, 4])

    def divide_matrix_along_rows(x, y):
        """
        Take the matrix x and divide it by the vector y, such that
            the ith row of x is divided by the ith value of y.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2,  3],
            ...               [ 4,  5,  6,  7],
            ...               [ 8,  9, 10, 11]])
            >>> y = np.array([1, 2, 4])
            >>> divide_rows(x, y)
            array([[0.  , 1.  , 2.  , 3.  ],
                   [2.  , 2.5 , 3.  , 3.5 ],
                   [2.  , 2.25, 2.5 , 2.75]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.broadcasting.html
        You should use one of:
            - np.reshape: https://numpy.org/doc/stable/reference/generated/numpy.reshape.html
            - np.newaxis: https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis
    
        Args:
          x: a matrix
          y: a vector with as many entries as x has rows
        Returns:
          a numpy matrix
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:171: NotImplementedError
------------------------------------------ Captured stdout teardown ------------------------------------------

======================
Output of autograder
======================
# of tests:	8/19 tests passed
Overall score:	9/100
======================
FAIL: test_train_test_split
FAIL: test_cross_validation
FAIL: test_decision_tree_binary_predict
FAIL: test_decision_tree_continuous_predict
FAIL: test_information_gain
FAIL: test_decision_tree_run
FAIL: test_predict_mode
FAIL: test_comparisons
FAIL: test_metrics
PASS: test_hello_world
PASS: test_numpy_replace_nonfinite_in_place
PASS: test_numpy_replace_nans_out_of_place
PASS: test_numpy_find_mode
FAIL: test_numpy_flip_and_slice_matrix
FAIL: test_numpy_divide_matrix_along_rows
======================
============================================== warnings summary ==============================================
tests/test_data.py::test_load_data
  /Users/ankitaroychoudhury/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2
    warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================================== short test summary info ===========================================
FAILED tests/test_data.py::test_train_test_split - NotImplementedError
FAILED tests/test_data.py::test_cross_validation - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_binary_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_continuous_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_information_gain - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_run - NotImplementedError
FAILED tests/test_experiment.py::test_predict_mode - NotImplementedError
FAILED tests/test_experiment.py::test_comparisons - NotImplementedError
FAILED tests/test_metrics.py::test_metrics - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_flip_and_slice_matrix - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_divide_matrix_along_rows - NotImplementedError
================================== 11 failed, 9 passed, 1 warning in 1.59s ===================================
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % pytest
============================================ test session starts =============================================
platform darwin -- Python 3.9.13, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury
plugins: anyio-3.5.0
collected 20 items                                                                                           

tests/test_a_environment.py .                                                                          [  5%]
tests/test_a_setup.py ...                                                                              [ 20%]
tests/test_data.py .FF                                                                                 [ 35%]
tests/test_decision_tree.py FFFF                                                                       [ 55%]
tests/test_experiment.py FF                                                                            [ 65%]
tests/test_metrics.py F                                                                                [ 70%]
tests/test_numpy.py ....FF                                                                             [100%]

================================================== FAILURES ==================================================
___________________________________________ test_train_test_split ____________________________________________

    def test_train_test_split():
        from src import load_data
        from src import train_test_split
    
        n_features = np.random.randint(5, 20)
        n_samples = np.random.randint(50, 150)
        features, targets, attribute_names = write_random_csv_file(n_features, n_samples)
        fraction = np.random.rand()
    
>       output = train_test_split(features, targets, fraction)

tests/test_data.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[-1.44651999, -3.71564188,  1.25816366, ...,  0.80447792,
        -0.08783721,  0.09342423],
       [ 1.2261574...653,  0.04256156],
       [ 1.38669658, -0.56953588, -1.53503113, ...,  2.58977275,
         0.18927884, -1.01691339]])
labels = array([0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,
       0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,...0, 1, 1, 1, 1, 0,
       1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 1])
fraction = 0.7231136090927314

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
___________________________________________ test_cross_validation ____________________________________________

    def test_cross_validation():
        from src import load_data
        from src import cross_validation
    
        # Remember, your train_test_split should be deterministic
        # You shouldn't be randomly shuffling the data!
        n = 10
        features = np.arange(n).reshape(-1, 1)
        targets = np.arange(n).reshape(-1, 1)
        for folds in [2, 5, 10]:
>           cv = cross_validation(features, targets, folds)

tests/test_data.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
labels = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
n_folds = 2

    def cross_validation(features, labels, n_folds):
        """
        Split the data in `n_folds` different groups for cross-validation.
            Split the features and labels into a `n_folds` number of groups that
            divide the data as evenly as possible. Then for each group,
            return a tuple that treats that group as the test set and all
            other groups combine to make the training set.
    
            Note that this should be *deterministic*; don't shuffle the data.
            If there are 100 examples and you have 5 folds, each group
            should contain 20 examples and the first group should contain
            the first 20 examples.
    
            See test_cross_validation for expected behavior.
    
        Args:
            features: an NxK matrix of N examples, each with K features
            labels: an Nx1 array of N labels
            n_folds: the number of cross-validation groups
    
        Output:
            A list of tuples, where each tuple contains:
              (train_features, train_labels, test_features, test_labels)
        """
    
        assert features.shape[0] == labels.shape[0]
    
        if n_folds == 1:
            return [(features, labels, features, labels)]
>       raise NotImplementedError
E       NotImplementedError

src/data.py:92: NotImplementedError
_____________________________________ test_decision_tree_binary_predict ______________________________________

    def test_decision_tree_binary_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Outlook', 'Temp', 'Wind']
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Outlook", attribute_index=0,
            split_value=0.5, branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=0.5, branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
        examples = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [0, 1, 1]])
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7f93d186b6d0>
features = array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 1, 1],
       [0, 1, 1]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________ test_decision_tree_continuous_predict ____________________________________

    def test_decision_tree_continuous_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Wind', 'Temp', 'Outlook']
        examples = np.array([[1, 79.21, 1], [2, 90.56, 0], [7, 88.36, 1], [5, 84.02, 0], [1, 43.77, 0]])
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Wind", attribute_index=0,
            split_value=np.median(examples[:, 0]), branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=np.median(examples[:, 1]), branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
    
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7f93d1881ee0>
features = array([[ 1.  , 79.21,  1.  ],
       [ 2.  , 90.56,  0.  ],
       [ 7.  , 88.36,  1.  ],
       [ 5.  , 84.02,  0.  ],
       [ 1.  , 43.77,  0.  ]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________________ test_information_gain ____________________________________________

    def test_information_gain():
        from src import load_data
        from src import information_gain
    
        _features, _targets, _attribute_names = load_data('data/play-tennis.csv')
>       iGHumidity = information_gain(_features, 2, _targets)

tests/test_decision_tree.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0, 0, 1, 0],
       [0, 0, 1, 1],
       [1, 0, 1, 0],
       [1, 1, 1, 0],
       [1, 1, 0, 0],
       [1, 1,...[0, 1, 0, 0],
       [1, 1, 0, 0],
       [0, 1, 0, 1],
       [1, 1, 1, 1],
       [1, 0, 0, 0],
       [1, 1, 1, 1]])
attribute_index = 2
labels = array([[0],
       [0],
       [1],
       [1],
       [1],
       [0],
       [1],
       [0],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0]])

    def information_gain(features, attribute_index, labels):
        """
        Information gain is how a decision tree makes decisions on how to create
        split points in the tree. Information gain is measured in terms of entropy.
        The goal of a decision tree is to decrease entropy at each split point as
        much as possible. This function should work perfectly or your decision tree
        will not work properly.
    
        Information gain is a central concept in many machine learning algorithms.
        In decision trees, it captures how effective splitting the tree on a
        specific attribute will be for the goal of classifying the training data
        correctly.  Consider data points S and an attribute A; we'll split S into
        two data points.
    
        For binary A: S(A == 0) and S(A == 1)
        For continuous A: S(A < m) and S(A >= m), where m is the median of A in S.
    
        Together, the two subsets make up S. If the attribute A were perfectly correlated with
        the class of each data point in S, then all points in a given subset will have the
        same class. Clearly, in this case, we want something that captures that A is a good
        attribute to use in the decision tree. This something is information gain. Formally:
    
            IG(S,A) = H(S) - H(S|A)
    
        where H is information entropy. Recall that entropy captures how orderly or chaotic
        a system is. A system that is very chaotic will evenly distribute probabilities to
        all outcomes (e.g. 50% chance of class 0, 50% chance of class 1). Machine learning
        algorithms work to decrease entropy, so as to make predictions that are
        accurate on testing data. Formally, H is defined as:
    
            H(S) = sum_{c in (groups in S)} -p(c) * log_2 p(c)
    
        To elaborate: for each group c in S, you compute the probability (or weight) of c:
    
            p(c) = (# of elements of group c in S) / (total # of elements in S)
    
        Then you compute the term for this group:
    
            -p(c) * log_2 p(c)
    
        Note: if p(c) is 0, we define `-p(c) * log_2 p(c)` as 0. You can see how
            we handle this in the provided `entropy()` function, to avoid how numpy
            defines `0 * log(0) = 0 * -inf = nan`.
    
        Then compute the sum across all groups: either classes 0 and 1 for binary data, or
        for the above-median and below-median classes for continuous data. The final number
        is the entropy. To gain more intution about entropy, consider the following - what
        does H(S) = 0 tell you about S?
    
        Information gain is an extension of entropy. The equation for information gain
        involves comparing the entropy of the set and the entropy of the set when conditioned
        on selecting for a single attribute (e.g. S(A == 0)).
    
        For more details: https://en.wikipedia.org/wiki/ID3_algorithm#The_ID3_metrics
    
        Args:
            features (np.array): numpy array containing features for each example.
            attribute_index (int): which column of features to take when computing the
                information gain
            labels (np.array): numpy array containing labels corresponding to each example.
    
        Returns:
            information_gain (float): information gain if the features were split on the
                attribute_index.
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:262: NotImplementedError
___________________________________________ test_decision_tree_run ___________________________________________

    def test_decision_tree_run():
        goals = {
            'xor-easy.csv': {1.0: 1.0},
            'xor-hard.csv': {1.0: 0.8, 0.8: 1.0},
            'ivy-league.csv': {1.0: .9, 0.8: 0.6,},
            'majority-rule.csv': {1.0: 1.0, 0.8: 0.8,},
            'circles-hard.csv': {1.0: 0.7},
            'circles-easy.csv': {1.0: 0.8},
            'blobs.csv': {1.0: 0.8, 0.8: 0.9,},
        }
    
        order = [
            'xor-easy.csv',
            'ivy-league.csv',
            'majority-rule.csv',
            'xor-hard.csv',
            'blobs.csv',
            'circles-easy.csv',
            'circles-hard.csv',
        ]
    
        learner_type = 'decision_tree'
        for key in order:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_decision_tree.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
src/decision_tree.py:125: in fit
    self.tree = self._create_tree(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7f93d1868bb0>
features = array([[1, 1],
       [0, 0],
       [1, 0],
       [0, 1]])
labels = array([[0],
       [0],
       [1],
       [1]]), used_attributes = [], default = 0

    def _create_tree(self, features, labels, used_attributes, default):
        '''
        Create a decision tree recursively.
        1. If no data remains, return a leaf node with return_value `default`
            (e.g., if features and labels are both empty)
    
        2. If all labels are the same, return a leaf node with
            that label as the return_value
    
        3. For each attribute, compute the information gain from splitting on it
    
        3.1. If that is in `used_attributes`, instead set information gain to -1
            to prevent us from reusing it
        3.2. If all attributes are used, return a leaf node with the mode class
    
        3.3.1 If at least one attribute, has a non-negative information gain,
            select `best_attribute` with the largest information gain;
        3.3.2 Split data (feature & label) according to attribute values,
            where: `attribute_values = features[:, best_attribute]`;
        3.3.3 If that attribute's values are binary, split on 0.5;
            Otherwise, split on the median of the attribute values;
    
        3.4 Create a non-leaf node with the specified attribute_name,
              attribute_index, and split_value, and then RECURSIVELY
              set build its branches using self._create_tree.
              After recursing, return the node.
        '''
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:160: NotImplementedError
_____________________________________________ test_predict_mode ______________________________________________

    def test_predict_mode():
        goals = {
          'ivy-league.csv': {1.0: 0.5},
          'majority-rule.csv': {1.0: 0.6},
          'circles-easy.csv': {1.0: 0.6},
          'blobs.csv': {1.0: 0.55},
        }
    
        learner_type = 'predict_mode'
        for key in goals:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_experiment.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.predict_mode.PredictMode object at 0x7f93d186a160>
features = array([[1, 1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 1, 0, 0]...      [0, 1, 1, 0, 1, 0, 1],
       [0, 1, 1, 0, 0, 1, 1],
       [0, 1, 1, 0, 0, 0, 1],
       [0, 1, 1, 0, 0, 1, 1]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0]...      [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0],
       [0]])

    def fit(self, features, labels):
        """
        Looking at the provided labels, record the mode (most common) label.
    
        You may call your `find_mode` function from `src.numpy_practice`
    
        Args:
            features (np.array): numpy array of shape (n, d)
                 where n is number of examples and d is number of features.
            labels (np.array): numpy array containing true labels for each of the N
                examples.
        Output:
            None: Simply update self.most_common_class with the most common label
        """
>       raise NotImplementedError
E       NotImplementedError

src/predict_mode.py:35: NotImplementedError
______________________________________________ test_comparisons ______________________________________________

    def test_comparisons():
        comparisons = [
            # predict_mode beats decision tree on majority rule w/ 0.7 frac
            ('majority-rule.csv', 0.7, 'predict_mode', 'decision_tree',
             {}, {}),
    
            # decision tree beats predict mode on majority rule w/ 1.0 frac
            ('majority-rule.csv', 1.0, 'decision_tree', 'predict_mode',
             {}, {}),
        ]
    
        for i, comparison in enumerate(comparisons):
            (key, fraction, method_a, method_b,
             kwargs_a, kwargs_b) = comparison
    
            data_path = datasets.get(key)
>           acc_a = run(data_path, method_a, fraction, **kwargs_a)

tests/test_experiment.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:55: in run
    X_train, Y_train, X_test, Y_test = train_test_split(X, Y, fraction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 0, 0],
       [1,... 1, 0, 0],
       [0, 0, 0, 0, 1, 1],
       [0, 0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0, 1],
       [0, 0, 0, 0, 0, 0]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [1],
       [1]...      [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0]])
fraction = 0.7

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
________________________________________________ test_metrics ________________________________________________

    def test_metrics():
        from sklearn.metrics import accuracy_score
        from src import compute_accuracy
    
        y_true, y_pred = make_fake_data()
        _actual = accuracy_score(y_true, y_pred)
>       _est = compute_accuracy(y_true, y_pred)

tests/test_metrics.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = array([ True, False, False,  True, False,  True,  True, False, False,
        True,  True,  True,  True,  True,  True,... True, False,  True, False,  True,
        True,  True,  True, False,  True, False, False, False,  True,
        True])
predictions = array([ True, False, False, False,  True,  True, False, False,  True,
        True,  True,  True, False, False,  True,... True, False, False,  True, False,
       False,  True,  True,  True, False, False, False,  True,  True,
       False])

    def compute_accuracy(actual, predictions):
        """
        Given predictions (an N-length numpy vector) and actual labels (an N-length
        numpy vector), compute the accuracy:
    
        Hint: implement and use the compute_confusion_matrix function!
    
        Args:
            actual (np.array): predicted labels of length N
            predictions (np.array): predicted labels of length N
    
        Output:
            accuracy (float): accuracy
        """
        if predictions.shape[0] != actual.shape[0]:
            raise ValueError("predictions and actual must be the same length!")
    
>       raise NotImplementedError
E       NotImplementedError

src/metrics.py:53: NotImplementedError
______________________________________ test_numpy_flip_and_slice_matrix ______________________________________

    def test_numpy_flip_and_slice_matrix():
    
        pairs = [
            (np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]]),
             np.array([[2, 1, 0], [11, 10, 9]])),
            (np.array([[ 2,  6, 16, 18, 13, 13, 17]]).T,
             np.array([[2, 18, 17]]).T),
            (np.array([[ 0, 17, 14,  4]]),
             np.array([[ 4, 14, 17,  0]]))
        ]
        for before, after in pairs:
            msg = f"flip_and_slice_matrix({before}) should return {after}"
            before = before.astype(int)
>           assert np.array_equal(src.numpy_practice.flip_and_slice_matrix(before), after), msg

tests/test_numpy.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11],
       [12, 13, 14]])

    def flip_and_slice_matrix(x):
        """
        Take the matrix x and flip it horizontally, then take the every third row.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2],
            ...               [ 3,  4,  5],
            ...               [ 6,  7,  8],
            ...               [ 9, 10, 11],
            ...               [12, 13, 14]])
            >>> flip_and_slice_matrix(x)
            array([[2, 1, 0],
                   [11, 10, 9]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.indexing.html#basics-indexing
    
        Args:
          x: a matrix
        Returns:
          a numpy matrix
        """
>       raise np.flip(x,axis=1)[::3]
E       TypeError: exceptions must derive from BaseException

src/numpy_practice.py:137: TypeError
____________________________________ test_numpy_divide_matrix_along_rows _____________________________________

    def test_numpy_divide_matrix_along_rows():
    
        trios = [
            (np.array([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]),
             np.array([1, 2, 4]),
             np.array([[0, 1, 2, 3], [2, 2.5, 3, 3.5], [2, 2.25, 2.5, 2.75]])),
            (np.array([[2, 14], [2, 17], [8, 8], [12, 9], [9, 6], [10, 4]]),
             np.array([1, 1, 2, 3, 3, 2]),
             np.array([[2, 14], [2, 17], [4, 4], [4, 3], [3, 2], [5, 2]]))
        ]
        for (x, y, target) in trios:
            msg = f"divide_matrix_along_rows({x}, {y}) should return {target}"
>           assert np.array_equal(src.numpy_practice.divide_matrix_along_rows(x, y), target), msg

tests/test_numpy.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]]), y = array([1, 2, 4])

    def divide_matrix_along_rows(x, y):
        """
        Take the matrix x and divide it by the vector y, such that
            the ith row of x is divided by the ith value of y.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2,  3],
            ...               [ 4,  5,  6,  7],
            ...               [ 8,  9, 10, 11]])
            >>> y = np.array([1, 2, 4])
            >>> divide_rows(x, y)
            array([[0.  , 1.  , 2.  , 3.  ],
                   [2.  , 2.5 , 3.  , 3.5 ],
                   [2.  , 2.25, 2.5 , 2.75]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.broadcasting.html
        You should use one of:
            - np.reshape: https://numpy.org/doc/stable/reference/generated/numpy.reshape.html
            - np.newaxis: https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis
    
        Args:
          x: a matrix
          y: a vector with as many entries as x has rows
        Returns:
          a numpy matrix
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:171: NotImplementedError
------------------------------------------ Captured stdout teardown ------------------------------------------

======================
Output of autograder
======================
# of tests:	8/19 tests passed
Overall score:	9/100
======================
FAIL: test_train_test_split
FAIL: test_cross_validation
FAIL: test_decision_tree_binary_predict
FAIL: test_decision_tree_continuous_predict
FAIL: test_information_gain
FAIL: test_decision_tree_run
FAIL: test_predict_mode
FAIL: test_comparisons
FAIL: test_metrics
PASS: test_hello_world
PASS: test_numpy_replace_nonfinite_in_place
PASS: test_numpy_replace_nans_out_of_place
PASS: test_numpy_find_mode
FAIL: test_numpy_flip_and_slice_matrix
FAIL: test_numpy_divide_matrix_along_rows
======================
============================================== warnings summary ==============================================
tests/test_data.py::test_load_data
  /Users/ankitaroychoudhury/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2
    warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================================== short test summary info ===========================================
FAILED tests/test_data.py::test_train_test_split - NotImplementedError
FAILED tests/test_data.py::test_cross_validation - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_binary_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_continuous_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_information_gain - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_run - NotImplementedError
FAILED tests/test_experiment.py::test_predict_mode - NotImplementedError
FAILED tests/test_experiment.py::test_comparisons - NotImplementedError
FAILED tests/test_metrics.py::test_metrics - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_flip_and_slice_matrix - TypeError: exceptions must derive from BaseE...
FAILED tests/test_numpy.py::test_numpy_divide_matrix_along_rows - NotImplementedError
================================== 11 failed, 9 passed, 1 warning in 1.59s ===================================
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % pytest
============================================ test session starts =============================================
platform darwin -- Python 3.9.13, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury
plugins: anyio-3.5.0
collected 20 items                                                                                           

tests/test_a_environment.py .                                                                          [  5%]
tests/test_a_setup.py ...                                                                              [ 20%]
tests/test_data.py .FF                                                                                 [ 35%]
tests/test_decision_tree.py FFFF                                                                       [ 55%]
tests/test_experiment.py FF                                                                            [ 65%]
tests/test_metrics.py F                                                                                [ 70%]
tests/test_numpy.py ....FF                                                                             [100%]

================================================== FAILURES ==================================================
___________________________________________ test_train_test_split ____________________________________________

    def test_train_test_split():
        from src import load_data
        from src import train_test_split
    
        n_features = np.random.randint(5, 20)
        n_samples = np.random.randint(50, 150)
        features, targets, attribute_names = write_random_csv_file(n_features, n_samples)
        fraction = np.random.rand()
    
>       output = train_test_split(features, targets, fraction)

tests/test_data.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[-0.55635494, -0.17396271, -0.02807583, ...,  1.40426975,
        -0.11018584,  0.43337812],
       [-1.5454968...405,  1.69473821],
       [ 1.62112442,  0.54626401,  0.043546  , ..., -1.23190017,
         0.10965003, -1.49332738]])
labels = array([1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,
       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,
       0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0])
fraction = 0.4845107447662851

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
___________________________________________ test_cross_validation ____________________________________________

    def test_cross_validation():
        from src import load_data
        from src import cross_validation
    
        # Remember, your train_test_split should be deterministic
        # You shouldn't be randomly shuffling the data!
        n = 10
        features = np.arange(n).reshape(-1, 1)
        targets = np.arange(n).reshape(-1, 1)
        for folds in [2, 5, 10]:
>           cv = cross_validation(features, targets, folds)

tests/test_data.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
labels = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
n_folds = 2

    def cross_validation(features, labels, n_folds):
        """
        Split the data in `n_folds` different groups for cross-validation.
            Split the features and labels into a `n_folds` number of groups that
            divide the data as evenly as possible. Then for each group,
            return a tuple that treats that group as the test set and all
            other groups combine to make the training set.
    
            Note that this should be *deterministic*; don't shuffle the data.
            If there are 100 examples and you have 5 folds, each group
            should contain 20 examples and the first group should contain
            the first 20 examples.
    
            See test_cross_validation for expected behavior.
    
        Args:
            features: an NxK matrix of N examples, each with K features
            labels: an Nx1 array of N labels
            n_folds: the number of cross-validation groups
    
        Output:
            A list of tuples, where each tuple contains:
              (train_features, train_labels, test_features, test_labels)
        """
    
        assert features.shape[0] == labels.shape[0]
    
        if n_folds == 1:
            return [(features, labels, features, labels)]
>       raise NotImplementedError
E       NotImplementedError

src/data.py:92: NotImplementedError
_____________________________________ test_decision_tree_binary_predict ______________________________________

    def test_decision_tree_binary_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Outlook', 'Temp', 'Wind']
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Outlook", attribute_index=0,
            split_value=0.5, branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=0.5, branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
        examples = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [0, 1, 1]])
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fe491c02310>
features = array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 1, 1],
       [0, 1, 1]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________ test_decision_tree_continuous_predict ____________________________________

    def test_decision_tree_continuous_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Wind', 'Temp', 'Outlook']
        examples = np.array([[1, 79.21, 1], [2, 90.56, 0], [7, 88.36, 1], [5, 84.02, 0], [1, 43.77, 0]])
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Wind", attribute_index=0,
            split_value=np.median(examples[:, 0]), branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=np.median(examples[:, 1]), branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
    
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fe491c19e50>
features = array([[ 1.  , 79.21,  1.  ],
       [ 2.  , 90.56,  0.  ],
       [ 7.  , 88.36,  1.  ],
       [ 5.  , 84.02,  0.  ],
       [ 1.  , 43.77,  0.  ]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________________ test_information_gain ____________________________________________

    def test_information_gain():
        from src import load_data
        from src import information_gain
    
        _features, _targets, _attribute_names = load_data('data/play-tennis.csv')
>       iGHumidity = information_gain(_features, 2, _targets)

tests/test_decision_tree.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0, 0, 1, 0],
       [0, 0, 1, 1],
       [1, 0, 1, 0],
       [1, 1, 1, 0],
       [1, 1, 0, 0],
       [1, 1,...[0, 1, 0, 0],
       [1, 1, 0, 0],
       [0, 1, 0, 1],
       [1, 1, 1, 1],
       [1, 0, 0, 0],
       [1, 1, 1, 1]])
attribute_index = 2
labels = array([[0],
       [0],
       [1],
       [1],
       [1],
       [0],
       [1],
       [0],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0]])

    def information_gain(features, attribute_index, labels):
        """
        Information gain is how a decision tree makes decisions on how to create
        split points in the tree. Information gain is measured in terms of entropy.
        The goal of a decision tree is to decrease entropy at each split point as
        much as possible. This function should work perfectly or your decision tree
        will not work properly.
    
        Information gain is a central concept in many machine learning algorithms.
        In decision trees, it captures how effective splitting the tree on a
        specific attribute will be for the goal of classifying the training data
        correctly.  Consider data points S and an attribute A; we'll split S into
        two data points.
    
        For binary A: S(A == 0) and S(A == 1)
        For continuous A: S(A < m) and S(A >= m), where m is the median of A in S.
    
        Together, the two subsets make up S. If the attribute A were perfectly correlated with
        the class of each data point in S, then all points in a given subset will have the
        same class. Clearly, in this case, we want something that captures that A is a good
        attribute to use in the decision tree. This something is information gain. Formally:
    
            IG(S,A) = H(S) - H(S|A)
    
        where H is information entropy. Recall that entropy captures how orderly or chaotic
        a system is. A system that is very chaotic will evenly distribute probabilities to
        all outcomes (e.g. 50% chance of class 0, 50% chance of class 1). Machine learning
        algorithms work to decrease entropy, so as to make predictions that are
        accurate on testing data. Formally, H is defined as:
    
            H(S) = sum_{c in (groups in S)} -p(c) * log_2 p(c)
    
        To elaborate: for each group c in S, you compute the probability (or weight) of c:
    
            p(c) = (# of elements of group c in S) / (total # of elements in S)
    
        Then you compute the term for this group:
    
            -p(c) * log_2 p(c)
    
        Note: if p(c) is 0, we define `-p(c) * log_2 p(c)` as 0. You can see how
            we handle this in the provided `entropy()` function, to avoid how numpy
            defines `0 * log(0) = 0 * -inf = nan`.
    
        Then compute the sum across all groups: either classes 0 and 1 for binary data, or
        for the above-median and below-median classes for continuous data. The final number
        is the entropy. To gain more intution about entropy, consider the following - what
        does H(S) = 0 tell you about S?
    
        Information gain is an extension of entropy. The equation for information gain
        involves comparing the entropy of the set and the entropy of the set when conditioned
        on selecting for a single attribute (e.g. S(A == 0)).
    
        For more details: https://en.wikipedia.org/wiki/ID3_algorithm#The_ID3_metrics
    
        Args:
            features (np.array): numpy array containing features for each example.
            attribute_index (int): which column of features to take when computing the
                information gain
            labels (np.array): numpy array containing labels corresponding to each example.
    
        Returns:
            information_gain (float): information gain if the features were split on the
                attribute_index.
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:262: NotImplementedError
___________________________________________ test_decision_tree_run ___________________________________________

    def test_decision_tree_run():
        goals = {
            'xor-easy.csv': {1.0: 1.0},
            'xor-hard.csv': {1.0: 0.8, 0.8: 1.0},
            'ivy-league.csv': {1.0: .9, 0.8: 0.6,},
            'majority-rule.csv': {1.0: 1.0, 0.8: 0.8,},
            'circles-hard.csv': {1.0: 0.7},
            'circles-easy.csv': {1.0: 0.8},
            'blobs.csv': {1.0: 0.8, 0.8: 0.9,},
        }
    
        order = [
            'xor-easy.csv',
            'ivy-league.csv',
            'majority-rule.csv',
            'xor-hard.csv',
            'blobs.csv',
            'circles-easy.csv',
            'circles-hard.csv',
        ]
    
        learner_type = 'decision_tree'
        for key in order:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_decision_tree.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
src/decision_tree.py:125: in fit
    self.tree = self._create_tree(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fe4a252ca30>
features = array([[1, 1],
       [0, 0],
       [1, 0],
       [0, 1]])
labels = array([[0],
       [0],
       [1],
       [1]]), used_attributes = [], default = 0

    def _create_tree(self, features, labels, used_attributes, default):
        '''
        Create a decision tree recursively.
        1. If no data remains, return a leaf node with return_value `default`
            (e.g., if features and labels are both empty)
    
        2. If all labels are the same, return a leaf node with
            that label as the return_value
    
        3. For each attribute, compute the information gain from splitting on it
    
        3.1. If that is in `used_attributes`, instead set information gain to -1
            to prevent us from reusing it
        3.2. If all attributes are used, return a leaf node with the mode class
    
        3.3.1 If at least one attribute, has a non-negative information gain,
            select `best_attribute` with the largest information gain;
        3.3.2 Split data (feature & label) according to attribute values,
            where: `attribute_values = features[:, best_attribute]`;
        3.3.3 If that attribute's values are binary, split on 0.5;
            Otherwise, split on the median of the attribute values;
    
        3.4 Create a non-leaf node with the specified attribute_name,
              attribute_index, and split_value, and then RECURSIVELY
              set build its branches using self._create_tree.
              After recursing, return the node.
        '''
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:160: NotImplementedError
_____________________________________________ test_predict_mode ______________________________________________

    def test_predict_mode():
        goals = {
          'ivy-league.csv': {1.0: 0.5},
          'majority-rule.csv': {1.0: 0.6},
          'circles-easy.csv': {1.0: 0.6},
          'blobs.csv': {1.0: 0.55},
        }
    
        learner_type = 'predict_mode'
        for key in goals:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_experiment.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.predict_mode.PredictMode object at 0x7fe491c19610>
features = array([[1, 1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 1, 0, 0]...      [0, 1, 1, 0, 1, 0, 1],
       [0, 1, 1, 0, 0, 1, 1],
       [0, 1, 1, 0, 0, 0, 1],
       [0, 1, 1, 0, 0, 1, 1]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0]...      [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0],
       [0]])

    def fit(self, features, labels):
        """
        Looking at the provided labels, record the mode (most common) label.
    
        You may call your `find_mode` function from `src.numpy_practice`
    
        Args:
            features (np.array): numpy array of shape (n, d)
                 where n is number of examples and d is number of features.
            labels (np.array): numpy array containing true labels for each of the N
                examples.
        Output:
            None: Simply update self.most_common_class with the most common label
        """
>       raise NotImplementedError
E       NotImplementedError

src/predict_mode.py:35: NotImplementedError
______________________________________________ test_comparisons ______________________________________________

    def test_comparisons():
        comparisons = [
            # predict_mode beats decision tree on majority rule w/ 0.7 frac
            ('majority-rule.csv', 0.7, 'predict_mode', 'decision_tree',
             {}, {}),
    
            # decision tree beats predict mode on majority rule w/ 1.0 frac
            ('majority-rule.csv', 1.0, 'decision_tree', 'predict_mode',
             {}, {}),
        ]
    
        for i, comparison in enumerate(comparisons):
            (key, fraction, method_a, method_b,
             kwargs_a, kwargs_b) = comparison
    
            data_path = datasets.get(key)
>           acc_a = run(data_path, method_a, fraction, **kwargs_a)

tests/test_experiment.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:55: in run
    X_train, Y_train, X_test, Y_test = train_test_split(X, Y, fraction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 0, 0],
       [1,... 1, 0, 0],
       [0, 0, 0, 0, 1, 1],
       [0, 0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0, 1],
       [0, 0, 0, 0, 0, 0]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [1],
       [1]...      [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0]])
fraction = 0.7

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
________________________________________________ test_metrics ________________________________________________

    def test_metrics():
        from sklearn.metrics import accuracy_score
        from src import compute_accuracy
    
        y_true, y_pred = make_fake_data()
        _actual = accuracy_score(y_true, y_pred)
>       _est = compute_accuracy(y_true, y_pred)

tests/test_metrics.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = array([False, False, False,  True,  True, False,  True, False,  True,
        True, False,  True,  True,  True, False,... True, False, False, False, False,
       False, False,  True,  True,  True,  True, False, False, False,
        True])
predictions = array([False, False,  True,  True,  True,  True,  True, False,  True,
       False, False, False, False,  True, False,... True, False, False, False, False,
        True, False, False,  True,  True,  True,  True,  True,  True,
       False])

    def compute_accuracy(actual, predictions):
        """
        Given predictions (an N-length numpy vector) and actual labels (an N-length
        numpy vector), compute the accuracy:
    
        Hint: implement and use the compute_confusion_matrix function!
    
        Args:
            actual (np.array): predicted labels of length N
            predictions (np.array): predicted labels of length N
    
        Output:
            accuracy (float): accuracy
        """
        if predictions.shape[0] != actual.shape[0]:
            raise ValueError("predictions and actual must be the same length!")
    
>       raise NotImplementedError
E       NotImplementedError

src/metrics.py:53: NotImplementedError
______________________________________ test_numpy_flip_and_slice_matrix ______________________________________

    def test_numpy_flip_and_slice_matrix():
    
        pairs = [
            (np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]]),
             np.array([[2, 1, 0], [11, 10, 9]])),
            (np.array([[ 2,  6, 16, 18, 13, 13, 17]]).T,
             np.array([[2, 18, 17]]).T),
            (np.array([[ 0, 17, 14,  4]]),
             np.array([[ 4, 14, 17,  0]]))
        ]
        for before, after in pairs:
            msg = f"flip_and_slice_matrix({before}) should return {after}"
            before = before.astype(int)
>           assert np.array_equal(src.numpy_practice.flip_and_slice_matrix(before), after), msg

tests/test_numpy.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11],
       [12, 13, 14]])

    def flip_and_slice_matrix(x):
        """
        Take the matrix x and flip it horizontally, then take the every third row.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2],
            ...               [ 3,  4,  5],
            ...               [ 6,  7,  8],
            ...               [ 9, 10, 11],
            ...               [12, 13, 14]])
            >>> flip_and_slice_matrix(x)
            array([[2, 1, 0],
                   [11, 10, 9]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.indexing.html#basics-indexing
    
        Args:
          x: a matrix
        Returns:
          a numpy matrix
        """
        x1 = np.flip(x,axis=1)
>       raise x1[::3]
E       TypeError: exceptions must derive from BaseException

src/numpy_practice.py:138: TypeError
____________________________________ test_numpy_divide_matrix_along_rows _____________________________________

    def test_numpy_divide_matrix_along_rows():
    
        trios = [
            (np.array([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]),
             np.array([1, 2, 4]),
             np.array([[0, 1, 2, 3], [2, 2.5, 3, 3.5], [2, 2.25, 2.5, 2.75]])),
            (np.array([[2, 14], [2, 17], [8, 8], [12, 9], [9, 6], [10, 4]]),
             np.array([1, 1, 2, 3, 3, 2]),
             np.array([[2, 14], [2, 17], [4, 4], [4, 3], [3, 2], [5, 2]]))
        ]
        for (x, y, target) in trios:
            msg = f"divide_matrix_along_rows({x}, {y}) should return {target}"
>           assert np.array_equal(src.numpy_practice.divide_matrix_along_rows(x, y), target), msg

tests/test_numpy.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]]), y = array([1, 2, 4])

    def divide_matrix_along_rows(x, y):
        """
        Take the matrix x and divide it by the vector y, such that
            the ith row of x is divided by the ith value of y.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2,  3],
            ...               [ 4,  5,  6,  7],
            ...               [ 8,  9, 10, 11]])
            >>> y = np.array([1, 2, 4])
            >>> divide_rows(x, y)
            array([[0.  , 1.  , 2.  , 3.  ],
                   [2.  , 2.5 , 3.  , 3.5 ],
                   [2.  , 2.25, 2.5 , 2.75]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.broadcasting.html
        You should use one of:
            - np.reshape: https://numpy.org/doc/stable/reference/generated/numpy.reshape.html
            - np.newaxis: https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis
    
        Args:
          x: a matrix
          y: a vector with as many entries as x has rows
        Returns:
          a numpy matrix
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:171: NotImplementedError
------------------------------------------ Captured stdout teardown ------------------------------------------

======================
Output of autograder
======================
# of tests:	8/19 tests passed
Overall score:	9/100
======================
FAIL: test_train_test_split
FAIL: test_cross_validation
FAIL: test_decision_tree_binary_predict
FAIL: test_decision_tree_continuous_predict
FAIL: test_information_gain
FAIL: test_decision_tree_run
FAIL: test_predict_mode
FAIL: test_comparisons
FAIL: test_metrics
PASS: test_hello_world
PASS: test_numpy_replace_nonfinite_in_place
PASS: test_numpy_replace_nans_out_of_place
PASS: test_numpy_find_mode
FAIL: test_numpy_flip_and_slice_matrix
FAIL: test_numpy_divide_matrix_along_rows
======================
============================================== warnings summary ==============================================
tests/test_data.py::test_load_data
  /Users/ankitaroychoudhury/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2
    warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================================== short test summary info ===========================================
FAILED tests/test_data.py::test_train_test_split - NotImplementedError
FAILED tests/test_data.py::test_cross_validation - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_binary_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_continuous_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_information_gain - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_run - NotImplementedError
FAILED tests/test_experiment.py::test_predict_mode - NotImplementedError
FAILED tests/test_experiment.py::test_comparisons - NotImplementedError
FAILED tests/test_metrics.py::test_metrics - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_flip_and_slice_matrix - TypeError: exceptions must derive from BaseE...
FAILED tests/test_numpy.py::test_numpy_divide_matrix_along_rows - NotImplementedError
================================== 11 failed, 9 passed, 1 warning in 1.31s ===================================
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % pytest
============================================ test session starts =============================================
platform darwin -- Python 3.9.13, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury
plugins: anyio-3.5.0
collected 20 items                                                                                           

tests/test_a_environment.py .                                                                          [  5%]
tests/test_a_setup.py ...                                                                              [ 20%]
tests/test_data.py .FF                                                                                 [ 35%]
tests/test_decision_tree.py FFFF                                                                       [ 55%]
tests/test_experiment.py FF                                                                            [ 65%]
tests/test_metrics.py F                                                                                [ 70%]
tests/test_numpy.py ....FF                                                                             [100%]

================================================== FAILURES ==================================================
___________________________________________ test_train_test_split ____________________________________________

    def test_train_test_split():
        from src import load_data
        from src import train_test_split
    
        n_features = np.random.randint(5, 20)
        n_samples = np.random.randint(50, 150)
        features, targets, attribute_names = write_random_csv_file(n_features, n_samples)
        fraction = np.random.rand()
    
>       output = train_test_split(features, targets, fraction)

tests/test_data.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[ 7.93950435e-01, -5.11583602e-01, -1.45947504e+00, ...,
        -1.16241280e+00, -6.84071440e-01, -7.10260807e...  [-5.38545171e-01, -5.91176256e-01, -2.27115955e-01, ...,
         3.31627154e-01, -1.11307112e+00,  3.45051725e-01]])
labels = array([0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,
       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1])
fraction = 0.5904429169559962

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
___________________________________________ test_cross_validation ____________________________________________

    def test_cross_validation():
        from src import load_data
        from src import cross_validation
    
        # Remember, your train_test_split should be deterministic
        # You shouldn't be randomly shuffling the data!
        n = 10
        features = np.arange(n).reshape(-1, 1)
        targets = np.arange(n).reshape(-1, 1)
        for folds in [2, 5, 10]:
>           cv = cross_validation(features, targets, folds)

tests/test_data.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
labels = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
n_folds = 2

    def cross_validation(features, labels, n_folds):
        """
        Split the data in `n_folds` different groups for cross-validation.
            Split the features and labels into a `n_folds` number of groups that
            divide the data as evenly as possible. Then for each group,
            return a tuple that treats that group as the test set and all
            other groups combine to make the training set.
    
            Note that this should be *deterministic*; don't shuffle the data.
            If there are 100 examples and you have 5 folds, each group
            should contain 20 examples and the first group should contain
            the first 20 examples.
    
            See test_cross_validation for expected behavior.
    
        Args:
            features: an NxK matrix of N examples, each with K features
            labels: an Nx1 array of N labels
            n_folds: the number of cross-validation groups
    
        Output:
            A list of tuples, where each tuple contains:
              (train_features, train_labels, test_features, test_labels)
        """
    
        assert features.shape[0] == labels.shape[0]
    
        if n_folds == 1:
            return [(features, labels, features, labels)]
>       raise NotImplementedError
E       NotImplementedError

src/data.py:92: NotImplementedError
_____________________________________ test_decision_tree_binary_predict ______________________________________

    def test_decision_tree_binary_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Outlook', 'Temp', 'Wind']
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Outlook", attribute_index=0,
            split_value=0.5, branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=0.5, branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
        examples = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [0, 1, 1]])
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fc91a7a37f0>
features = array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 1, 1],
       [0, 1, 1]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________ test_decision_tree_continuous_predict ____________________________________

    def test_decision_tree_continuous_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Wind', 'Temp', 'Outlook']
        examples = np.array([[1, 79.21, 1], [2, 90.56, 0], [7, 88.36, 1], [5, 84.02, 0], [1, 43.77, 0]])
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Wind", attribute_index=0,
            split_value=np.median(examples[:, 0]), branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=np.median(examples[:, 1]), branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
    
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fc91a79efd0>
features = array([[ 1.  , 79.21,  1.  ],
       [ 2.  , 90.56,  0.  ],
       [ 7.  , 88.36,  1.  ],
       [ 5.  , 84.02,  0.  ],
       [ 1.  , 43.77,  0.  ]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________________ test_information_gain ____________________________________________

    def test_information_gain():
        from src import load_data
        from src import information_gain
    
        _features, _targets, _attribute_names = load_data('data/play-tennis.csv')
>       iGHumidity = information_gain(_features, 2, _targets)

tests/test_decision_tree.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0, 0, 1, 0],
       [0, 0, 1, 1],
       [1, 0, 1, 0],
       [1, 1, 1, 0],
       [1, 1, 0, 0],
       [1, 1,...[0, 1, 0, 0],
       [1, 1, 0, 0],
       [0, 1, 0, 1],
       [1, 1, 1, 1],
       [1, 0, 0, 0],
       [1, 1, 1, 1]])
attribute_index = 2
labels = array([[0],
       [0],
       [1],
       [1],
       [1],
       [0],
       [1],
       [0],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0]])

    def information_gain(features, attribute_index, labels):
        """
        Information gain is how a decision tree makes decisions on how to create
        split points in the tree. Information gain is measured in terms of entropy.
        The goal of a decision tree is to decrease entropy at each split point as
        much as possible. This function should work perfectly or your decision tree
        will not work properly.
    
        Information gain is a central concept in many machine learning algorithms.
        In decision trees, it captures how effective splitting the tree on a
        specific attribute will be for the goal of classifying the training data
        correctly.  Consider data points S and an attribute A; we'll split S into
        two data points.
    
        For binary A: S(A == 0) and S(A == 1)
        For continuous A: S(A < m) and S(A >= m), where m is the median of A in S.
    
        Together, the two subsets make up S. If the attribute A were perfectly correlated with
        the class of each data point in S, then all points in a given subset will have the
        same class. Clearly, in this case, we want something that captures that A is a good
        attribute to use in the decision tree. This something is information gain. Formally:
    
            IG(S,A) = H(S) - H(S|A)
    
        where H is information entropy. Recall that entropy captures how orderly or chaotic
        a system is. A system that is very chaotic will evenly distribute probabilities to
        all outcomes (e.g. 50% chance of class 0, 50% chance of class 1). Machine learning
        algorithms work to decrease entropy, so as to make predictions that are
        accurate on testing data. Formally, H is defined as:
    
            H(S) = sum_{c in (groups in S)} -p(c) * log_2 p(c)
    
        To elaborate: for each group c in S, you compute the probability (or weight) of c:
    
            p(c) = (# of elements of group c in S) / (total # of elements in S)
    
        Then you compute the term for this group:
    
            -p(c) * log_2 p(c)
    
        Note: if p(c) is 0, we define `-p(c) * log_2 p(c)` as 0. You can see how
            we handle this in the provided `entropy()` function, to avoid how numpy
            defines `0 * log(0) = 0 * -inf = nan`.
    
        Then compute the sum across all groups: either classes 0 and 1 for binary data, or
        for the above-median and below-median classes for continuous data. The final number
        is the entropy. To gain more intution about entropy, consider the following - what
        does H(S) = 0 tell you about S?
    
        Information gain is an extension of entropy. The equation for information gain
        involves comparing the entropy of the set and the entropy of the set when conditioned
        on selecting for a single attribute (e.g. S(A == 0)).
    
        For more details: https://en.wikipedia.org/wiki/ID3_algorithm#The_ID3_metrics
    
        Args:
            features (np.array): numpy array containing features for each example.
            attribute_index (int): which column of features to take when computing the
                information gain
            labels (np.array): numpy array containing labels corresponding to each example.
    
        Returns:
            information_gain (float): information gain if the features were split on the
                attribute_index.
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:262: NotImplementedError
___________________________________________ test_decision_tree_run ___________________________________________

    def test_decision_tree_run():
        goals = {
            'xor-easy.csv': {1.0: 1.0},
            'xor-hard.csv': {1.0: 0.8, 0.8: 1.0},
            'ivy-league.csv': {1.0: .9, 0.8: 0.6,},
            'majority-rule.csv': {1.0: 1.0, 0.8: 0.8,},
            'circles-hard.csv': {1.0: 0.7},
            'circles-easy.csv': {1.0: 0.8},
            'blobs.csv': {1.0: 0.8, 0.8: 0.9,},
        }
    
        order = [
            'xor-easy.csv',
            'ivy-league.csv',
            'majority-rule.csv',
            'xor-hard.csv',
            'blobs.csv',
            'circles-easy.csv',
            'circles-hard.csv',
        ]
    
        learner_type = 'decision_tree'
        for key in order:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_decision_tree.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
src/decision_tree.py:125: in fit
    self.tree = self._create_tree(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fc91a7a3940>
features = array([[1, 1],
       [0, 0],
       [1, 0],
       [0, 1]])
labels = array([[0],
       [0],
       [1],
       [1]]), used_attributes = [], default = 0

    def _create_tree(self, features, labels, used_attributes, default):
        '''
        Create a decision tree recursively.
        1. If no data remains, return a leaf node with return_value `default`
            (e.g., if features and labels are both empty)
    
        2. If all labels are the same, return a leaf node with
            that label as the return_value
    
        3. For each attribute, compute the information gain from splitting on it
    
        3.1. If that is in `used_attributes`, instead set information gain to -1
            to prevent us from reusing it
        3.2. If all attributes are used, return a leaf node with the mode class
    
        3.3.1 If at least one attribute, has a non-negative information gain,
            select `best_attribute` with the largest information gain;
        3.3.2 Split data (feature & label) according to attribute values,
            where: `attribute_values = features[:, best_attribute]`;
        3.3.3 If that attribute's values are binary, split on 0.5;
            Otherwise, split on the median of the attribute values;
    
        3.4 Create a non-leaf node with the specified attribute_name,
              attribute_index, and split_value, and then RECURSIVELY
              set build its branches using self._create_tree.
              After recursing, return the node.
        '''
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:160: NotImplementedError
_____________________________________________ test_predict_mode ______________________________________________

    def test_predict_mode():
        goals = {
          'ivy-league.csv': {1.0: 0.5},
          'majority-rule.csv': {1.0: 0.6},
          'circles-easy.csv': {1.0: 0.6},
          'blobs.csv': {1.0: 0.55},
        }
    
        learner_type = 'predict_mode'
        for key in goals:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_experiment.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.predict_mode.PredictMode object at 0x7fc91a79e520>
features = array([[1, 1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 1, 0, 0]...      [0, 1, 1, 0, 1, 0, 1],
       [0, 1, 1, 0, 0, 1, 1],
       [0, 1, 1, 0, 0, 0, 1],
       [0, 1, 1, 0, 0, 1, 1]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0]...      [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0],
       [0]])

    def fit(self, features, labels):
        """
        Looking at the provided labels, record the mode (most common) label.
    
        You may call your `find_mode` function from `src.numpy_practice`
    
        Args:
            features (np.array): numpy array of shape (n, d)
                 where n is number of examples and d is number of features.
            labels (np.array): numpy array containing true labels for each of the N
                examples.
        Output:
            None: Simply update self.most_common_class with the most common label
        """
>       raise NotImplementedError
E       NotImplementedError

src/predict_mode.py:35: NotImplementedError
______________________________________________ test_comparisons ______________________________________________

    def test_comparisons():
        comparisons = [
            # predict_mode beats decision tree on majority rule w/ 0.7 frac
            ('majority-rule.csv', 0.7, 'predict_mode', 'decision_tree',
             {}, {}),
    
            # decision tree beats predict mode on majority rule w/ 1.0 frac
            ('majority-rule.csv', 1.0, 'decision_tree', 'predict_mode',
             {}, {}),
        ]
    
        for i, comparison in enumerate(comparisons):
            (key, fraction, method_a, method_b,
             kwargs_a, kwargs_b) = comparison
    
            data_path = datasets.get(key)
>           acc_a = run(data_path, method_a, fraction, **kwargs_a)

tests/test_experiment.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:55: in run
    X_train, Y_train, X_test, Y_test = train_test_split(X, Y, fraction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 0, 0],
       [1,... 1, 0, 0],
       [0, 0, 0, 0, 1, 1],
       [0, 0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0, 1],
       [0, 0, 0, 0, 0, 0]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [1],
       [1]...      [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0]])
fraction = 0.7

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
________________________________________________ test_metrics ________________________________________________

    def test_metrics():
        from sklearn.metrics import accuracy_score
        from src import compute_accuracy
    
        y_true, y_pred = make_fake_data()
        _actual = accuracy_score(y_true, y_pred)
>       _est = compute_accuracy(y_true, y_pred)

tests/test_metrics.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = array([False, False, False,  True,  True, False, False,  True, False,
       False,  True,  True, False,  True, False,... True, False, False, False,  True,
        True, False, False,  True, False,  True,  True,  True, False,
       False])
predictions = array([False, False, False, False,  True, False, False, False, False,
        True,  True, False, False,  True, False,...False,  True, False,  True,  True,
        True,  True, False,  True,  True,  True, False,  True, False,
        True])

    def compute_accuracy(actual, predictions):
        """
        Given predictions (an N-length numpy vector) and actual labels (an N-length
        numpy vector), compute the accuracy:
    
        Hint: implement and use the compute_confusion_matrix function!
    
        Args:
            actual (np.array): predicted labels of length N
            predictions (np.array): predicted labels of length N
    
        Output:
            accuracy (float): accuracy
        """
        if predictions.shape[0] != actual.shape[0]:
            raise ValueError("predictions and actual must be the same length!")
    
>       raise NotImplementedError
E       NotImplementedError

src/metrics.py:53: NotImplementedError
______________________________________ test_numpy_flip_and_slice_matrix ______________________________________

    def test_numpy_flip_and_slice_matrix():
    
        pairs = [
            (np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]]),
             np.array([[2, 1, 0], [11, 10, 9]])),
            (np.array([[ 2,  6, 16, 18, 13, 13, 17]]).T,
             np.array([[2, 18, 17]]).T),
            (np.array([[ 0, 17, 14,  4]]),
             np.array([[ 4, 14, 17,  0]]))
        ]
        for before, after in pairs:
            msg = f"flip_and_slice_matrix({before}) should return {after}"
            before = before.astype(int)
>           assert np.array_equal(src.numpy_practice.flip_and_slice_matrix(before), after), msg

tests/test_numpy.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11],
       [12, 13, 14]])

    def flip_and_slice_matrix(x):
        """
        Take the matrix x and flip it horizontally, then take the every third row.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2],
            ...               [ 3,  4,  5],
            ...               [ 6,  7,  8],
            ...               [ 9, 10, 11],
            ...               [12, 13, 14]])
            >>> flip_and_slice_matrix(x)
            array([[2, 1, 0],
                   [11, 10, 9]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.indexing.html#basics-indexing
    
        Args:
          x: a matrix
        Returns:
          a numpy matrix
        """
        x1 = np.flip(x,axis=1)
>       raise np.asmatrix(x1[::3])
E       TypeError: exceptions must derive from BaseException

src/numpy_practice.py:138: TypeError
____________________________________ test_numpy_divide_matrix_along_rows _____________________________________

    def test_numpy_divide_matrix_along_rows():
    
        trios = [
            (np.array([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]),
             np.array([1, 2, 4]),
             np.array([[0, 1, 2, 3], [2, 2.5, 3, 3.5], [2, 2.25, 2.5, 2.75]])),
            (np.array([[2, 14], [2, 17], [8, 8], [12, 9], [9, 6], [10, 4]]),
             np.array([1, 1, 2, 3, 3, 2]),
             np.array([[2, 14], [2, 17], [4, 4], [4, 3], [3, 2], [5, 2]]))
        ]
        for (x, y, target) in trios:
            msg = f"divide_matrix_along_rows({x}, {y}) should return {target}"
>           assert np.array_equal(src.numpy_practice.divide_matrix_along_rows(x, y), target), msg

tests/test_numpy.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]]), y = array([1, 2, 4])

    def divide_matrix_along_rows(x, y):
        """
        Take the matrix x and divide it by the vector y, such that
            the ith row of x is divided by the ith value of y.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2,  3],
            ...               [ 4,  5,  6,  7],
            ...               [ 8,  9, 10, 11]])
            >>> y = np.array([1, 2, 4])
            >>> divide_rows(x, y)
            array([[0.  , 1.  , 2.  , 3.  ],
                   [2.  , 2.5 , 3.  , 3.5 ],
                   [2.  , 2.25, 2.5 , 2.75]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.broadcasting.html
        You should use one of:
            - np.reshape: https://numpy.org/doc/stable/reference/generated/numpy.reshape.html
            - np.newaxis: https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis
    
        Args:
          x: a matrix
          y: a vector with as many entries as x has rows
        Returns:
          a numpy matrix
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:171: NotImplementedError
------------------------------------------ Captured stdout teardown ------------------------------------------

======================
Output of autograder
======================
# of tests:	8/19 tests passed
Overall score:	9/100
======================
FAIL: test_train_test_split
FAIL: test_cross_validation
FAIL: test_decision_tree_binary_predict
FAIL: test_decision_tree_continuous_predict
FAIL: test_information_gain
FAIL: test_decision_tree_run
FAIL: test_predict_mode
FAIL: test_comparisons
FAIL: test_metrics
PASS: test_hello_world
PASS: test_numpy_replace_nonfinite_in_place
PASS: test_numpy_replace_nans_out_of_place
PASS: test_numpy_find_mode
FAIL: test_numpy_flip_and_slice_matrix
FAIL: test_numpy_divide_matrix_along_rows
======================
============================================== warnings summary ==============================================
tests/test_data.py::test_load_data
  /Users/ankitaroychoudhury/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2
    warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

tests/test_numpy.py::test_numpy_flip_and_slice_matrix
  /Users/ankitaroychoudhury/opt/anaconda3/lib/python3.9/site-packages/numpy/matrixlib/defmatrix.py:69: PendingDeprecationWarning: the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.
    return matrix(data, dtype=dtype, copy=False)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================================== short test summary info ===========================================
FAILED tests/test_data.py::test_train_test_split - NotImplementedError
FAILED tests/test_data.py::test_cross_validation - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_binary_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_continuous_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_information_gain - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_run - NotImplementedError
FAILED tests/test_experiment.py::test_predict_mode - NotImplementedError
FAILED tests/test_experiment.py::test_comparisons - NotImplementedError
FAILED tests/test_metrics.py::test_metrics - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_flip_and_slice_matrix - TypeError: exceptions must derive from BaseE...
FAILED tests/test_numpy.py::test_numpy_divide_matrix_along_rows - NotImplementedError
================================== 11 failed, 9 passed, 2 warnings in 1.43s ==================================
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % pytest
============================================ test session starts =============================================
platform darwin -- Python 3.9.13, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury
plugins: anyio-3.5.0
collected 20 items                                                                                           

tests/test_a_environment.py .                                                                          [  5%]
tests/test_a_setup.py ...                                                                              [ 20%]
tests/test_data.py .FF                                                                                 [ 35%]
tests/test_decision_tree.py FFFF                                                                       [ 55%]
tests/test_experiment.py FF                                                                            [ 65%]
tests/test_metrics.py F                                                                                [ 70%]
tests/test_numpy.py ....FF                                                                             [100%]

================================================== FAILURES ==================================================
___________________________________________ test_train_test_split ____________________________________________

    def test_train_test_split():
        from src import load_data
        from src import train_test_split
    
        n_features = np.random.randint(5, 20)
        n_samples = np.random.randint(50, 150)
        features, targets, attribute_names = write_random_csv_file(n_features, n_samples)
        fraction = np.random.rand()
    
>       output = train_test_split(features, targets, fraction)

tests/test_data.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[ 0.37203326,  0.09880041, -0.21673525, ..., -0.38864126,
        -0.44757689,  0.62194968],
       [ 2.5948463...414, -0.58114041],
       [-0.43704705,  0.95796608, -1.10167426, ..., -1.05283229,
        -0.23666246,  1.78300064]])
labels = array([1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,
       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,...       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1])
fraction = 0.26724039023661905

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
___________________________________________ test_cross_validation ____________________________________________

    def test_cross_validation():
        from src import load_data
        from src import cross_validation
    
        # Remember, your train_test_split should be deterministic
        # You shouldn't be randomly shuffling the data!
        n = 10
        features = np.arange(n).reshape(-1, 1)
        targets = np.arange(n).reshape(-1, 1)
        for folds in [2, 5, 10]:
>           cv = cross_validation(features, targets, folds)

tests/test_data.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
labels = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
n_folds = 2

    def cross_validation(features, labels, n_folds):
        """
        Split the data in `n_folds` different groups for cross-validation.
            Split the features and labels into a `n_folds` number of groups that
            divide the data as evenly as possible. Then for each group,
            return a tuple that treats that group as the test set and all
            other groups combine to make the training set.
    
            Note that this should be *deterministic*; don't shuffle the data.
            If there are 100 examples and you have 5 folds, each group
            should contain 20 examples and the first group should contain
            the first 20 examples.
    
            See test_cross_validation for expected behavior.
    
        Args:
            features: an NxK matrix of N examples, each with K features
            labels: an Nx1 array of N labels
            n_folds: the number of cross-validation groups
    
        Output:
            A list of tuples, where each tuple contains:
              (train_features, train_labels, test_features, test_labels)
        """
    
        assert features.shape[0] == labels.shape[0]
    
        if n_folds == 1:
            return [(features, labels, features, labels)]
>       raise NotImplementedError
E       NotImplementedError

src/data.py:92: NotImplementedError
_____________________________________ test_decision_tree_binary_predict ______________________________________

    def test_decision_tree_binary_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Outlook', 'Temp', 'Wind']
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Outlook", attribute_index=0,
            split_value=0.5, branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=0.5, branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
        examples = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [0, 1, 1]])
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fa2e1e51b50>
features = array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 1, 1],
       [0, 1, 1]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________ test_decision_tree_continuous_predict ____________________________________

    def test_decision_tree_continuous_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Wind', 'Temp', 'Outlook']
        examples = np.array([[1, 79.21, 1], [2, 90.56, 0], [7, 88.36, 1], [5, 84.02, 0], [1, 43.77, 0]])
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Wind", attribute_index=0,
            split_value=np.median(examples[:, 0]), branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=np.median(examples[:, 1]), branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
    
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fa2e1e979d0>
features = array([[ 1.  , 79.21,  1.  ],
       [ 2.  , 90.56,  0.  ],
       [ 7.  , 88.36,  1.  ],
       [ 5.  , 84.02,  0.  ],
       [ 1.  , 43.77,  0.  ]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________________ test_information_gain ____________________________________________

    def test_information_gain():
        from src import load_data
        from src import information_gain
    
        _features, _targets, _attribute_names = load_data('data/play-tennis.csv')
>       iGHumidity = information_gain(_features, 2, _targets)

tests/test_decision_tree.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0, 0, 1, 0],
       [0, 0, 1, 1],
       [1, 0, 1, 0],
       [1, 1, 1, 0],
       [1, 1, 0, 0],
       [1, 1,...[0, 1, 0, 0],
       [1, 1, 0, 0],
       [0, 1, 0, 1],
       [1, 1, 1, 1],
       [1, 0, 0, 0],
       [1, 1, 1, 1]])
attribute_index = 2
labels = array([[0],
       [0],
       [1],
       [1],
       [1],
       [0],
       [1],
       [0],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0]])

    def information_gain(features, attribute_index, labels):
        """
        Information gain is how a decision tree makes decisions on how to create
        split points in the tree. Information gain is measured in terms of entropy.
        The goal of a decision tree is to decrease entropy at each split point as
        much as possible. This function should work perfectly or your decision tree
        will not work properly.
    
        Information gain is a central concept in many machine learning algorithms.
        In decision trees, it captures how effective splitting the tree on a
        specific attribute will be for the goal of classifying the training data
        correctly.  Consider data points S and an attribute A; we'll split S into
        two data points.
    
        For binary A: S(A == 0) and S(A == 1)
        For continuous A: S(A < m) and S(A >= m), where m is the median of A in S.
    
        Together, the two subsets make up S. If the attribute A were perfectly correlated with
        the class of each data point in S, then all points in a given subset will have the
        same class. Clearly, in this case, we want something that captures that A is a good
        attribute to use in the decision tree. This something is information gain. Formally:
    
            IG(S,A) = H(S) - H(S|A)
    
        where H is information entropy. Recall that entropy captures how orderly or chaotic
        a system is. A system that is very chaotic will evenly distribute probabilities to
        all outcomes (e.g. 50% chance of class 0, 50% chance of class 1). Machine learning
        algorithms work to decrease entropy, so as to make predictions that are
        accurate on testing data. Formally, H is defined as:
    
            H(S) = sum_{c in (groups in S)} -p(c) * log_2 p(c)
    
        To elaborate: for each group c in S, you compute the probability (or weight) of c:
    
            p(c) = (# of elements of group c in S) / (total # of elements in S)
    
        Then you compute the term for this group:
    
            -p(c) * log_2 p(c)
    
        Note: if p(c) is 0, we define `-p(c) * log_2 p(c)` as 0. You can see how
            we handle this in the provided `entropy()` function, to avoid how numpy
            defines `0 * log(0) = 0 * -inf = nan`.
    
        Then compute the sum across all groups: either classes 0 and 1 for binary data, or
        for the above-median and below-median classes for continuous data. The final number
        is the entropy. To gain more intution about entropy, consider the following - what
        does H(S) = 0 tell you about S?
    
        Information gain is an extension of entropy. The equation for information gain
        involves comparing the entropy of the set and the entropy of the set when conditioned
        on selecting for a single attribute (e.g. S(A == 0)).
    
        For more details: https://en.wikipedia.org/wiki/ID3_algorithm#The_ID3_metrics
    
        Args:
            features (np.array): numpy array containing features for each example.
            attribute_index (int): which column of features to take when computing the
                information gain
            labels (np.array): numpy array containing labels corresponding to each example.
    
        Returns:
            information_gain (float): information gain if the features were split on the
                attribute_index.
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:262: NotImplementedError
___________________________________________ test_decision_tree_run ___________________________________________

    def test_decision_tree_run():
        goals = {
            'xor-easy.csv': {1.0: 1.0},
            'xor-hard.csv': {1.0: 0.8, 0.8: 1.0},
            'ivy-league.csv': {1.0: .9, 0.8: 0.6,},
            'majority-rule.csv': {1.0: 1.0, 0.8: 0.8,},
            'circles-hard.csv': {1.0: 0.7},
            'circles-easy.csv': {1.0: 0.8},
            'blobs.csv': {1.0: 0.8, 0.8: 0.9,},
        }
    
        order = [
            'xor-easy.csv',
            'ivy-league.csv',
            'majority-rule.csv',
            'xor-hard.csv',
            'blobs.csv',
            'circles-easy.csv',
            'circles-hard.csv',
        ]
    
        learner_type = 'decision_tree'
        for key in order:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_decision_tree.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
src/decision_tree.py:125: in fit
    self.tree = self._create_tree(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7fa2e1e51c70>
features = array([[1, 1],
       [0, 0],
       [1, 0],
       [0, 1]])
labels = array([[0],
       [0],
       [1],
       [1]]), used_attributes = [], default = 0

    def _create_tree(self, features, labels, used_attributes, default):
        '''
        Create a decision tree recursively.
        1. If no data remains, return a leaf node with return_value `default`
            (e.g., if features and labels are both empty)
    
        2. If all labels are the same, return a leaf node with
            that label as the return_value
    
        3. For each attribute, compute the information gain from splitting on it
    
        3.1. If that is in `used_attributes`, instead set information gain to -1
            to prevent us from reusing it
        3.2. If all attributes are used, return a leaf node with the mode class
    
        3.3.1 If at least one attribute, has a non-negative information gain,
            select `best_attribute` with the largest information gain;
        3.3.2 Split data (feature & label) according to attribute values,
            where: `attribute_values = features[:, best_attribute]`;
        3.3.3 If that attribute's values are binary, split on 0.5;
            Otherwise, split on the median of the attribute values;
    
        3.4 Create a non-leaf node with the specified attribute_name,
              attribute_index, and split_value, and then RECURSIVELY
              set build its branches using self._create_tree.
              After recursing, return the node.
        '''
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:160: NotImplementedError
_____________________________________________ test_predict_mode ______________________________________________

    def test_predict_mode():
        goals = {
          'ivy-league.csv': {1.0: 0.5},
          'majority-rule.csv': {1.0: 0.6},
          'circles-easy.csv': {1.0: 0.6},
          'blobs.csv': {1.0: 0.55},
        }
    
        learner_type = 'predict_mode'
        for key in goals:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_experiment.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.predict_mode.PredictMode object at 0x7fa2e1e555e0>
features = array([[1, 1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 1, 0, 0]...      [0, 1, 1, 0, 1, 0, 1],
       [0, 1, 1, 0, 0, 1, 1],
       [0, 1, 1, 0, 0, 0, 1],
       [0, 1, 1, 0, 0, 1, 1]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0]...      [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0],
       [0]])

    def fit(self, features, labels):
        """
        Looking at the provided labels, record the mode (most common) label.
    
        You may call your `find_mode` function from `src.numpy_practice`
    
        Args:
            features (np.array): numpy array of shape (n, d)
                 where n is number of examples and d is number of features.
            labels (np.array): numpy array containing true labels for each of the N
                examples.
        Output:
            None: Simply update self.most_common_class with the most common label
        """
>       raise NotImplementedError
E       NotImplementedError

src/predict_mode.py:35: NotImplementedError
______________________________________________ test_comparisons ______________________________________________

    def test_comparisons():
        comparisons = [
            # predict_mode beats decision tree on majority rule w/ 0.7 frac
            ('majority-rule.csv', 0.7, 'predict_mode', 'decision_tree',
             {}, {}),
    
            # decision tree beats predict mode on majority rule w/ 1.0 frac
            ('majority-rule.csv', 1.0, 'decision_tree', 'predict_mode',
             {}, {}),
        ]
    
        for i, comparison in enumerate(comparisons):
            (key, fraction, method_a, method_b,
             kwargs_a, kwargs_b) = comparison
    
            data_path = datasets.get(key)
>           acc_a = run(data_path, method_a, fraction, **kwargs_a)

tests/test_experiment.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:55: in run
    X_train, Y_train, X_test, Y_test = train_test_split(X, Y, fraction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 0, 0],
       [1,... 1, 0, 0],
       [0, 0, 0, 0, 1, 1],
       [0, 0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0, 1],
       [0, 0, 0, 0, 0, 0]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [1],
       [1]...      [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0]])
fraction = 0.7

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
________________________________________________ test_metrics ________________________________________________

    def test_metrics():
        from sklearn.metrics import accuracy_score
        from src import compute_accuracy
    
        y_true, y_pred = make_fake_data()
        _actual = accuracy_score(y_true, y_pred)
>       _est = compute_accuracy(y_true, y_pred)

tests/test_metrics.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = array([False,  True, False, False, False, False,  True,  True,  True,
       False, False, False, False,  True,  True,...False,  True,  True,  True,  True,
       False, False,  True, False,  True, False,  True, False, False,
        True])
predictions = array([ True,  True, False, False,  True,  True, False,  True,  True,
       False,  True, False, False, False,  True,... True,  True,  True, False,  True,
        True, False, False, False,  True,  True,  True, False, False,
       False])

    def compute_accuracy(actual, predictions):
        """
        Given predictions (an N-length numpy vector) and actual labels (an N-length
        numpy vector), compute the accuracy:
    
        Hint: implement and use the compute_confusion_matrix function!
    
        Args:
            actual (np.array): predicted labels of length N
            predictions (np.array): predicted labels of length N
    
        Output:
            accuracy (float): accuracy
        """
        if predictions.shape[0] != actual.shape[0]:
            raise ValueError("predictions and actual must be the same length!")
    
>       raise NotImplementedError
E       NotImplementedError

src/metrics.py:53: NotImplementedError
______________________________________ test_numpy_flip_and_slice_matrix ______________________________________

    def test_numpy_flip_and_slice_matrix():
    
        pairs = [
            (np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]]),
             np.array([[2, 1, 0], [11, 10, 9]])),
            (np.array([[ 2,  6, 16, 18, 13, 13, 17]]).T,
             np.array([[2, 18, 17]]).T),
            (np.array([[ 0, 17, 14,  4]]),
             np.array([[ 4, 14, 17,  0]]))
        ]
        for before, after in pairs:
            msg = f"flip_and_slice_matrix({before}) should return {after}"
            before = before.astype(int)
>           assert np.array_equal(src.numpy_practice.flip_and_slice_matrix(before), after), msg

tests/test_numpy.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11],
       [12, 13, 14]])

    def flip_and_slice_matrix(x):
        """
        Take the matrix x and flip it horizontally, then take the every third row.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2],
            ...               [ 3,  4,  5],
            ...               [ 6,  7,  8],
            ...               [ 9, 10, 11],
            ...               [12, 13, 14]])
            >>> flip_and_slice_matrix(x)
            array([[2, 1, 0],
                   [11, 10, 9]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.indexing.html#basics-indexing
    
        Args:
          x: a matrix
        Returns:
          a numpy matrix
        """
        x1 = np.flip(x,axis=1)
>       raise np.matrix(x1[::3])
E       TypeError: exceptions must derive from BaseException

src/numpy_practice.py:138: TypeError
____________________________________ test_numpy_divide_matrix_along_rows _____________________________________

    def test_numpy_divide_matrix_along_rows():
    
        trios = [
            (np.array([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]),
             np.array([1, 2, 4]),
             np.array([[0, 1, 2, 3], [2, 2.5, 3, 3.5], [2, 2.25, 2.5, 2.75]])),
            (np.array([[2, 14], [2, 17], [8, 8], [12, 9], [9, 6], [10, 4]]),
             np.array([1, 1, 2, 3, 3, 2]),
             np.array([[2, 14], [2, 17], [4, 4], [4, 3], [3, 2], [5, 2]]))
        ]
        for (x, y, target) in trios:
            msg = f"divide_matrix_along_rows({x}, {y}) should return {target}"
>           assert np.array_equal(src.numpy_practice.divide_matrix_along_rows(x, y), target), msg

tests/test_numpy.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]]), y = array([1, 2, 4])

    def divide_matrix_along_rows(x, y):
        """
        Take the matrix x and divide it by the vector y, such that
            the ith row of x is divided by the ith value of y.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2,  3],
            ...               [ 4,  5,  6,  7],
            ...               [ 8,  9, 10, 11]])
            >>> y = np.array([1, 2, 4])
            >>> divide_rows(x, y)
            array([[0.  , 1.  , 2.  , 3.  ],
                   [2.  , 2.5 , 3.  , 3.5 ],
                   [2.  , 2.25, 2.5 , 2.75]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.broadcasting.html
        You should use one of:
            - np.reshape: https://numpy.org/doc/stable/reference/generated/numpy.reshape.html
            - np.newaxis: https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis
    
        Args:
          x: a matrix
          y: a vector with as many entries as x has rows
        Returns:
          a numpy matrix
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:171: NotImplementedError
------------------------------------------ Captured stdout teardown ------------------------------------------

======================
Output of autograder
======================
# of tests:	8/19 tests passed
Overall score:	9/100
======================
FAIL: test_train_test_split
FAIL: test_cross_validation
FAIL: test_decision_tree_binary_predict
FAIL: test_decision_tree_continuous_predict
FAIL: test_information_gain
FAIL: test_decision_tree_run
FAIL: test_predict_mode
FAIL: test_comparisons
FAIL: test_metrics
PASS: test_hello_world
PASS: test_numpy_replace_nonfinite_in_place
PASS: test_numpy_replace_nans_out_of_place
PASS: test_numpy_find_mode
FAIL: test_numpy_flip_and_slice_matrix
FAIL: test_numpy_divide_matrix_along_rows
======================
============================================== warnings summary ==============================================
tests/test_data.py::test_load_data
  /Users/ankitaroychoudhury/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2
    warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

tests/test_numpy.py::test_numpy_flip_and_slice_matrix
  /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury/src/numpy_practice.py:138: PendingDeprecationWarning: the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.
    raise np.matrix(x1[::3])

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================================== short test summary info ===========================================
FAILED tests/test_data.py::test_train_test_split - NotImplementedError
FAILED tests/test_data.py::test_cross_validation - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_binary_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_continuous_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_information_gain - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_run - NotImplementedError
FAILED tests/test_experiment.py::test_predict_mode - NotImplementedError
FAILED tests/test_experiment.py::test_comparisons - NotImplementedError
FAILED tests/test_metrics.py::test_metrics - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_flip_and_slice_matrix - TypeError: exceptions must derive from BaseE...
FAILED tests/test_numpy.py::test_numpy_divide_matrix_along_rows - NotImplementedError
================================== 11 failed, 9 passed, 2 warnings in 1.43s ==================================
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % pytest
============================================ test session starts =============================================
platform darwin -- Python 3.9.13, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury
plugins: anyio-3.5.0
collected 20 items                                                                                           

tests/test_a_environment.py .                                                                          [  5%]
tests/test_a_setup.py ...                                                                              [ 20%]
tests/test_data.py .FF                                                                                 [ 35%]
tests/test_decision_tree.py FFFF                                                                       [ 55%]
tests/test_experiment.py FF                                                                            [ 65%]
tests/test_metrics.py F                                                                                [ 70%]
tests/test_numpy.py .....F                                                                             [100%]

================================================== FAILURES ==================================================
___________________________________________ test_train_test_split ____________________________________________

    def test_train_test_split():
        from src import load_data
        from src import train_test_split
    
        n_features = np.random.randint(5, 20)
        n_samples = np.random.randint(50, 150)
        features, targets, attribute_names = write_random_csv_file(n_features, n_samples)
        fraction = np.random.rand()
    
>       output = train_test_split(features, targets, fraction)

tests/test_data.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[-0.58272913, -0.61407277,  1.38627084, ..., -0.33755065,
         1.77716141, -1.81045091],
       [-2.6245881...08 , -0.75431221],
       [-1.58816664,  0.1409727 , -0.69123189, ...,  1.12762106,
        -1.20148255, -1.94413272]])
labels = array([0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,
       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,...1, 1,
       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,
       1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0])
fraction = 0.1568449609857122

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
___________________________________________ test_cross_validation ____________________________________________

    def test_cross_validation():
        from src import load_data
        from src import cross_validation
    
        # Remember, your train_test_split should be deterministic
        # You shouldn't be randomly shuffling the data!
        n = 10
        features = np.arange(n).reshape(-1, 1)
        targets = np.arange(n).reshape(-1, 1)
        for folds in [2, 5, 10]:
>           cv = cross_validation(features, targets, folds)

tests/test_data.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
labels = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
n_folds = 2

    def cross_validation(features, labels, n_folds):
        """
        Split the data in `n_folds` different groups for cross-validation.
            Split the features and labels into a `n_folds` number of groups that
            divide the data as evenly as possible. Then for each group,
            return a tuple that treats that group as the test set and all
            other groups combine to make the training set.
    
            Note that this should be *deterministic*; don't shuffle the data.
            If there are 100 examples and you have 5 folds, each group
            should contain 20 examples and the first group should contain
            the first 20 examples.
    
            See test_cross_validation for expected behavior.
    
        Args:
            features: an NxK matrix of N examples, each with K features
            labels: an Nx1 array of N labels
            n_folds: the number of cross-validation groups
    
        Output:
            A list of tuples, where each tuple contains:
              (train_features, train_labels, test_features, test_labels)
        """
    
        assert features.shape[0] == labels.shape[0]
    
        if n_folds == 1:
            return [(features, labels, features, labels)]
>       raise NotImplementedError
E       NotImplementedError

src/data.py:92: NotImplementedError
_____________________________________ test_decision_tree_binary_predict ______________________________________

    def test_decision_tree_binary_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Outlook', 'Temp', 'Wind']
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Outlook", attribute_index=0,
            split_value=0.5, branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=0.5, branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
        examples = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [0, 1, 1]])
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7f9309eb3820>
features = array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 1, 1],
       [0, 1, 1]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________ test_decision_tree_continuous_predict ____________________________________

    def test_decision_tree_continuous_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Wind', 'Temp', 'Outlook']
        examples = np.array([[1, 79.21, 1], [2, 90.56, 0], [7, 88.36, 1], [5, 84.02, 0], [1, 43.77, 0]])
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Wind", attribute_index=0,
            split_value=np.median(examples[:, 0]), branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=np.median(examples[:, 1]), branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
    
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7f9309eb4fd0>
features = array([[ 1.  , 79.21,  1.  ],
       [ 2.  , 90.56,  0.  ],
       [ 7.  , 88.36,  1.  ],
       [ 5.  , 84.02,  0.  ],
       [ 1.  , 43.77,  0.  ]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________________ test_information_gain ____________________________________________

    def test_information_gain():
        from src import load_data
        from src import information_gain
    
        _features, _targets, _attribute_names = load_data('data/play-tennis.csv')
>       iGHumidity = information_gain(_features, 2, _targets)

tests/test_decision_tree.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0, 0, 1, 0],
       [0, 0, 1, 1],
       [1, 0, 1, 0],
       [1, 1, 1, 0],
       [1, 1, 0, 0],
       [1, 1,...[0, 1, 0, 0],
       [1, 1, 0, 0],
       [0, 1, 0, 1],
       [1, 1, 1, 1],
       [1, 0, 0, 0],
       [1, 1, 1, 1]])
attribute_index = 2
labels = array([[0],
       [0],
       [1],
       [1],
       [1],
       [0],
       [1],
       [0],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0]])

    def information_gain(features, attribute_index, labels):
        """
        Information gain is how a decision tree makes decisions on how to create
        split points in the tree. Information gain is measured in terms of entropy.
        The goal of a decision tree is to decrease entropy at each split point as
        much as possible. This function should work perfectly or your decision tree
        will not work properly.
    
        Information gain is a central concept in many machine learning algorithms.
        In decision trees, it captures how effective splitting the tree on a
        specific attribute will be for the goal of classifying the training data
        correctly.  Consider data points S and an attribute A; we'll split S into
        two data points.
    
        For binary A: S(A == 0) and S(A == 1)
        For continuous A: S(A < m) and S(A >= m), where m is the median of A in S.
    
        Together, the two subsets make up S. If the attribute A were perfectly correlated with
        the class of each data point in S, then all points in a given subset will have the
        same class. Clearly, in this case, we want something that captures that A is a good
        attribute to use in the decision tree. This something is information gain. Formally:
    
            IG(S,A) = H(S) - H(S|A)
    
        where H is information entropy. Recall that entropy captures how orderly or chaotic
        a system is. A system that is very chaotic will evenly distribute probabilities to
        all outcomes (e.g. 50% chance of class 0, 50% chance of class 1). Machine learning
        algorithms work to decrease entropy, so as to make predictions that are
        accurate on testing data. Formally, H is defined as:
    
            H(S) = sum_{c in (groups in S)} -p(c) * log_2 p(c)
    
        To elaborate: for each group c in S, you compute the probability (or weight) of c:
    
            p(c) = (# of elements of group c in S) / (total # of elements in S)
    
        Then you compute the term for this group:
    
            -p(c) * log_2 p(c)
    
        Note: if p(c) is 0, we define `-p(c) * log_2 p(c)` as 0. You can see how
            we handle this in the provided `entropy()` function, to avoid how numpy
            defines `0 * log(0) = 0 * -inf = nan`.
    
        Then compute the sum across all groups: either classes 0 and 1 for binary data, or
        for the above-median and below-median classes for continuous data. The final number
        is the entropy. To gain more intution about entropy, consider the following - what
        does H(S) = 0 tell you about S?
    
        Information gain is an extension of entropy. The equation for information gain
        involves comparing the entropy of the set and the entropy of the set when conditioned
        on selecting for a single attribute (e.g. S(A == 0)).
    
        For more details: https://en.wikipedia.org/wiki/ID3_algorithm#The_ID3_metrics
    
        Args:
            features (np.array): numpy array containing features for each example.
            attribute_index (int): which column of features to take when computing the
                information gain
            labels (np.array): numpy array containing labels corresponding to each example.
    
        Returns:
            information_gain (float): information gain if the features were split on the
                attribute_index.
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:262: NotImplementedError
___________________________________________ test_decision_tree_run ___________________________________________

    def test_decision_tree_run():
        goals = {
            'xor-easy.csv': {1.0: 1.0},
            'xor-hard.csv': {1.0: 0.8, 0.8: 1.0},
            'ivy-league.csv': {1.0: .9, 0.8: 0.6,},
            'majority-rule.csv': {1.0: 1.0, 0.8: 0.8,},
            'circles-hard.csv': {1.0: 0.7},
            'circles-easy.csv': {1.0: 0.8},
            'blobs.csv': {1.0: 0.8, 0.8: 0.9,},
        }
    
        order = [
            'xor-easy.csv',
            'ivy-league.csv',
            'majority-rule.csv',
            'xor-hard.csv',
            'blobs.csv',
            'circles-easy.csv',
            'circles-hard.csv',
        ]
    
        learner_type = 'decision_tree'
        for key in order:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_decision_tree.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
src/decision_tree.py:125: in fit
    self.tree = self._create_tree(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7f9309eb6490>
features = array([[1, 1],
       [0, 0],
       [1, 0],
       [0, 1]])
labels = array([[0],
       [0],
       [1],
       [1]]), used_attributes = [], default = 0

    def _create_tree(self, features, labels, used_attributes, default):
        '''
        Create a decision tree recursively.
        1. If no data remains, return a leaf node with return_value `default`
            (e.g., if features and labels are both empty)
    
        2. If all labels are the same, return a leaf node with
            that label as the return_value
    
        3. For each attribute, compute the information gain from splitting on it
    
        3.1. If that is in `used_attributes`, instead set information gain to -1
            to prevent us from reusing it
        3.2. If all attributes are used, return a leaf node with the mode class
    
        3.3.1 If at least one attribute, has a non-negative information gain,
            select `best_attribute` with the largest information gain;
        3.3.2 Split data (feature & label) according to attribute values,
            where: `attribute_values = features[:, best_attribute]`;
        3.3.3 If that attribute's values are binary, split on 0.5;
            Otherwise, split on the median of the attribute values;
    
        3.4 Create a non-leaf node with the specified attribute_name,
              attribute_index, and split_value, and then RECURSIVELY
              set build its branches using self._create_tree.
              After recursing, return the node.
        '''
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:160: NotImplementedError
_____________________________________________ test_predict_mode ______________________________________________

    def test_predict_mode():
        goals = {
          'ivy-league.csv': {1.0: 0.5},
          'majority-rule.csv': {1.0: 0.6},
          'circles-easy.csv': {1.0: 0.6},
          'blobs.csv': {1.0: 0.55},
        }
    
        learner_type = 'predict_mode'
        for key in goals:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_experiment.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.predict_mode.PredictMode object at 0x7f9309eb4460>
features = array([[1, 1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 1, 0, 0]...      [0, 1, 1, 0, 1, 0, 1],
       [0, 1, 1, 0, 0, 1, 1],
       [0, 1, 1, 0, 0, 0, 1],
       [0, 1, 1, 0, 0, 1, 1]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0]...      [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0],
       [0]])

    def fit(self, features, labels):
        """
        Looking at the provided labels, record the mode (most common) label.
    
        You may call your `find_mode` function from `src.numpy_practice`
    
        Args:
            features (np.array): numpy array of shape (n, d)
                 where n is number of examples and d is number of features.
            labels (np.array): numpy array containing true labels for each of the N
                examples.
        Output:
            None: Simply update self.most_common_class with the most common label
        """
>       raise NotImplementedError
E       NotImplementedError

src/predict_mode.py:35: NotImplementedError
______________________________________________ test_comparisons ______________________________________________

    def test_comparisons():
        comparisons = [
            # predict_mode beats decision tree on majority rule w/ 0.7 frac
            ('majority-rule.csv', 0.7, 'predict_mode', 'decision_tree',
             {}, {}),
    
            # decision tree beats predict mode on majority rule w/ 1.0 frac
            ('majority-rule.csv', 1.0, 'decision_tree', 'predict_mode',
             {}, {}),
        ]
    
        for i, comparison in enumerate(comparisons):
            (key, fraction, method_a, method_b,
             kwargs_a, kwargs_b) = comparison
    
            data_path = datasets.get(key)
>           acc_a = run(data_path, method_a, fraction, **kwargs_a)

tests/test_experiment.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:55: in run
    X_train, Y_train, X_test, Y_test = train_test_split(X, Y, fraction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 0, 0],
       [1,... 1, 0, 0],
       [0, 0, 0, 0, 1, 1],
       [0, 0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0, 1],
       [0, 0, 0, 0, 0, 0]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [1],
       [1]...      [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0]])
fraction = 0.7

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
________________________________________________ test_metrics ________________________________________________

    def test_metrics():
        from sklearn.metrics import accuracy_score
        from src import compute_accuracy
    
        y_true, y_pred = make_fake_data()
        _actual = accuracy_score(y_true, y_pred)
>       _est = compute_accuracy(y_true, y_pred)

tests/test_metrics.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = array([False, False, False,  True, False, False, False,  True,  True,
        True, False,  True,  True,  True, False,... True,  True,  True,  True,  True,
       False,  True,  True,  True,  True, False, False, False, False,
       False])
predictions = array([False, False, False,  True,  True,  True,  True, False,  True,
       False,  True,  True,  True, False,  True,...False, False,  True, False, False,
        True, False, False,  True,  True,  True, False, False, False,
       False])

    def compute_accuracy(actual, predictions):
        """
        Given predictions (an N-length numpy vector) and actual labels (an N-length
        numpy vector), compute the accuracy:
    
        Hint: implement and use the compute_confusion_matrix function!
    
        Args:
            actual (np.array): predicted labels of length N
            predictions (np.array): predicted labels of length N
    
        Output:
            accuracy (float): accuracy
        """
        if predictions.shape[0] != actual.shape[0]:
            raise ValueError("predictions and actual must be the same length!")
    
>       raise NotImplementedError
E       NotImplementedError

src/metrics.py:53: NotImplementedError
____________________________________ test_numpy_divide_matrix_along_rows _____________________________________

    def test_numpy_divide_matrix_along_rows():
    
        trios = [
            (np.array([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]),
             np.array([1, 2, 4]),
             np.array([[0, 1, 2, 3], [2, 2.5, 3, 3.5], [2, 2.25, 2.5, 2.75]])),
            (np.array([[2, 14], [2, 17], [8, 8], [12, 9], [9, 6], [10, 4]]),
             np.array([1, 1, 2, 3, 3, 2]),
             np.array([[2, 14], [2, 17], [4, 4], [4, 3], [3, 2], [5, 2]]))
        ]
        for (x, y, target) in trios:
            msg = f"divide_matrix_along_rows({x}, {y}) should return {target}"
>           assert np.array_equal(src.numpy_practice.divide_matrix_along_rows(x, y), target), msg

tests/test_numpy.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

x = array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]]), y = array([1, 2, 4])

    def divide_matrix_along_rows(x, y):
        """
        Take the matrix x and divide it by the vector y, such that
            the ith row of x is divided by the ith value of y.
    
        You should be able to do this in two or fewer lines of code.
        You may not use a `for` loop or `if` statement!
    
        For example:
            >>> x = np.array([[ 0,  1,  2,  3],
            ...               [ 4,  5,  6,  7],
            ...               [ 8,  9, 10, 11]])
            >>> y = np.array([1, 2, 4])
            >>> divide_rows(x, y)
            array([[0.  , 1.  , 2.  , 3.  ],
                   [2.  , 2.5 , 3.  , 3.5 ],
                   [2.  , 2.25, 2.5 , 2.75]])
    
        First, read:
            - https://numpy.org/doc/stable/user/basics.broadcasting.html
        You should use one of:
            - np.reshape: https://numpy.org/doc/stable/reference/generated/numpy.reshape.html
            - np.newaxis: https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis
    
        Args:
          x: a matrix
          y: a vector with as many entries as x has rows
        Returns:
          a numpy matrix
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/numpy_practice.py:171: NotImplementedError
------------------------------------------ Captured stdout teardown ------------------------------------------

======================
Output of autograder
======================
# of tests:	9/19 tests passed
Overall score:	11/100
======================
FAIL: test_train_test_split
FAIL: test_cross_validation
FAIL: test_decision_tree_binary_predict
FAIL: test_decision_tree_continuous_predict
FAIL: test_information_gain
FAIL: test_decision_tree_run
FAIL: test_predict_mode
FAIL: test_comparisons
FAIL: test_metrics
PASS: test_hello_world
PASS: test_numpy_replace_nonfinite_in_place
PASS: test_numpy_replace_nans_out_of_place
PASS: test_numpy_find_mode
PASS: test_numpy_flip_and_slice_matrix
FAIL: test_numpy_divide_matrix_along_rows
======================
============================================== warnings summary ==============================================
tests/test_data.py::test_load_data
  /Users/ankitaroychoudhury/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2
    warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

tests/test_numpy.py::test_numpy_flip_and_slice_matrix
tests/test_numpy.py::test_numpy_flip_and_slice_matrix
tests/test_numpy.py::test_numpy_flip_and_slice_matrix
  /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury/src/numpy_practice.py:138: PendingDeprecationWarning: the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.
    return np.matrix(x1[::3])

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================================== short test summary info ===========================================
FAILED tests/test_data.py::test_train_test_split - NotImplementedError
FAILED tests/test_data.py::test_cross_validation - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_binary_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_continuous_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_information_gain - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_run - NotImplementedError
FAILED tests/test_experiment.py::test_predict_mode - NotImplementedError
FAILED tests/test_experiment.py::test_comparisons - NotImplementedError
FAILED tests/test_metrics.py::test_metrics - NotImplementedError
FAILED tests/test_numpy.py::test_numpy_divide_matrix_along_rows - NotImplementedError
================================= 10 failed, 10 passed, 4 warnings in 1.30s ==================================
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % pytest
============================================ test session starts =============================================
platform darwin -- Python 3.9.13, pytest-7.1.2, pluggy-1.0.0
rootdir: /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury
plugins: anyio-3.5.0
collected 20 items                                                                                           

tests/test_a_environment.py .                                                                          [  5%]
tests/test_a_setup.py ...                                                                              [ 20%]
tests/test_data.py .FF                                                                                 [ 35%]
tests/test_decision_tree.py FFFF                                                                       [ 55%]
tests/test_experiment.py FF                                                                            [ 65%]
tests/test_metrics.py F                                                                                [ 70%]
tests/test_numpy.py ......                                                                             [100%]

================================================== FAILURES ==================================================
___________________________________________ test_train_test_split ____________________________________________

    def test_train_test_split():
        from src import load_data
        from src import train_test_split
    
        n_features = np.random.randint(5, 20)
        n_samples = np.random.randint(50, 150)
        features, targets, attribute_names = write_random_csv_file(n_features, n_samples)
        fraction = np.random.rand()
    
>       output = train_test_split(features, targets, fraction)

tests/test_data.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[ 1.65977173, -0.86746851,  0.17864762, ..., -1.12439768,
         0.98904995,  0.55874237],
       [ 1.4830887...015, -1.37132304],
       [-0.01869342, -0.54079806, -1.45550511, ..., -0.20467526,
        -0.29738532,  1.35263615]])
labels = array([1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,
       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,...0, 1, 1,
       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 1, 1, 0, 0, 0, 0, 1, 0, 1])
fraction = 0.7414872723945165

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
___________________________________________ test_cross_validation ____________________________________________

    def test_cross_validation():
        from src import load_data
        from src import cross_validation
    
        # Remember, your train_test_split should be deterministic
        # You shouldn't be randomly shuffling the data!
        n = 10
        features = np.arange(n).reshape(-1, 1)
        targets = np.arange(n).reshape(-1, 1)
        for folds in [2, 5, 10]:
>           cv = cross_validation(features, targets, folds)

tests/test_data.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
labels = array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
n_folds = 2

    def cross_validation(features, labels, n_folds):
        """
        Split the data in `n_folds` different groups for cross-validation.
            Split the features and labels into a `n_folds` number of groups that
            divide the data as evenly as possible. Then for each group,
            return a tuple that treats that group as the test set and all
            other groups combine to make the training set.
    
            Note that this should be *deterministic*; don't shuffle the data.
            If there are 100 examples and you have 5 folds, each group
            should contain 20 examples and the first group should contain
            the first 20 examples.
    
            See test_cross_validation for expected behavior.
    
        Args:
            features: an NxK matrix of N examples, each with K features
            labels: an Nx1 array of N labels
            n_folds: the number of cross-validation groups
    
        Output:
            A list of tuples, where each tuple contains:
              (train_features, train_labels, test_features, test_labels)
        """
    
        assert features.shape[0] == labels.shape[0]
    
        if n_folds == 1:
            return [(features, labels, features, labels)]
>       raise NotImplementedError
E       NotImplementedError

src/data.py:92: NotImplementedError
_____________________________________ test_decision_tree_binary_predict ______________________________________

    def test_decision_tree_binary_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Outlook', 'Temp', 'Wind']
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Outlook", attribute_index=0,
            split_value=0.5, branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=0.5, branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
        examples = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1], [0, 1, 1]])
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7f7e4a41a520>
features = array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [1, 1, 1],
       [0, 1, 1]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________ test_decision_tree_continuous_predict ____________________________________

    def test_decision_tree_continuous_predict():
        from src.decision_tree import DecisionTree, Node
        attribute_names = ['Wind', 'Temp', 'Outlook']
        examples = np.array([[1, 79.21, 1], [2, 90.56, 0], [7, 88.36, 1], [5, 84.02, 0], [1, 43.77, 0]])
        decision_tree = DecisionTree(attribute_names=attribute_names)
        root = Node(
            attribute_name="Wind", attribute_index=0,
            split_value=np.median(examples[:, 0]), branches=[])
    
        left = Node(
            attribute_name="Temp", attribute_index=1,
            split_value=np.median(examples[:, 1]), branches=[])
    
        left_left = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left_right = Node(
            attribute_name=None, attribute_index=None,
            return_value=0, branches=[])
    
        right = Node(
            attribute_name=None, attribute_index=None,
            return_value=1, branches=[])
    
        left.branches = [left_left, left_right]
        root.branches = [left, right]
        decision_tree.tree = root
    
>       predictions = decision_tree.predict(examples)

tests/test_decision_tree.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7f7e4a4169a0>
features = array([[ 1.  , 79.21,  1.  ],
       [ 2.  , 90.56,  0.  ],
       [ 7.  , 88.36,  1.  ],
       [ 5.  , 84.02,  0.  ],
       [ 1.  , 43.77,  0.  ]])

    def predict(self, features):
        """
        Predicts label for each example in features using the trained model.
    
        Args:
            features (np.array): numpy array of shape (n, d)
                where n is number of examples and d is number of features.
        Returns:
            predictions (np.array): numpy array of size N array which has the predicitons
                for the input data.
        """
        self._check_input(features)
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:175: NotImplementedError
___________________________________________ test_information_gain ____________________________________________

    def test_information_gain():
        from src import load_data
        from src import information_gain
    
        _features, _targets, _attribute_names = load_data('data/play-tennis.csv')
>       iGHumidity = information_gain(_features, 2, _targets)

tests/test_decision_tree.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[0, 0, 1, 0],
       [0, 0, 1, 1],
       [1, 0, 1, 0],
       [1, 1, 1, 0],
       [1, 1, 0, 0],
       [1, 1,...[0, 1, 0, 0],
       [1, 1, 0, 0],
       [0, 1, 0, 1],
       [1, 1, 1, 1],
       [1, 0, 0, 0],
       [1, 1, 1, 1]])
attribute_index = 2
labels = array([[0],
       [0],
       [1],
       [1],
       [1],
       [0],
       [1],
       [0],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0]])

    def information_gain(features, attribute_index, labels):
        """
        Information gain is how a decision tree makes decisions on how to create
        split points in the tree. Information gain is measured in terms of entropy.
        The goal of a decision tree is to decrease entropy at each split point as
        much as possible. This function should work perfectly or your decision tree
        will not work properly.
    
        Information gain is a central concept in many machine learning algorithms.
        In decision trees, it captures how effective splitting the tree on a
        specific attribute will be for the goal of classifying the training data
        correctly.  Consider data points S and an attribute A; we'll split S into
        two data points.
    
        For binary A: S(A == 0) and S(A == 1)
        For continuous A: S(A < m) and S(A >= m), where m is the median of A in S.
    
        Together, the two subsets make up S. If the attribute A were perfectly correlated with
        the class of each data point in S, then all points in a given subset will have the
        same class. Clearly, in this case, we want something that captures that A is a good
        attribute to use in the decision tree. This something is information gain. Formally:
    
            IG(S,A) = H(S) - H(S|A)
    
        where H is information entropy. Recall that entropy captures how orderly or chaotic
        a system is. A system that is very chaotic will evenly distribute probabilities to
        all outcomes (e.g. 50% chance of class 0, 50% chance of class 1). Machine learning
        algorithms work to decrease entropy, so as to make predictions that are
        accurate on testing data. Formally, H is defined as:
    
            H(S) = sum_{c in (groups in S)} -p(c) * log_2 p(c)
    
        To elaborate: for each group c in S, you compute the probability (or weight) of c:
    
            p(c) = (# of elements of group c in S) / (total # of elements in S)
    
        Then you compute the term for this group:
    
            -p(c) * log_2 p(c)
    
        Note: if p(c) is 0, we define `-p(c) * log_2 p(c)` as 0. You can see how
            we handle this in the provided `entropy()` function, to avoid how numpy
            defines `0 * log(0) = 0 * -inf = nan`.
    
        Then compute the sum across all groups: either classes 0 and 1 for binary data, or
        for the above-median and below-median classes for continuous data. The final number
        is the entropy. To gain more intution about entropy, consider the following - what
        does H(S) = 0 tell you about S?
    
        Information gain is an extension of entropy. The equation for information gain
        involves comparing the entropy of the set and the entropy of the set when conditioned
        on selecting for a single attribute (e.g. S(A == 0)).
    
        For more details: https://en.wikipedia.org/wiki/ID3_algorithm#The_ID3_metrics
    
        Args:
            features (np.array): numpy array containing features for each example.
            attribute_index (int): which column of features to take when computing the
                information gain
            labels (np.array): numpy array containing labels corresponding to each example.
    
        Returns:
            information_gain (float): information gain if the features were split on the
                attribute_index.
        """
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:262: NotImplementedError
___________________________________________ test_decision_tree_run ___________________________________________

    def test_decision_tree_run():
        goals = {
            'xor-easy.csv': {1.0: 1.0},
            'xor-hard.csv': {1.0: 0.8, 0.8: 1.0},
            'ivy-league.csv': {1.0: .9, 0.8: 0.6,},
            'majority-rule.csv': {1.0: 1.0, 0.8: 0.8,},
            'circles-hard.csv': {1.0: 0.7},
            'circles-easy.csv': {1.0: 0.8},
            'blobs.csv': {1.0: 0.8, 0.8: 0.9,},
        }
    
        order = [
            'xor-easy.csv',
            'ivy-league.csv',
            'majority-rule.csv',
            'xor-hard.csv',
            'blobs.csv',
            'circles-easy.csv',
            'circles-hard.csv',
        ]
    
        learner_type = 'decision_tree'
        for key in order:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_decision_tree.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
src/decision_tree.py:125: in fit
    self.tree = self._create_tree(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.decision_tree.DecisionTree object at 0x7f7e39e7dc40>
features = array([[1, 1],
       [0, 0],
       [1, 0],
       [0, 1]])
labels = array([[0],
       [0],
       [1],
       [1]]), used_attributes = [], default = 0

    def _create_tree(self, features, labels, used_attributes, default):
        '''
        Create a decision tree recursively.
        1. If no data remains, return a leaf node with return_value `default`
            (e.g., if features and labels are both empty)
    
        2. If all labels are the same, return a leaf node with
            that label as the return_value
    
        3. For each attribute, compute the information gain from splitting on it
    
        3.1. If that is in `used_attributes`, instead set information gain to -1
            to prevent us from reusing it
        3.2. If all attributes are used, return a leaf node with the mode class
    
        3.3.1 If at least one attribute, has a non-negative information gain,
            select `best_attribute` with the largest information gain;
        3.3.2 Split data (feature & label) according to attribute values,
            where: `attribute_values = features[:, best_attribute]`;
        3.3.3 If that attribute's values are binary, split on 0.5;
            Otherwise, split on the median of the attribute values;
    
        3.4 Create a non-leaf node with the specified attribute_name,
              attribute_index, and split_value, and then RECURSIVELY
              set build its branches using self._create_tree.
              After recursing, return the node.
        '''
    
>       raise NotImplementedError
E       NotImplementedError

src/decision_tree.py:160: NotImplementedError
_____________________________________________ test_predict_mode ______________________________________________

    def test_predict_mode():
        goals = {
          'ivy-league.csv': {1.0: 0.5},
          'majority-rule.csv': {1.0: 0.6},
          'circles-easy.csv': {1.0: 0.6},
          'blobs.csv': {1.0: 0.55},
        }
    
        learner_type = 'predict_mode'
        for key in goals:
            for fraction, goal in goals[key].items():
>               accuracy = run(datasets.get(key), learner_type, fraction)

tests/test_experiment.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:58: in run
    learner.fit(X_train, Y_train)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.predict_mode.PredictMode object at 0x7f7e4a41aca0>
features = array([[1, 1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 1, 0, 0]...      [0, 1, 1, 0, 1, 0, 1],
       [0, 1, 1, 0, 0, 1, 1],
       [0, 1, 1, 0, 0, 0, 1],
       [0, 1, 1, 0, 0, 1, 1]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0]...      [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [0],
       [0]])

    def fit(self, features, labels):
        """
        Looking at the provided labels, record the mode (most common) label.
    
        You may call your `find_mode` function from `src.numpy_practice`
    
        Args:
            features (np.array): numpy array of shape (n, d)
                 where n is number of examples and d is number of features.
            labels (np.array): numpy array containing true labels for each of the N
                examples.
        Output:
            None: Simply update self.most_common_class with the most common label
        """
>       raise NotImplementedError
E       NotImplementedError

src/predict_mode.py:35: NotImplementedError
______________________________________________ test_comparisons ______________________________________________

    def test_comparisons():
        comparisons = [
            # predict_mode beats decision tree on majority rule w/ 0.7 frac
            ('majority-rule.csv', 0.7, 'predict_mode', 'decision_tree',
             {}, {}),
    
            # decision tree beats predict mode on majority rule w/ 1.0 frac
            ('majority-rule.csv', 1.0, 'decision_tree', 'predict_mode',
             {}, {}),
        ]
    
        for i, comparison in enumerate(comparisons):
            (key, fraction, method_a, method_b,
             kwargs_a, kwargs_b) = comparison
    
            data_path = datasets.get(key)
>           acc_a = run(data_path, method_a, fraction, **kwargs_a)

tests/test_experiment.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/experiment.py:55: in run
    X_train, Y_train, X_test, Y_test = train_test_split(X, Y, fraction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

features = array([[1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 0],
       [1, 1, 1, 1, 0, 1],
       [1, 1, 1, 1, 0, 0],
       [1,... 1, 0, 0],
       [0, 0, 0, 0, 1, 1],
       [0, 0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0, 1],
       [0, 0, 0, 0, 0, 0]])
labels = array([[1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [1],
       [0],
       [1],
       [1]...      [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0]])
fraction = 0.7

    def train_test_split(features, labels, fraction):
        """
        Split features and labels into training and testing. The first M points
        from the data will be used for training and the remaining
        (features.shape[0] - M) points will be used for testing. Where M is:
    
            M = int(features.shape[0] * fraction)
    
        However, when fraction is 1.0, both training and test splits are
        the entire dataset. Code for this special case is provided for you.
    
        Args:
            features (np.array): NxD numpy array containing D features for each example
            labels (np.array): Nx1 numpy array containing labels corresponding to each example
            fraction (float between 0.0 and 1.0): fraction of examples to be drawn for training
    
        Returns (a tuple containing four variables):
            train_features: MxD numpy array of examples to be used for training
            train_labels: Mx1 numpy array of labels corresponding to `train_features`
            test_features: (N - M)xD numpy array of examples to be used for testing
            test_labels: (N - M)x1 numpy array of labels corresponding to `test_features`
        """
    
        if fraction == 1.0:
            return features, labels, features, labels
        elif fraction < 1.0:
>           raise NotImplementedError
E           NotImplementedError

src/data.py:58: NotImplementedError
________________________________________________ test_metrics ________________________________________________

    def test_metrics():
        from sklearn.metrics import accuracy_score
        from src import compute_accuracy
    
        y_true, y_pred = make_fake_data()
        _actual = accuracy_score(y_true, y_pred)
>       _est = compute_accuracy(y_true, y_pred)

tests/test_metrics.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = array([ True, False, False,  True,  True,  True, False,  True, False,
       False, False,  True, False,  True,  True,... True,  True,  True, False, False,
       False,  True,  True, False, False,  True,  True,  True,  True,
        True])
predictions = array([False, False,  True, False,  True,  True, False,  True,  True,
        True,  True,  True, False,  True,  True,...False, False, False,  True, False,
        True,  True, False, False, False,  True,  True, False,  True,
        True])

    def compute_accuracy(actual, predictions):
        """
        Given predictions (an N-length numpy vector) and actual labels (an N-length
        numpy vector), compute the accuracy:
    
        Hint: implement and use the compute_confusion_matrix function!
    
        Args:
            actual (np.array): predicted labels of length N
            predictions (np.array): predicted labels of length N
    
        Output:
            accuracy (float): accuracy
        """
        if predictions.shape[0] != actual.shape[0]:
            raise ValueError("predictions and actual must be the same length!")
    
>       raise NotImplementedError
E       NotImplementedError

src/metrics.py:53: NotImplementedError
============================================== warnings summary ==============================================
tests/test_data.py::test_load_data
  /Users/ankitaroychoudhury/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2
    warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

tests/test_numpy.py::test_numpy_flip_and_slice_matrix
tests/test_numpy.py::test_numpy_flip_and_slice_matrix
tests/test_numpy.py::test_numpy_flip_and_slice_matrix
  /Users/ankitaroychoudhury/Documents/2_winter_nu/ML/hw1-decision-tree-AnkitaRoychoudhury/src/numpy_practice.py:138: PendingDeprecationWarning: the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.
    return np.matrix(x1[::3])

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================================== short test summary info ===========================================
FAILED tests/test_data.py::test_train_test_split - NotImplementedError
FAILED tests/test_data.py::test_cross_validation - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_binary_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_continuous_predict - NotImplementedError
FAILED tests/test_decision_tree.py::test_information_gain - NotImplementedError
FAILED tests/test_decision_tree.py::test_decision_tree_run - NotImplementedError
FAILED tests/test_experiment.py::test_predict_mode - NotImplementedError
FAILED tests/test_experiment.py::test_comparisons - NotImplementedError
FAILED tests/test_metrics.py::test_metrics - NotImplementedError
================================== 9 failed, 11 passed, 4 warnings in 1.47s ==================================
(base) ankitaroychoudhury@Ankitas-MacBook-Pro hw1-decision-tree-AnkitaRoychoudhury % 
